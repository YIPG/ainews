<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>静かな金曜日。 | AIニュース</title>
    <meta name="description" content="静かな金曜日。 - AIニュース 2025-12-12。最新のAI技術動向を日本語でお届け。">
    <meta name="keywords" content="AI,人工知能,ニュースレター,2025-12-12,機械学習,深層学習,日本語">
    <meta name="author" content="AIニュース">
    <link rel="canonical" href="https://yipg.github.io/ainews/docs/newsletters/2025-12-12.html">
    
    <!-- Open Graph meta tags -->
    <meta property="og:title" content="静かな金曜日。 | AIニュース">
    <meta property="og:description" content="静かな金曜日。 - AIニュース 2025-12-12。最新のAI技術動向を日本語でお届け。">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://yipg.github.io/ainews/docs/newsletters/2025-12-12.html">
    <meta property="og:image" content="https://yipg.github.io/ainews/newsletters/og/2025-12-12.png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:image:type" content="image/png">
    <meta property="og:site_name" content="AIニュース">
    <meta property="og:locale" content="ja_JP">
    <meta property="article:published_time" content="2025-12-12T09:00:00+00:00">
    <meta property="article:author" content="AIニュース">
    <meta property="article:section" content="AI技術ニュース">
    
    <!-- Twitter Card meta tags -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="静かな金曜日。 | AIニュース">
    <meta name="twitter:description" content="静かな金曜日。 - AIニュース 2025-12-12。最新のAI技術動向を日本語でお届け。">
    <meta name="twitter:image" content="https://yipg.github.io/ainews/newsletters/og/2025-12-12.png">
    
    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>✏️</text></svg>">
    <link rel="alternate icon" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAACXBIWXMAAA7EAAAOxAGVKw4bAAAA">
    
    <!-- RSS Feed -->
    <link rel="alternate" type="application/rss+xml" title="AIニュース RSS Feed" href="../feed.xml">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: Verdana, Geneva, sans-serif;
            font-size: 1em;
            line-height: 1.7;
            letter-spacing: 0.02em;
            max-width: 720px;
            margin: 0 auto;
            padding: 20px;
            background-color: #fff;
            color: #111;
            word-wrap: break-word;
        }
        
        nav {
            margin-bottom: 25px;
            padding-bottom: 15px;
            border-bottom: 1px solid #ddd;
            display: flex;
            align-items: center;
            justify-content: space-between;
            flex-wrap: nowrap;
        }
        
        .site-title {
            font-size: 1.1em;
            font-weight: bold;
            color: #111;
            text-decoration: none;
            flex-shrink: 0;
        }
        
        .site-title:hover {
            text-decoration: underline;
        }
        
        .nav-links {
            font-size: 0.85em;
            white-space: nowrap;
        }
        
        .nav-links a {
            color: #111;
            text-decoration: none;
            margin-left: 12px;
        }
        
        .nav-links a:hover {
            text-decoration: underline;
        }
        
        
        h1, h2, h3, h4, h5, h6 {
            margin: 35px 0 20px 0;
            line-height: 1.3;
            color: #111;
            letter-spacing: 0.01em;
        }
        
        h1 { font-size: 1.5em; }
        h2 { font-size: 1.3em; }
        h3 { font-size: 1.1em; }
        
        p {
            margin: 20px 0;
        }
        
        a {
            color: #0969da;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin: 20px 0;
            padding-left: 30px;
        }
        
        li {
            margin: 8px 0;
        }
        
        blockquote {
            border-left: 3px solid #ccc;
            margin: 25px 0;
            padding: 0 25px;
            color: #555;
            font-style: italic;
        }
        
        code {
            background-color: #f6f8fa;
            padding: 2px 4px;
            border-radius: 3px;
            font-family: 'Courier New', Courier, monospace;
            font-size: 0.9em;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            padding: 20px;
            overflow-x: auto;
            margin: 25px 0;
        }
        
        pre code {
            background: none;
            padding: 0;
        }
        
        img {
            max-width: 100%;
            height: auto;
            margin: 25px 0;
            border-radius: 3px;
        }
        
        hr {
            border: none;
            border-top: 1px solid #ddd;
            margin: 35px 0;
        }
        
        footer {
            margin-top: 40px;
            padding-top: 15px;
            border-top: 1px solid #ddd;
            text-align: center;
            color: #555;
            font-size: 0.85em;
        }
        
        footer a {
            color: #555;
            text-decoration: none;
            margin: 0 8px;
        }
        
        footer a:hover {
            text-decoration: underline;
        }
        
        @media (max-width: 600px) {
            body {
                padding: 15px;
                font-size: 0.95em;
            }
            
            nav {
                flex-direction: column;
                align-items: flex-start;
                gap: 10px;
            }
            
            .nav-links {
                font-size: 0.8em;
            }
            
            .nav-links a {
                margin-left: 0;
                margin-right: 12px;
            }
            
            .article-title {
                font-size: 1.4em;
            }
        }
        
        @media (max-width: 480px) {
            body {
                font-size: 0.9em;
                padding: 12px;
            }
            
            .site-title {
                font-size: 1em;
            }
            
            .nav-links {
                font-size: 0.75em;
            }
            
            .article-title {
                font-size: 1.3em;
            }
        }
        
        @media (prefers-color-scheme: dark) {
            body {
                background-color: #111;
                color: #eee;
            }
            
            nav {
                border-bottom-color: #444;
            }
            
            .site-title, .nav-links a, .article-title, h1, h2, h3, h4, h5, h6 {
                color: #eee;
            }
            
            .article-date {
                color: #ccc;
            }
            
            blockquote {
                border-left-color: #555;
                color: #ccc;
            }
            
            code {
                background-color: #2d3748;
                color: #e2e8f0;
            }
            
            pre {
                background-color: #2d3748;
            }
            
            hr, footer {
                border-color: #444;
            }
            
            footer, footer a {
                color: #ccc;
            }
        }
    </style>
</head>
<body>
    <nav>
        <a href="../index.html" class="site-title">✏️ AIニュース</a>
        <div class="nav-links">
            <a href="../index.html">ホーム</a>
            <a href="./archive.html">アーカイブ</a>
            <a href="../feed.xml">RSS</a>
            <a href="https://github.com/YIPG/ainews">GitHub</a>
        </div>
    </nav>

    <main>
        <p><strong>静かな金曜日。</strong></p>
<blockquote>
<p>AIニュース（2025年12月11日〜12月12日）。<br />
今週末も <a href="https://www.youtube.com/channel/UCLKPca3kwwd-B59HNr-_lvA">AIE Talks</a> が続々公開予定です。</p>
</blockquote>
<hr />
<h1 id="ai-twitter">AI Twitterまとめ</h1>
<p><strong>フロンティアモデル評価：GPT‑5.2 vs Opus 4.5、Gemini 3、コストとコンテキスト設定</strong></p>
<ul>
<li><strong>GPT‑5.2の性能は公開評価でまちまち</strong>：実務的でエージェント的なタスクでは、GPT‑5.2がGDPval‑AAでClaude Opus 4.5を上回りましたが、コストは高く、<strong>1回あたり約620ドル</strong>（Opus 4.5は608ドル、GPT‑5.1は88ドル）。これはトークン数が6倍以上、さらに価格が40%上昇したためです（<a href="https://twitter.com/ArtificialAnlys/status/1999404579599823091">@ArtificialAnlys</a>）。推論やコーディングの定番評価では、LiveBenchでOpus 4.5やGemini 3 Proに劣り、SimpleBenchではSonnet 3.7より低く、VendingBench‑2では改善したもののGemini 3 ProやOpus 4.5には及びません（<a href="https://twitter.com/scaling01/status/1999323401421488319">@scaling01</a>、<a href="https://twitter.com/scaling01/status/1999466846563762290">@scaling01</a>、<a href="https://twitter.com/scaling01/status/1999449402776387808">@scaling01</a>）。長文コンテキストのMRCR v2では、5.2 xhighがGemini 3 Proを上回りました。OpenAIはv1の修正後にMRCRv2を更新しています（<a href="https://twitter.com/DillonUzar/status/1999328225164431394">スレッド</a>、<a href="https://twitter.com/scaling01/status/1999327512401527107">@scaling01</a>）。評価は条件に敏感で、@eliebakouchはGPT‑5.1のMRCR数値に組織間で差異があることを発見し、後に異なるベンチマーク変種によるものと説明しました（<a href="https://twitter.com/eliebakouch/status/1999534955274117457">ノート</a>）。</li>
<li><strong>「推論努力」設定に注意</strong>：GPT‑5.2のハイライトの多くは、xhighの拡張思考（例：10万トークンの「思考」）に依存しており、結果が大きく変わる可能性があります（<a href="https://twitter.com/scaling01/status/1999535536130662576">@scaling01</a>）。例として、Extended NYT Connectionsは<strong>77.9（High）</strong>から<strong>89.3（xHigh）</strong>に跳ね上がります（<a href="https://twitter.com/LechMazur/status/1999582591905583256">@LechMazur</a>）。コミュニティの評価は、証明作成が大幅に改善されたという声（<a href="https://twitter.com/AcerFur/status/1999314476320063546">@AcerFur</a>）から、「Gemini 3 Proより明らかに優れているわけではない」という意見（<a href="https://twitter.com/scaling01/status/1999566015873569174">@scaling01</a>）まで幅があります。</li>
<li><strong>集計結果</strong>：EpochのECIではGPT‑5.2が<strong>152</strong>でGemini 3 Proに次ぐ2位。ECIからTime‑Horizonsへの投影では、5.2の中央値タスク持続時間は<strong>3.5時間</strong>、Gemini 3 Proは<strong>4.9時間</strong>、Opus 4.5は<strong>2.6時間</strong>です（<a href="https://twitter.com/EpochAIResearch/status/1999548496198926728">@EpochAIResearch</a>、<a href="https://twitter.com/EpochAIResearch/status/1999585243003781413">続報</a>）。<a href="https://twitter.com/sama/status/1999624463013544024">@sama</a>は、GPT‑5.2がAPIで初日に「1兆トークン」を超えたと述べ、急速な採用を強調しました。</li>
</ul>
<p><strong>オープンモデル、RLスケーリング、スパース化</strong></p>
<ul>
<li><strong>Allen AIのOlmo 3.1（32B）がオープンRLスケールを拡大</strong>：以前のRLジョブを3週間延長し、Olmo 3.1 Think 32BとInstruct 32Bを作成。約<strong>125,000 H100時間</strong>（約25万ドル）を投入し、AIMEやコーディングなど難易度の高い評価で継続的な向上を達成。中間チェックポイント、新しい7B数学/コードRL‑Zeroベースライン、大規模フィルタリング/嗜好データセットを公開しました（<a href="https://twitter.com/allen_ai/status/1999528336318509316">@allen_ai</a>、<a href="https://twitter.com/natolambert/status/1999528636085649532">@natolambert</a>）。結論：長期RLは未開拓であり、改善が続いています。</li>
<li><strong>OpenAIの回路スパース化</strong>：スパースな活性パターン/モデルの公開（huggingface.co/openai/circuit‑sparsity）がMoEとのトレードオフ議論を呼び、共有容量を持つ大規模スパース活性アーキテクチャが孤立したエキスパートより好ましいという意見もあります（<a href="https://twitter.com/_akhaliq/status/1999528833490239864">@_akhaliq</a>、<a href="https://twitter.com/teortaxesTex/status/1999559676866724272">解説</a>）。</li>
<li><strong>ローカル推論インフラ</strong>：MistralのDevstral‑2がOllamaとLM Studioに登場。GGUFビルド修正、MLXがApple Siliconで分散推論の高速化を追加（<a href="https://twitter.com/ollama/status/1999590723373662612">Ollama</a>、<a href="https://twitter.com/lmstudio/status/1999648656958296119">@lmstudio</a>、<a href="https://twitter.com/awnihannun/status/1999596403472105975">@awnihannun</a>）。llama.cppはOllama風のモデル管理を導入：GGUF自動検出、モデルごとのプロセス、LRUアンロード（<a href="https://twitter.com/victormustar/status/1999484435910263256">@victormustar</a>）。</li>
</ul>
<p><strong>エージェントプラットフォームとツール</strong></p>
<ul>
<li><strong>TinkerがフロンティアVLのファインチューニングを解放</strong>：TinkerがGAとなり、ビジョン入力をサポート。<strong>Qwen3‑VL‑235B</strong>のファインチューニング、Kimi K2 Thinking、OpenAI互換推論、簡易サンプリングを追加。Cookbook例も同梱（<a href="https://twitter.com/thinkymachines/status/1999543421631946888">発表</a>、<a href="https://twitter.com/dchaplot/status/1999543675765031289">@dchaplot</a>、<a href="https://twitter.com/rown/status/1999544121984245872">@rown</a>）。別のコミュニティフォークでは、Tinkerのトレーニングループにマルチターンツール使用のオンポリシー蒸留（トークン、ログ確率、報酬マスク）を追加し、シングルターンTRL/Tinkerベースラインを超えることを目指しています（<a href="https://twitter.com/HeMuyu0327/status/1999316923885191376">詳細</a>）。</li>
<li><strong>エージェント協調のガイドラインと可観測性</strong>：Googleは、マルチエージェントシステムが有効な場合と逆効果な場合の実践原則、および適切なエージェント構成を<strong>87%</strong>の確率で選択する予測フレームワークを提案（<a href="https://twitter.com/TheTuringPost/status/1999499042880127328">概要</a>、<a href="https://twitter.com/TheTuringPost/status/1999499191840817202">論文</a>）。LangChainは「Deep Agents」デバッグワークフローを公開し、トレース対応アシスタント（Polly）やCLIによるコーディングエージェントのデバッグ機能を追加。MCPアダプタはツールからの構造化コンテンツをサポート（<a href="https://twitter.com/LangChainAI/status/1999568074450829482">まとめ</a>、<a href="https://twitter.com/sydneyrunkle/status/1999538200243511725">MCP更新</a>）。また、ChatGPTはホストされたスキル用の/home/oai/skillsフォルダを表示するようになりました（<a href="https://twitter.com/simonw/status/1999503124592230780">@simonw</a>）。</li>
<li><strong>高速コーディングエージェント</strong>：CognitionはCerebras上で約<strong>1k tok/s</strong>でコーディングエージェントを実行し、フロンティアレベルの精度を達成（<a href="https://twitter.com/cerebras/status/1999540379553611955">@cerebras</a>）。GitHub/VS Codeはローカル・クラウド・バックグラウンド統合エージェントを披露（<a href="https://twitter.com/code/status/1999575448087396563">@code</a>）。</li>
</ul>
<p><strong>新技術と論文</strong></p>
<ul>
<li><strong>正規化不要のTransformer</strong>：「Derf」（Dynamic erf）は、正規化なしのTransformerを機能させ、正規化ありのベースラインを上回る単純なポイントワイズ層です（<a href="https://twitter.com/liuzhuang1234/status/1999321116641497355">@liuzhuang1234</a>）。</li>
<li><strong>推論のトークンレベルのクレジット割り当て</strong>：HICRAは「Strategic Grams」で特定された「計画トークン」にRL最適化を集中させ、GRPOよりAIME/AMC/オリンピックで改善（例：Qwen3‑4B‑Instruct AIME24 <strong>73.1% vs 68.5%</strong>）し、RL中の「aha」フェーズの機械的理解を提供します（<a href="https://twitter.com/omarsar0/status/1999483394963701911">スレッド</a>）。</li>
<li><strong>オリンピック幾何をエージェント＋RLで解く</strong>：InternGeometryは反復推論と「Complexity‑Boosting RL」でIMO問題50問中44問を解き、テストセットで金メダリストを上回ります（<a href="https://twitter.com/HuggingPapers/status/1999572332906438987">概要</a>）。</li>
<li><strong>事前学習済み視覚エンコーダを1層で適応</strong>：AppleのFAEは、画像生成用に視覚エンコーダを適応させるのに「1層で十分」であることを示します（<a href="https://twitter.com/_akhaliq/status/1999516539351883823">論文</a>）。</li>
<li><strong>動画モデルによるロボットシミュレーション</strong>：Veo‑RoboticsはGeminiロボティクスポリシーを動画世界シミュレーターで評価し、展開前に安全評価や失敗モード分析を可能にします（<a href="https://twitter.com/SeanKirmani/status/1999528692448657687">紹介</a>、<a href="https://twitter.com/Majumdar_Ani/status/1999525259276423569">GDMスレッド</a>）。</li>
</ul>
<p><strong>製品・リーダーボード更新</strong></p>
<ul>
<li><strong>動画・画像モデル</strong>：Runway Gen‑4.5が全プランで展開され、忠実度・制御性でコミュニティ最高評価を獲得（<a href="https://twitter.com/runwayml/status/1999481621326729530">@runwayml</a>）。Video ArenaはKling 2.6 Pro（前回比+16）とKandinsky 5.0（トップのオープンt2v）を追加（<a href="https://twitter.com/arena/status/1999530939886768205">Arena更新</a>）。Flux‑2‑DevがArenaのテキスト→画像/編集Top‑10入り（<a href="https://twitter.com/arena/status/1999560495867793881">画像更新</a>）。</li>
<li><strong>文書・データ処理</strong>：ByteDance OSSがMITライセンスのDolphin‑v2を公開。<strong>3B</strong>の文書理解モデルで、スキャンや写真、21種類のコンテンツタイプをピクセル座標付きで処理（<a href="https://twitter.com/AdinaYakup/status/1999462500551786692">@AdinaYakup</a>）。DatologyAIはLuxicalを公開。高速な語彙密度CPU埋め込みモデルとウェブスケールのキュレーションパイプライン手法を提供（<a href="https://twitter.com/lukemerrick_/status/1999516702808375791">紹介</a>、<a href="https://twitter.com/lukemerrick_/status/1999516722030870542">ブログ/コード/モデル</a>）。</li>
<li><strong>地理空間・翻訳</strong>：GeoAI QGISプラグインがMoondream VLM、SAM‑3セグメンテーション、DIY地理空間トレーニングをサポート（<a href="https://twitter.com/giswqs/status/1999536028282179721">@giswqs</a>）。GoogleはGemini音声を更新：Translate（ベータ）でライブ音声→音声、TTSの忠実度向上、Flash/Pro/Liveでの会話処理改善（<a href="https://twitter.com/GoogleAI/status/1999560839679082507">@GoogleAI</a>、<a href="https://twitter.com/googleaidevs/status/1999539531826036973">開発者</a>）、MapsからGeminiへの豊富なローカル結果追加（<a href="https://twitter.com/GeminiApp/status/1999631529379791121">@GeminiApp</a>）。</li>
</ul>
<p><strong>ベンチマーク：期待と現実</strong></p>
<ul>
<li><strong>「ベンチマークはすぐ陳腐化する」</strong>：有識者は有用なベンチマークの半減期は「数ヶ月単位」とし、動的環境、討論・説得、効率的推論など新タスクの必要性を訴えています（<a href="https://twitter.com/gdb/status/1999454952801075353">@gdb</a>、<a href="https://twitter.com/scaling01/status/1999321464319754290">@scaling01</a>）。MRCR v2の修正やセットアップ差異は、再現可能な長文コンテキスト評価の難しさを浮き彫りにしています（<a href="https://twitter.com/DillonUzar/status/1999328225164431394">@DillonUzar</a>、<a href="https://twitter.com/eliebakouch/status/1999482968717279441">@eliebakouch</a>）。Stirrupのようなマルチエージェント/エージェント的ハーネスが広がるにつれ、評価は精度だけでなくプロセス指向の指標、コスト、レイテンシも重視される見込みです（<a href="https://twitter.com/ArtificialAnlys/status/1999404589049872615">@ArtificialAnlys</a>）。</li>
</ul>
<p><strong>エンゲージメント上位ツイート</strong></p>
<ul>
<li><a href="https://twitter.com/NC_Renic/status/1999351657730290042">「AIで文章を書くと、本来の『書かない』という作家体験を奪ってしまう」</a>（約6万）– AI支援創作に関する皮肉な文化的コメント。</li>
<li><a href="https://twitter.com/RnaudBertrand/status/1999315488598622360">蘇蕙の4世紀「星ゲージ」組み合わせ詩</a>（約4.1万）– AIではないが、人間文学における深いアルゴリズム的芸術の例。</li>
<li><a href="https://twitter.com/scaling01/status/1999456392495923555">「これはひどいミーム…訓練が61,320倍遅くなる」</a>（約1.56万）– 推論時に訓練を行うという流行ネタへの反論。</li>
<li><a href="https://twitter.com/gdb/status/1999416686446019049">「エンタープライズAIは2026年の大きなテーマになる」</a>（約1.4千）– 近未来の採用動向に関する専門家のシグナル。</li>
</ul>
<hr />
<p>（以下、Reddit・Discordまとめは省略せず日本語化）</p>
<h1 id="ai-reddit">AI Redditまとめ</h1>
<h2 id="rlocalllama-rlocalllm">/r/LocalLlama + /r/localLLMまとめ</h2>
<h3 id="1-nvidia-nemotron">1. NVIDIA Nemotronモデルのリーク</h3>
<ul>
<li><a href="https://www.reddit.com/r/LocalLLaMA/comments/1pkpxss/someone_from_nvidia_made_a_big_mistake_and/"><strong>NVIDIAの関係者が誤って次期モデルの親フォルダをHugging Faceにアップロード</strong></a>（活動量: 1196）：画像には、NVIDIAが次期Nemotronモデルに関連するフォルダ（"NVIDIA-Nemotron-Nano-3-30B-A3B-BF16"や"Nemotron-H-4B-Instruct-128K"など）をHugging Faceリポジトリにアップロードした様子が写っています。これは未公開モデルデータの偶発的な露出を示唆しており、アップロードはhuggingface_hubツールでスクリーンショット撮影の数分前に行われたようです。NemotronモデルはNVIDIAの新ラインナップの一部であり、「30B-A3B」はモデルサイズや構成を示す可能性があり、AIモデル開発の進展を追う人々にとって重要です。コメントでは、データ削除の可能性やNemotronラインナップへの関心が示され、これらのモデルが有望視されていることがうかがえます。<ul>
<li>「30B-A3B」は300億パラメータのモデルを示す可能性があり、大規模かつ高性能な計算能力を持つことを意味します。これはNVIDIAが高度なAIアプリケーション向けに大規模モデルを開発する傾向と一致します。</li>
<li>「Nemotronラインナップ」という言及は、NVIDIAが複数のプロジェクトやモデルを戦略的に展開していることを示唆します。</li>
<li>Hugging Faceへの親フォルダ誤アップロードは、機密データ管理やアクセス制御の重要性を改めて浮き彫りにしています。</li>
</ul>
</li>
</ul>
<p>（以下略）</p>
<hr />
<h1 id="ai-discord">AI Discordまとめ</h1>
<blockquote>
<p>gpt-5.1による要約の要約</p>
</blockquote>
<p><strong>1. フロンティアモデル戦争：GPT‑5.2 vs Opus, Gemini, Kimi &amp; DeepSeek</strong></p>
<ul>
<li><strong>GPT‑5.2はベンチマークでは好成績も実務では不安定</strong>：LMArena、Cursor、Perplexity、OpenAI、Nous、OpenRouter、Windsurfなどで、GPT‑5.2は<a href="https://artificialanalysis.ai/">ARC‑AGI 2</a>などのリーダーボードで高得点を出し、SOTAコーディングモデルとして宣伝されていますが、創作や実務的コーディングではGPT‑5.1よりわずかに良い程度との声も。OpenRouterでは<strong>gpt‑5.2‑pro</strong>が「出力トークン100万あたり168ドル」と揶揄され、LMArenaやNousでは<strong>ベンチマーク過学習</strong>を疑う声も。CursorやOpenAI Discordでは依然としてClaude Opus 4.5や旧GPTを好む開発者が多いです。<ul>
<li>長期ツール使用やエージェント的コーディングでは優れる一方、画像解析の誤りや「プロフェッショナルモード」での機械的応答、高価格（5.1は100万トークン10ドル、5.2は14ドル）などが不満点として挙がっています。</li>
</ul>
</li>
<li><strong>OpusがコーディングでGPTを凌駕</strong>：LMArenaやCursorのエンジニアは、複雑なリファクタリングや大規模コード編集でClaude Opus 4.5を最優先に選び、Gemini 3も有力候補としています。OpenAIやPerplexityではGemini 3 Proが一発でコードタスクを解く例もあり、NousやYannickではDeepSeekが安価で強力な代替と評価されています。</li>
<li><strong>多言語特性と検閲がモデル選択に影響</strong>：Moonshot AIのKimiサーバーではClaude 4.5が時折中国語で思考するとの報告があり、MistralからKimiへ乗り換えるユーザーも。NousやBASI Jailbreakingでは政治的・倫理的に敏感なデータセット生成で安全壁に阻まれ、プロンプト改変で回避する事例もあります。</li>
</ul>
<p>（以下略）</p>
<hr />
<p>このように、全体としてGPT‑5.2はベンチマークでは強いものの、実務や創作では従来モデルや他社モデルに軍配が上がる場面が多く、コストや検閲ポリシーも選択の重要な要因となっています。</p>
    </main>

    <footer>
        <p>
            <a href="https://github.com/YIPG/ainews">GitHub</a>
            <a href="https://news.smol.ai/">news.smol.ai</a>
        </p>
    </footer>
</body>
</html>