<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>うちには Opus 4.5 があります | AIニュース</title>
    <meta name="description" content="うちには Opus 4.5 があります - AIニュース 2026-02-11。最新のAI技術動向を日本語でお届け。">
    <meta name="keywords" content="AI,人工知能,ニュースレター,2026-02-11,機械学習,深層学習,日本語">
    <meta name="author" content="AIニュース">
    <link rel="canonical" href="https://yipg.github.io/ainews/docs/newsletters/2026-02-11.html">
    
    <!-- Open Graph meta tags -->
    <meta property="og:title" content="うちには Opus 4.5 があります | AIニュース">
    <meta property="og:description" content="うちには Opus 4.5 があります - AIニュース 2026-02-11。最新のAI技術動向を日本語でお届け。">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://yipg.github.io/ainews/docs/newsletters/2026-02-11.html">
    <meta property="og:image" content="https://yipg.github.io/ainews/newsletters/og/2026-02-11.png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:image:type" content="image/png">
    <meta property="og:site_name" content="AIニュース">
    <meta property="og:locale" content="ja_JP">
    <meta property="article:published_time" content="2026-02-11T09:00:00+00:00">
    <meta property="article:author" content="AIニュース">
    <meta property="article:section" content="AI技術ニュース">
    
    <!-- Twitter Card meta tags -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="うちには Opus 4.5 があります | AIニュース">
    <meta name="twitter:description" content="うちには Opus 4.5 があります - AIニュース 2026-02-11。最新のAI技術動向を日本語でお届け。">
    <meta name="twitter:image" content="https://yipg.github.io/ainews/newsletters/og/2026-02-11.png">
    
    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>✏️</text></svg>">
    <link rel="alternate icon" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAACXBIWXMAAA7EAAAOxAGVKw4bAAAA">
    
    <!-- RSS Feed -->
    <link rel="alternate" type="application/rss+xml" title="AIニュース RSS Feed" href="../feed.xml">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: Verdana, Geneva, sans-serif;
            font-size: 1em;
            line-height: 1.7;
            letter-spacing: 0.02em;
            max-width: 720px;
            margin: 0 auto;
            padding: 20px;
            background-color: #fff;
            color: #111;
            word-wrap: break-word;
        }
        
        nav {
            margin-bottom: 25px;
            padding-bottom: 15px;
            border-bottom: 1px solid #ddd;
            display: flex;
            align-items: center;
            justify-content: space-between;
            flex-wrap: nowrap;
        }
        
        .site-title {
            font-size: 1.1em;
            font-weight: bold;
            color: #111;
            text-decoration: none;
            flex-shrink: 0;
        }
        
        .site-title:hover {
            text-decoration: underline;
        }
        
        .nav-links {
            font-size: 0.85em;
            white-space: nowrap;
        }
        
        .nav-links a {
            color: #111;
            text-decoration: none;
            margin-left: 12px;
        }
        
        .nav-links a:hover {
            text-decoration: underline;
        }
        
        
        h1, h2, h3, h4, h5, h6 {
            margin: 35px 0 20px 0;
            line-height: 1.3;
            color: #111;
            letter-spacing: 0.01em;
        }
        
        h1 { font-size: 1.5em; }
        h2 { font-size: 1.3em; }
        h3 { font-size: 1.1em; }
        
        p {
            margin: 20px 0;
        }
        
        a {
            color: #0969da;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin: 20px 0;
            padding-left: 30px;
        }
        
        li {
            margin: 8px 0;
        }
        
        blockquote {
            border-left: 3px solid #ccc;
            margin: 25px 0;
            padding: 0 25px;
            color: #555;
            font-style: italic;
        }
        
        code {
            background-color: #f6f8fa;
            padding: 2px 4px;
            border-radius: 3px;
            font-family: 'Courier New', Courier, monospace;
            font-size: 0.9em;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            padding: 20px;
            overflow-x: auto;
            margin: 25px 0;
        }
        
        pre code {
            background: none;
            padding: 0;
        }
        
        img {
            max-width: 100%;
            height: auto;
            margin: 25px 0;
            border-radius: 3px;
        }
        
        hr {
            border: none;
            border-top: 1px solid #ddd;
            margin: 35px 0;
        }
        
        footer {
            margin-top: 40px;
            padding-top: 15px;
            border-top: 1px solid #ddd;
            text-align: center;
            color: #555;
            font-size: 0.85em;
        }
        
        footer a {
            color: #555;
            text-decoration: none;
            margin: 0 8px;
        }
        
        footer a:hover {
            text-decoration: underline;
        }
        
        @media (max-width: 600px) {
            body {
                padding: 15px;
                font-size: 0.95em;
            }
            
            nav {
                flex-direction: column;
                align-items: flex-start;
                gap: 10px;
            }
            
            .nav-links {
                font-size: 0.8em;
            }
            
            .nav-links a {
                margin-left: 0;
                margin-right: 12px;
            }
            
            .article-title {
                font-size: 1.4em;
            }
        }
        
        @media (max-width: 480px) {
            body {
                font-size: 0.9em;
                padding: 12px;
            }
            
            .site-title {
                font-size: 1em;
            }
            
            .nav-links {
                font-size: 0.75em;
            }
            
            .article-title {
                font-size: 1.3em;
            }
        }
        
        @media (prefers-color-scheme: dark) {
            body {
                background-color: #111;
                color: #eee;
            }
            
            nav {
                border-bottom-color: #444;
            }
            
            .site-title, .nav-links a, .article-title, h1, h2, h3, h4, h5, h6 {
                color: #eee;
            }
            
            .article-date {
                color: #ccc;
            }
            
            blockquote {
                border-left-color: #555;
                color: #ccc;
            }
            
            code {
                background-color: #2d3748;
                color: #e2e8f0;
            }
            
            pre {
                background-color: #2d3748;
            }
            
            hr, footer {
                border-color: #444;
            }
            
            footer, footer a {
                color: #ccc;
            }
        }
    </style>
</head>
<body>
    <nav>
        <a href="../index.html" class="site-title">✏️ AIニュース</a>
        <div class="nav-links">
            <a href="../index.html">ホーム</a>
            <a href="./archive.html">アーカイブ</a>
            <a href="../feed.xml">RSS</a>
            <a href="https://github.com/YIPG/ainews">GitHub</a>
        </div>
    </nav>

    <main>
        <p><strong>うちには Opus 4.5 があります</strong></p>
<blockquote>
<p>AIニュース（2026年2月10日〜2月11日）。中国オープンモデル週間は現在進行中で、本日は Big Whale の前に Z.ai が大型アップデートを発表しました。詳細は <a href="https://z.ai/blog/glm-5">GLM-5 のブログ記事</a>によると以下の通りです。</p>
</blockquote>
<ul>
<li><strong>Opusクラスだが、<a href="https://news.smol.ai/issues/25-09-05-1t-models">Kimi や Qwen</a>のような1兆パラメータのスーパー・モデルではない</strong>。GLM-4.5と比較すると、GLM-5は355Bパラメータ（32Bアクティブ）から744Bパラメータ（40Bアクティブ）へスケールアップし、事前学習データは23兆トークンから28.5兆トークンに増加しています。<ul>
<li>GLM-5は<a href="https://news.smol.ai/issues/25-12-01-deepseek-32">DeepSeek Sparse Attention（DSA）</a>を統合し、長文コンテキスト能力を維持しながら展開コストを大幅に削減しています。</li>
</ul>
</li>
<li>社内コーディング評価や標準的なフロンティア評価で良好なスコアを記録し、特にBrowseCompで同業他社中SOTAを達成、<a href="https://andonlabs.com/evals/vending-bench-2">Vending Bench 2</a>ではトップのオープンモデルとされています。</li>
<li><a href="https://www.latent.space/p/ainews-moonshot-kimi-k25-beats-sonnet">Kimi K2.5</a>同様、PDF/Word/Excelなどのオフィス業務に注力していますが、派手さは控えめです。</li>
</ul>
<p><img alt="" src="https://substackcdn.com/image/fetch/$s_!E06s!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa53ffe01-36c6-4756-b40c-b004624413ce_2442x1712.png" /></p>
<p>しかし、GDPVal-AAという事実上の「ホワイトカラー業務」ベンチマークではKimi K2.5を上回っています。</p>
<p><a href="https://x.com/ArtificialAnlys/status/2021678229418066004/photo/1">articificial analysis</a></p>
<p><img alt="" src="https://substackcdn.com/image/fetch/$s_!oOz6!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8fb42dea-73b0-48fc-84f9-1345076c762e_3600x2072.png" /></p>
<p>Redditでの議論の大部分は、推論サービスにおける計算資源の制約に集中していました。</p>
<p><img alt="" src="https://substackcdn.com/image/fetch/$s_!lJUu!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9d403988-426e-4424-9796-028cfddf5786_1736x1770.png" /></p>
<hr />
<h1 id="ai-twitter">AI Twitterまとめ</h1>
<p><strong>Zhipu AIのGLM-5発表（Pony Alpha公開）と新たなオープンウェイトの最前線</strong></p>
<ul>
<li><strong>GLM-5の詳細（GLM-4.5からの変更点）</strong>：Zhipu AIは、これまで「ステルス」モデルとされていた<strong>Pony Alpha</strong>が<strong>GLM-5</strong>であることを発表し、「エージェント的エンジニアリング」と長期的タスク向けに位置づけました（<a href="https://twitter.com/Zai_org/status/2021638634739527773">Zai_org</a>; <a href="https://twitter.com/OpenRouterAI/status/2021639702789730631">OpenRouterAI</a>）。スケーリングは<strong>355B MoE / 32Bアクティブ</strong>（GLM-4.5）から<strong>744B / 40Bアクティブ</strong>へ、事前学習は<strong>23T → 28.5Tトークン</strong>へ拡大（<a href="https://twitter.com/Zai_org/status/2021638634739527773">Zai_org</a>）。主要なシステム改善として<strong>DeepSeek Sparse Attention</strong>を統合し、長文コンテキストの提供コストを削減（<a href="https://twitter.com/scaling01/status/2021627498451370331">scaling01</a>; <a href="https://twitter.com/lmsysorg/status/2021639499374375014">lmsysorg</a>）。コンテキスト/出力制限は<strong>200Kコンテキスト</strong>、<strong>128K最大出力</strong>とされています（<a href="https://twitter.com/scaling01/status/2021628691357298928">scaling01</a>）。</li>
<li><strong>利用可能性と「計算資源不足」の現実</strong>：GLM-5はOpenRouter、Modal（期間限定無料エンドポイント）、DeepInfra、Ollama Cloudなどで即日提供され、IDEやエージェントツールにも統合されています（例：Qoder, Vercel AI Gateway）。Zhipuは提供能力が制約されていることを明言し、「Coding Plan Pro」以外への展開を遅らせ、価格変更を行っています。</li>
<li><strong>ベンチマークと第三者評価</strong>：Artificial Analysisによると、GLM-5は同社のIntelligence Indexでスコア50を獲得し、オープンウェイトモデルの新たなトップと評価されています。GDPval-AA ELOは1412で、Opus 4.6とGPT-5.2 xhighに次ぐ順位。幻覚率も最低値を記録。BF16形式（約1.5TB）での提供は、FP8やINT4で提供されるモデルに比べてセルフホスティングの負担が大きいと指摘されています。</li>
<li><strong>ライセンスとエコシステム統合</strong>：MITライセンスで公開され、vLLMやSGLangなど主要推論スタックで即日サポート。Hugging FaceやModelScopeでも配布されています。GLM-5はビジョン機能を持たない点やBF16から量子化への変換によるランキング変動の可能性も議論されています。</li>
<li><strong>オープンリーダーボードでの躍進</strong>：GLM-5はText Arenaでオープンモデル中1位（全体で11位）を獲得。中国発のオープンエコシステムの加速を示す事例として、DeepSeekやMiniMaxとの競争が「血戦」と形容されています。</li>
</ul>
<hr />
<p><strong>DeepSeek「V4-lite」／1Mコンテキスト展開、アテンション技術の差別化、推論スタック改善</strong></p>
<ul>
<li><strong>実際に何が公開されたか</strong>：DeepSeekはチャット体験を1Mコンテキストに更新（2025年5月カットオフ）。初期はV4と推測されましたが、モデルは明言せず、アプリとAPIで展開が不均一。後に「V4 Liteが稼働、1Mコンテキスト、テキストのみ、Muon＋mHC確認、大型版は後日」との具体的情報が出ています。</li>
<li><strong>アテンションのアップグレードが真の節目</strong>：DeepSeekは長文コンテキストでの能動的挙動が可能で、単なる検索ではなく文脈を「生きる」ような動作をすると評価されています。これは成熟したSparse Attentionのアプローチに近いと推測されています。</li>
<li><strong>スループットの課題（MLA＋TP）</strong>：MLAモデルでKVヘッドが1つの場合、単純なテンソル並列はKVキャッシュを冗長に複製しメモリを浪費します。SGLangはこれを解消するDP Attention（DPA）を導入し、スループット92％向上、キャッシュヒット率275％改善を達成しました。</li>
<li><strong>DeepSeekのオープンMoEレシピへの影響</strong>：Sparse MoEやMLA、Sparse Attentionの実運用、GRPOなどの技術がほぼ全ての最前線オープンLLMに影響を与えていると評価されています。</li>
</ul>
<hr />
<p><strong>MiniMax M2.5／StepFun／Qwen：高速コーディングモデル、コスト圧力、ベンチマーク競争</strong></p>
<ul>
<li><strong>MiniMax 2.5の投入とエージェント展開</strong>：MiniMaxはM2.5を発表し、同社のエージェントアプリやパートナー経由で提供開始。計算資源投入と出荷タイミングのトレードオフを強調しています。</li>
<li><strong>StepFun-Flash-3.5</strong>：MathArenaで1位を獲得。高い速度とアクティブパラメータ数に対する性能が評価されています。</li>
<li><strong>Qwen Imageのバグ修正＋Qwen3-Coder-Next</strong>：Qwen-Image 2.0で古典詩の順序や編集時の文字整合性を修正。Qwen3-Coder-Next（80B）はSWE-Bench Verifiedで70.6％、リポジトリ単位のワークフローで10倍のスループットを達成とされています。</li>
<li><strong>コスト／レイテンシの優位性</strong>：中国の研究所は約90％の性能を1/5〜1/10の価格で提供可能とされ、特にコーディング分野で市場シェアを変える可能性があります。</li>
</ul>
<hr />
<p><strong>動画生成の衝撃波：SeeDance v2、PixVerse R1、IP制約の構造的優位性</strong></p>
<ul>
<li><strong>SeeDance v2.0が際立つ存在</strong>：コミュニティはSeeDance v2.0の品質に驚愕。「不気味の谷を超えた」「テキストから動画のチューリングテスト」と評されています。BytePlusで一時的に停止もあり。</li>
<li><strong>動画推論テスト</strong>：SeeDanceとVeoを比較し、SeeDanceは5手程度の一貫した動きを維持、Veoは1〜2手と報告されています。</li>
<li><strong>構造的説明：学習データ／IP</strong>：中国モデルはIP制約が少ないため、生成メディア分野で構造的優位性があるとの議論があります。</li>
<li><strong>PixVerse R1</strong>：720Pのリアルタイムインタラクティブ世界生成を謳い、オフライン映画的クリップとは異なるカテゴリーを示しています。</li>
</ul>
<hr />
<p><strong>エージェント、コーディングワークフロー、新しい「可塑的ソフトウェア」ツールチェーン</strong></p>
<ul>
<li><strong>Karpathyの「エージェントでコードを切り出す」ワークフロー</strong>：DeepWiki MCP＋GitHub CLIを使い、必要な実装だけを抽出して依存関係を削除し、速度向上も確認。</li>
<li><strong>OpenAI：ハーネス設計と長時間ワークフロー</strong>：OpenAI DevRelはCodexを使い1500件のPRを手動コーディングなしで出荷した事例を紹介。長時間ワークフローの安定実行方法も公開。</li>
<li><strong>人間中心のコーディングエージェント</strong>：自律性よりも人間の能力を強化する方向に焦点を当てるべきとの意見。</li>
<li><strong>サンドボックス設計論争</strong>：エージェントをサンドボックス内に置くか、サンドボックスをツールとして使うかという設計選択が議論されています。</li>
<li><strong>mini-SWE-agent 2.0</strong>：100行程度の最小限のコーディングエージェントを公開、監査可能なハーネスへの志向を示しています。</li>
<li><strong>開発者ツールの現実</strong>：モデル品質が高くても、ターミナルUXやレート制限など製品品質の低さが課題として浮上しています。</li>
</ul>
<hr />
<p><strong>計測・評価・安全性：ベンチマーク、可観測性、エージェントのセキュリティギャップ</strong></p>
<ul>
<li><strong>300万ドルのオープンベンチマーク助成金</strong>：Snorkelらが評価ギャップを埋めるための助成金を発表。</li>
<li><strong>エージェント可観測性を評価基盤に</strong>：LangChainはトレースを真実のソースと位置づけ、従来のログとの違いを説明。</li>
<li><strong>安全評価の論争（コンピュータ利用エージェント）</strong>：AnthropicのOpus 4.6安全性評価とRedTeamCUAの結果が大きく乖離し、能力不足が低ASRの原因となっている可能性が指摘されています。</li>
</ul>
<hr />
<h3 id="_1">エンゲージメント上位ツイート</h3>
<ul>
<li><strong>GLM-5発表</strong>：<a href="https://twitter.com/Zai_org/status/2021638634739527773">@Zai_org</a>（モデル公開／仕様）、<a href="https://twitter.com/Zai_org/status/2021564343029203032">@Zai_org</a>（新モデル稼働）、<a href="https://twitter.com/Zai_org/status/2021656633320018365">@Zai_org</a>（計算資源制約）</li>
<li><strong>エージェントによるソフトウェア可塑性</strong>：<a href="https://twitter.com/karpathy/status/2021633574089416993">@karpathy</a></li>
<li><strong>Codexの影響物語</strong>：<a href="https://twitter.com/sama/status/2021606985469211065">@sama</a>、<a href="https://twitter.com/OpenAIDevs/status/2021637918847381656">@OpenAIDevs</a></li>
<li><strong>中国／オープンモデル「リリースラッシュ」感</strong>：<a href="https://twitter.com/paulbz/status/2021537295883481437">@paulbz</a>、<a href="https://twitter.com/scaling01/status/2021562929728885166">@scaling01</a>、<a href="https://twitter.com/SkylerMiao7/status/2021587213230715306">@SkylerMiao7</a></li>
<li><strong>SeeDance v2「動画の瞬間」</strong>：<a href="https://twitter.com/kimmonismus/status/2021604639557464134">@kimmonismus</a>、<a href="https://twitter.com/TomLikesRobots/status/2021504992268492814">@TomLikesRobots</a></li>
</ul>
    </main>

    <footer>
        <p>
            <a href="https://github.com/YIPG/ainews">GitHub</a>
            <a href="https://news.smol.ai/">news.smol.ai</a>
        </p>
    </footer>
</body>
</html>