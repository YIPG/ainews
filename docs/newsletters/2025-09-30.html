<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>あなたの顔がすべてです。 | AIニュース</title>
    <meta name="description" content="あなたの顔がすべてです。 - AIニュース 2025-09-30。最新のAI技術動向を日本語でお届け。">
    <meta name="keywords" content="AI,人工知能,ニュースレター,2025-09-30,機械学習,深層学習,日本語">
    <meta name="author" content="AIニュース">
    <link rel="canonical" href="https://yipg.github.io/ainews/docs/newsletters/2025-09-30.html">
    
    <!-- Open Graph meta tags -->
    <meta property="og:title" content="あなたの顔がすべてです。 | AIニュース">
    <meta property="og:description" content="あなたの顔がすべてです。 - AIニュース 2025-09-30。最新のAI技術動向を日本語でお届け。">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://yipg.github.io/ainews/docs/newsletters/2025-09-30.html">
    <meta property="og:image" content="https://yipg.github.io/ainews/newsletters/og/2025-09-30.png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:image:type" content="image/png">
    <meta property="og:site_name" content="AIニュース">
    <meta property="og:locale" content="ja_JP">
    <meta property="article:published_time" content="2025-09-30T09:00:00+00:00">
    <meta property="article:author" content="AIニュース">
    <meta property="article:section" content="AI技術ニュース">
    
    <!-- Twitter Card meta tags -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="あなたの顔がすべてです。 | AIニュース">
    <meta name="twitter:description" content="あなたの顔がすべてです。 - AIニュース 2025-09-30。最新のAI技術動向を日本語でお届け。">
    <meta name="twitter:image" content="https://yipg.github.io/ainews/newsletters/og/2025-09-30.png">
    
    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>✏️</text></svg>">
    <link rel="alternate icon" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAACXBIWXMAAA7EAAAOxAGVKw4bAAAA">
    
    <!-- RSS Feed -->
    <link rel="alternate" type="application/rss+xml" title="AIニュース RSS Feed" href="../feed.xml">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: Verdana, Geneva, sans-serif;
            font-size: 1em;
            line-height: 1.7;
            letter-spacing: 0.02em;
            max-width: 720px;
            margin: 0 auto;
            padding: 20px;
            background-color: #fff;
            color: #111;
            word-wrap: break-word;
        }
        
        nav {
            margin-bottom: 25px;
            padding-bottom: 15px;
            border-bottom: 1px solid #ddd;
            display: flex;
            align-items: center;
            justify-content: space-between;
            flex-wrap: nowrap;
        }
        
        .site-title {
            font-size: 1.1em;
            font-weight: bold;
            color: #111;
            text-decoration: none;
            flex-shrink: 0;
        }
        
        .site-title:hover {
            text-decoration: underline;
        }
        
        .nav-links {
            font-size: 0.85em;
            white-space: nowrap;
        }
        
        .nav-links a {
            color: #111;
            text-decoration: none;
            margin-left: 12px;
        }
        
        .nav-links a:hover {
            text-decoration: underline;
        }
        
        
        h1, h2, h3, h4, h5, h6 {
            margin: 35px 0 20px 0;
            line-height: 1.3;
            color: #111;
            letter-spacing: 0.01em;
        }
        
        h1 { font-size: 1.5em; }
        h2 { font-size: 1.3em; }
        h3 { font-size: 1.1em; }
        
        p {
            margin: 20px 0;
        }
        
        a {
            color: #0969da;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin: 20px 0;
            padding-left: 30px;
        }
        
        li {
            margin: 8px 0;
        }
        
        blockquote {
            border-left: 3px solid #ccc;
            margin: 25px 0;
            padding: 0 25px;
            color: #555;
            font-style: italic;
        }
        
        code {
            background-color: #f6f8fa;
            padding: 2px 4px;
            border-radius: 3px;
            font-family: 'Courier New', Courier, monospace;
            font-size: 0.9em;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            padding: 20px;
            overflow-x: auto;
            margin: 25px 0;
        }
        
        pre code {
            background: none;
            padding: 0;
        }
        
        img {
            max-width: 100%;
            height: auto;
            margin: 25px 0;
            border-radius: 3px;
        }
        
        hr {
            border: none;
            border-top: 1px solid #ddd;
            margin: 35px 0;
        }
        
        footer {
            margin-top: 40px;
            padding-top: 15px;
            border-top: 1px solid #ddd;
            text-align: center;
            color: #555;
            font-size: 0.85em;
        }
        
        footer a {
            color: #555;
            text-decoration: none;
            margin: 0 8px;
        }
        
        footer a:hover {
            text-decoration: underline;
        }
        
        @media (max-width: 600px) {
            body {
                padding: 15px;
                font-size: 0.95em;
            }
            
            nav {
                flex-direction: column;
                align-items: flex-start;
                gap: 10px;
            }
            
            .nav-links {
                font-size: 0.8em;
            }
            
            .nav-links a {
                margin-left: 0;
                margin-right: 12px;
            }
            
            .article-title {
                font-size: 1.4em;
            }
        }
        
        @media (max-width: 480px) {
            body {
                font-size: 0.9em;
                padding: 12px;
            }
            
            .site-title {
                font-size: 1em;
            }
            
            .nav-links {
                font-size: 0.75em;
            }
            
            .article-title {
                font-size: 1.3em;
            }
        }
        
        @media (prefers-color-scheme: dark) {
            body {
                background-color: #111;
                color: #eee;
            }
            
            nav {
                border-bottom-color: #444;
            }
            
            .site-title, .nav-links a, .article-title, h1, h2, h3, h4, h5, h6 {
                color: #eee;
            }
            
            .article-date {
                color: #ccc;
            }
            
            blockquote {
                border-left-color: #555;
                color: #ccc;
            }
            
            code {
                background-color: #2d3748;
                color: #e2e8f0;
            }
            
            pre {
                background-color: #2d3748;
            }
            
            hr, footer {
                border-color: #444;
            }
            
            footer, footer a {
                color: #ccc;
            }
        }
    </style>
</head>
<body>
    <nav>
        <a href="../index.html" class="site-title">✏️ AIニュース</a>
        <div class="nav-links">
            <a href="../index.html">ホーム</a>
            <a href="./archive.html">アーカイブ</a>
            <a href="../feed.xml">RSS</a>
            <a href="https://github.com/YIPG/ainews">GitHub</a>
        </div>
    </nav>

    <main>
        <p><strong>あなたの顔がすべてです。</strong></p>
<p>Sora発表から1年半、Sora.comが一般公開されてから10か月が経過し、Metaが物議を醸す「Vibes」アプリを発表してから4日後、Sora 2（<a href="https://x.com/apples_jimmy/status/1972756684297978256?s=46">リーク情報</a>）が本日リリースされ、<a href="https://x.com/anuatluru/status/1973125101047451830">好意的な反応</a>を得ています（ただしHNのアップボート数では<a href="https://news.ycombinator.com/item?id=39386156">Sora 1の約7分の1</a>）。</p>
<p><a href="https://openai.com/index/sora-2/">Sora 2</a>は、Sora 1時代の動画モデルで早期に発見された物理世界に関する問題（体操やフィギュアスケートの演技など）を改善しています。</p>
<p>ブログ記事では「暗黙的」モデルに言及しており、<a href="https://news.smol.ai/issues/25-08-05-gpt-oss">Genieの研究</a>から多くが推測していたような明示的な世界モデルはまだありません。しかし、<a href="https://x.com/elder_plinius/status/1973124528680345871">ビデオゲーム</a>や<a href="https://x.com/jesperengelen/status/1973147038499086523">ブラウザ出力</a>でのトレーニングが行われていることは確かです。</p>
<p>「ネイティブ音声付き動画」機能は既に<a href="https://youtu.be/hlcAZ2lX_ZI">Veo 3</a>が数か月前から備えていますが、Sora 2の目玉機能の一つは、単一のデモ動画から「<strong>現実世界の要素をSora 2に注入する</strong>」能力です。OpenAIの社員たちはこの機能を楽しんでいる様子です。</p>
<p><a href="https://blog.samaltman.com/sora-2">Sam Altmanのブログ</a>では、この機能を「キャラクターの一貫性」と呼んでいます。</p>
<p>この機能とモデルは、新しい<a href="https://apps.apple.com/app/id6744034028">Sora iOSアプリ</a>と<a href="https://sora.com/">ウェブサイト</a>に製品化され、現在は招待コード制で提供されています。「カメオ」機能が新しい<strong>Soraソーシャルネットワーク</strong>の中心的役割を担っています。</p>
<p>今年初めに<a href="https://www.theverge.com/openai/648130/openai-social-network-x-competitor">Samaが約束した</a>通り、新しいSoraアプリにはプロフィール、フォロワー数、DM機能があり、既に<a href="https://x.com/GabrielPeterss4/status/1973120058907041902">最初のバイラル動画</a>も登場しています。</p>
<p>チーム（および<a href="https://x.com/willdepue/status/1973089331284681110">元メンバー</a>）は<a href="https://www.youtube.com/watch?v=gzneGhpXwjU">ライブ配信</a>で、反スクロール依存タイムアウトなどの安全対策について説明しました。</p>
<p>カメオはオンボーディング時に自分でアップロードする動画で、他者が自分の肖像を使用できるかどうかの許可設定が可能です。特筆すべきは、<a href="https://x.com/GabrielPeterss4/status/1973071380842229781">Sam Altmanの肖像</a>が誰でも使用可能な点で、今後数日間はソーシャルフィードでSamのディープフェイクを多く目にすることになるでしょう。</p>
<hr />
<h1 id="ai-twitter">AI Twitterまとめ</h1>
<p><strong>AnthropicのClaude Sonnet 4.5：能力、コーディング、初期評価</strong></p>
<ul>
<li><strong>Claude 4.5 Sonnet（200Kコンテキスト、最大出力64K）</strong>：Anthropicのアップグレードは、Sonnet 4と同価格（入力/出力100万トークンあたり$3/$15）で知能を向上させ、「Thinking」モードでもトークン効率が改善されています。Artificial Analysisによる独立評価では、GPT‑5-highに次ぎ、Gemini 2.5 ProやGrok 4 Fastを上回り、出力トークンの節約が顕著です。エージェント的ツール利用や安全性・アラインメント行動の向上も報告されています（<a href="https://twitter.com/ArtificialAnlys/status/1972854742167761204">スレッド</a>）。ARC‑AGIでは、Sonnet 4.5は高い思考予算でGPT‑5に近い性能を示しています（<a href="https://twitter.com/GregKamradt/status/1973081243907399962">@GregKamradt</a>、<a href="https://twitter.com/scaling01/status/1973081750189334587">解説</a>）。ユーザーからは「状態管理」やコンテキスト圧縮が際立ち、長いエージェント的ワークフローの信頼性が向上したとの報告があります（<a href="https://twitter.com/nickbaumann_/status/1972838170493628847">@nickbaumann_</a>、<a href="https://twitter.com/skirano/status/1973026387528458451">@skirano</a>）。LangSmithのコスト追跡やプレイグラウンド、ARC Prize結果、LiveBenchやDeep Research Benchでの強いコーディング・数学性能など、エコシステム対応も迅速です（<a href="https://twitter.com/scaling01/status/1973088409359982623">1</a>、<a href="https://twitter.com/scaling01/status/1973088829138460987">2</a>）。</li>
<li><strong>Claude Code 2とエージェントスタック</strong>：AnthropicはClaude Code v2、VS Code拡張の更新、コンテキスト編集やメモリツールを提供しました（<a href="https://twitter.com/latentspacepod/status/1973017487190139140">ローンチまとめ</a>）。ReplitはSonnet 4.5がAgent 3でのコード編集や自律性を向上させたと報告しています（<a href="https://twitter.com/pirroh/status/1972805643691266111">@pirroh</a>）。Anthropicはエージェントシステム向けの「コンテキストエンジニアリング」に関する技術ブログも公開しました（<a href="https://twitter.com/AnthropicAI/status/1973098580060631341">@AnthropicAI</a>）。</li>
</ul>
<p><strong>ZhipuのGLM‑4.6（オープンウェイト）とエージェント的コーディング強化</strong></p>
<ul>
<li><strong>GLM‑4.6リリース（MITライセンス）</strong>：ZhipuはGLM‑4.5系を拡張し、200Kコンテキスト、強化されたコーディング、推論・ツール利用の改善、エージェントタスク成功率の向上を実現しました。4.5比で約15%少ないトークンで軌跡を生成します。ZhipuはCC‑Bench‑V1.1（74の実世界エージェント的コーディングタスク）を公開し、GLM‑4.6がコーディングでClaude Sonnet 4にほぼ並び、国内競合を上回ることを示しました（<a href="https://twitter.com/Zai_org/status/1973034639708344767">@Zai_org</a>、<a href="https://twitter.com/Zai_org/status/1973034644091392002">ベンチ</a>、分析：<a href="https://twitter.com/gm8xx8/status/1972951657542545619"> @gm8xx8</a>）。オープンウェイトとAPIは公開済みで、HFやModelScopeでのホスティングも予定されています。</li>
<li><strong>エコシステム採用</strong>：OpenRouter（<a href="https://twitter.com/OpenRouterAI/status/1973037695774384352">@OpenRouterAI</a>）、Yupp（<a href="https://twitter.com/yupp_ai/status/1972994220144427266">@yupp_ai</a>）、YouWare（<a href="https://twitter.com/YouWareAI/status/1972990785428811923">@YouWareAI</a>）、Roo Code（<a href="https://twitter.com/roo_code/status/1973022454298837294">@roo_code</a>）、Cline（<a href="https://twitter.com/cline/status/1973099598903386227">@cline</a>）、Anycoder（<a href="https://twitter.com/_akhaliq/status/1973068098539593932">@_akhaliq</a>）などで利用可能です。ローカルでは、MLXがM3 UltraでGLM‑4.6を約17トークン/秒で動作させています（5.5 bpw量子化、5.3Kトークン）（<a href="https://twitter.com/awnihannun/status/1973063906341114327">@awnihannun</a>）。</li>
</ul>
<p><strong>フロンティア動画モデル：Sora 2のローンチと初期比較</strong></p>
<ul>
<li><strong>OpenAI Sora 2とアプリ</strong>：OpenAIはSora 2をiOSアプリ（米国・カナダで招待制）と共にリリースしました。カメオ機能（同意管理、透かし）、システムカードを備え、Android版やAPIも予定されています。物理・操作性・音声が改善された「世界シミュレーション」デモを強調し、アルゴリズムフィードやディープフェイクのリスクも認めています（<a href="https://twitter.com/OpenAI/status/1973087446469406732">製品投稿</a>、<a href="https://twitter.com/OpenAI/status/1973071069016641829">ティーザー</a>、<a href="https://twitter.com/sama/status/1973073987023352250">Sam Altmanのコメント</a>）。反応は賛否両論で、リアリズムや一貫性を評価する声もあれば、アーティファクトやGoogleのVeo 3の競争力を指摘する声もあります（<a href="https://twitter.com/mattshumer_/status/1973077933481677245">肯定的意見</a>、<a href="https://twitter.com/scaling01/status/1973076175342756152">懐疑的意見</a>、<a href="https://twitter.com/OpenAI/status/1973143639200243959">物理デモ</a>）。</li>
<li><strong>Luma Ray 3</strong>：Lumaの新しいRay 3はArtificial AnalysisのT2V Video Arenaで2位にランクインし、反復的な思考連鎖生成ループと16ビットHDR対応を導入しました（I2V/T2Vで最大10秒1080p）。APIは未提供です（<a href="https://twitter.com/ArtificialAnlys/status/1973077941161734566">@ArtificialAnlys</a>）。</li>
</ul>
<p><strong>トレーニング効率と事後学習：FP4、QAT、事前学習中のRL</strong></p>
<ul>
<li><strong>NVFP4（NVIDIA）</strong>：4ビット事前学習で2段階スケーリング、RHT、確率的丸めを使用し、12Bモデルを10Tトークンで訓練した場合、FP8ベースラインと同等の性能（MMLU‑Pro 62.58 vs 62.62）を達成しました。約6.8倍の効率と約50%のメモリ削減を実現します。BlackwellはFP4 matmulと必要な丸めモードをサポートします（<a href="https://twitter.com/arankomatsuzaki/status/1972869149102858441">論文/コード</a>、<a href="https://twitter.com/rohanpaul_ai/status/1973017414011932791">概要</a>）。オープンソースTE対応は進行中です。</li>
<li><strong>Compute-Optimal QAT（Apple）</strong>：トークン数やメモリに応じて量子化対応学習（QAT）とフル精度の予算配分を行うスケーリング法則を提案し、QATをトレーニングスケジュールの主要要素として計画するための実践的ガイドを提供しています（<a href="https://twitter.com/aldrmv/status/1972850288731234476">@aldrmv</a>、<a href="https://twitter.com/awnihannun/status/1972860094439391384">@awnihannun</a>）。</li>
<li><strong>RLP（NVIDIA）</strong>：検証器不要の密な情報利得報酬を用いて、予測前に「考える」ことをモデルに教える事前学習手法です。ウェブテキストでの学習により、ベースモデル比で大幅な性能向上（例：Qwen3‑1.7Bで+19%、Nemotron‑Nano‑12Bで+35%）を達成し、事後学習と組み合わせることで効果が増します（<a href="https://twitter.com/shrimai_/status/1973113867455832096">論文/ブログ</a>）。</li>
</ul>
<p><strong>ユーザーからの学習とエージェントメモリ</strong></p>
<ul>
<li><strong>RLHI（Meta）</strong>：自然なユーザー会話から直接学習する強化学習手法で、ユーザー主導の書き換えや報酬を活用します。パーソナライズや指示遵守でベースラインを上回り、標準ベンチマーク性能も維持します（<a href="https://twitter.com/jaseweston/status/1972851921255051489">@jaseweston</a>、<a href="https://twitter.com/arankomatsuzaki/status/1972873547933782160">論文</a>）。</li>
<li><strong>ReasoningBank（エージェント）</strong>：成功と失敗の両方から抽出した戦略を保存し、再利用と効率を改善するメモリシステムです。ウェブやSWEタスクで+34.2%の効率向上、ステップ数16%削減を報告しています（<a href="https://twitter.com/arankomatsuzaki/status/1972870229463355677">ツイート</a>）。</li>
<li><strong>効率的なシーケンスモデル</strong>：SWAXはスライディングウィンドウ注意機構とxLSTM、確率的ウィンドウサイズを組み合わせ、短期・長期の記憶を向上させます（<a href="https://twitter.com/arankomatsuzaki/status/1972874639333605540">ツイート</a>）。拡散LM向けにはSparseDが疎注意を提案し（1.3–1.5倍高速、ほぼ損失なし）、LLaDA‑MoE（疎MoE dLLM）は拡散LLMの中で最先端性能を報告しています（<a href="https://twitter.com/_akhaliq/status/1972906913739555220">SparseD</a>、<a href="https://twitter.com/iScienceLuvr/status/1972971896036851767">LLaDA‑MoE</a>）。最後に、MobileLLM‑R1は10億未満のパラメータ（950M）でAIME 15.5を達成し、約2Tトークンの精選データと標準的事後学習を使用しています（<a href="https://twitter.com/iScienceLuvr/status/1972973249148617081">ツイート</a>）。</li>
</ul>
<p><strong>エージェント的コーディングスタックとインフラ</strong></p>
<ul>
<li><strong>ローカルおよびホスト型エージェントスタック</strong>：AMDはCline + LM Studioによるローカル「vibe coding」を推奨し、高RAM環境向けにQwen3‑Coder‑30B（4/8ビット）やGLM‑4.5‑Airを推奨しています（<a href="https://twitter.com/cline/status/1973035211379310708">@cline</a>）。AI SDKは任意のHFモデルへのルーティングに対応しました（<a href="https://twitter.com/nishimiya/status/1973032330479669462">@nishimiya</a>）。Cursor 1.7はプロンプト提案や組織全体のルールを追加しました（<a href="https://twitter.com/cursor_ai/status/1973093532282851837">@cursor_ai</a>）。SimはMCP統合を備えた完全ローカル・オープンソースのドラッグ＆ドロップ型エージェントワークフロー構築ツールを公開しました（<a href="https://twitter.com/_avichawla/status/1972912060230164732">スレッド</a>）。</li>
<li><strong>Codex vs Claude Codeの運用選択</strong>：OpenAI Codex CLIのシェル優先ループ（think→tool→observe）、エラー範囲を減らす統一diff、OSレベルのサンドボックス化などが強調されています（<a href="https://twitter.com/imjaredz/status/1973035370041532685">分析</a>）。一方、GitHub MCP RegistryやClaude拡張はVS Codeで成熟を続けています（<a href="https://twitter.com/code/status/1972800559489876276">@code</a>、<a href="https://twitter.com/gallabytes/status/1972805892610617466">@gallabytes</a>）。</li>
</ul>
<hr />
<p><strong>Periodic Labs：AI科学者＋自律型ラボ</strong></p>
<ul>
<li>Liam FedusとDoğuş Ekinが率いるPeriodicは、a16z主導で3億ドルの資金調達を行い、検証可能な実験駆動型科学のためのAI科学者と自律型ラボを構築します。対象は材料（例：超伝導体）や半導体の進歩です。チームにはChatGPT、GNoME、attention、MatterGen、スケーラブルな自律型物理ラボの開発経験者が含まれます（<a href="https://twitter.com/LiamFedus/status/1973055380193431965">ローンチ</a>、<a href="https://twitter.com/a16z/status/1973057267286098131">a16z</a>）。彼らの主張は、インターネットテキストは有限であり、進歩には新しい高信号の実験データと閉ループ検証が必要だというものです。</li>
</ul>
<hr />
<p><strong>トップツイート（エンゲージメント順）</strong></p>
<ul>
<li>「Sound on.」Sora 2ティーザー（<a href="https://twitter.com/OpenAI/status/1973071069016641829">@OpenAI</a>、約34K）</li>
<li>Sora 2ローンチ（<a href="https://twitter.com/OpenAI/status/1973075422058623274">@OpenAI</a>、約12.7K）</li>
<li>「10am PT」事前ティーザー（<a href="https://twitter.com/OpenAI/status/1973055265084690780">@OpenAI</a>、約6.6K）</li>
<li>「新しいアプリSoraをローンチします。」（<a href="https://twitter.com/sama/status/1973073987023352250">@sama</a>、約6.7K）</li>
<li>Soraアプリデモ（<a href="https://twitter.com/OpenAI/status/1973087446469406732">@OpenAI</a>、約4.6K）</li>
<li>「Claude Sonnet 4.5で構築」チャレンジ（<a href="https://twitter.com/alexalbert__/status/1973071320025014306">@alexalbert__</a>、約1.2K）</li>
<li>Bolt v2「vibe coding goes pro」（<a href="https://twitter.com/boltdotnew/status/1973063093849567591">@boltdotnew</a>、約1.3K）</li>
<li>Periodic Labsローンチ（<a href="https://twitter.com/LiamFedus/status/1973055380193431965">@LiamFedus</a>、約2.9K）</li>
</ul>
    </main>

    <footer>
        <p>
            <a href="https://github.com/YIPG/ainews">GitHub</a>
            <a href="https://news.smol.ai/">news.smol.ai</a>
        </p>
    </footer>
</body>
</html>