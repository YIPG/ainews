<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gemini がすべてを制す | AIニュース</title>
    <meta name="description" content="Gemini がすべてを制す - AIニュース 2025-08-26。最新のAI技術動向を日本語でお届け。">
    <meta name="keywords" content="AI,人工知能,ニュースレター,2025-08-26,機械学習,深層学習,日本語">
    <meta name="author" content="AIニュース">
    <link rel="canonical" href="https://yipg.github.io/ainews/docs/newsletters/2025-08-26.html">
    
    <!-- Open Graph meta tags -->
    <meta property="og:title" content="Gemini がすべてを制す | AIニュース">
    <meta property="og:description" content="Gemini がすべてを制す - AIニュース 2025-08-26。最新のAI技術動向を日本語でお届け。">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://yipg.github.io/ainews/docs/newsletters/2025-08-26.html">
    <meta property="og:image" content="https://yipg.github.io/ainews/newsletters/og/2025-08-26.png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:image:type" content="image/png">
    <meta property="og:site_name" content="AIニュース">
    <meta property="og:locale" content="ja_JP">
    <meta property="article:published_time" content="2025-08-26T09:00:00+00:00">
    <meta property="article:author" content="AIニュース">
    <meta property="article:section" content="AI技術ニュース">
    
    <!-- Twitter Card meta tags -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Gemini がすべてを制す | AIニュース">
    <meta name="twitter:description" content="Gemini がすべてを制す - AIニュース 2025-08-26。最新のAI技術動向を日本語でお届け。">
    <meta name="twitter:image" content="https://yipg.github.io/ainews/newsletters/og/2025-08-26.png">
    
    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>✏️</text></svg>">
    <link rel="alternate icon" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAACXBIWXMAAA7EAAAOxAGVKw4bAAAA">
    
    <!-- RSS Feed -->
    <link rel="alternate" type="application/rss+xml" title="AIニュース RSS Feed" href="../feed.xml">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: Verdana, Geneva, sans-serif;
            font-size: 1em;
            line-height: 1.7;
            letter-spacing: 0.02em;
            max-width: 720px;
            margin: 0 auto;
            padding: 20px;
            background-color: #fff;
            color: #111;
            word-wrap: break-word;
        }
        
        nav {
            margin-bottom: 25px;
            padding-bottom: 15px;
            border-bottom: 1px solid #ddd;
            display: flex;
            align-items: center;
            justify-content: space-between;
            flex-wrap: nowrap;
        }
        
        .site-title {
            font-size: 1.1em;
            font-weight: bold;
            color: #111;
            text-decoration: none;
            flex-shrink: 0;
        }
        
        .site-title:hover {
            text-decoration: underline;
        }
        
        .nav-links {
            font-size: 0.85em;
            white-space: nowrap;
        }
        
        .nav-links a {
            color: #111;
            text-decoration: none;
            margin-left: 12px;
        }
        
        .nav-links a:hover {
            text-decoration: underline;
        }
        
        
        h1, h2, h3, h4, h5, h6 {
            margin: 35px 0 20px 0;
            line-height: 1.3;
            color: #111;
            letter-spacing: 0.01em;
        }
        
        h1 { font-size: 1.5em; }
        h2 { font-size: 1.3em; }
        h3 { font-size: 1.1em; }
        
        p {
            margin: 20px 0;
        }
        
        a {
            color: #0969da;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin: 20px 0;
            padding-left: 30px;
        }
        
        li {
            margin: 8px 0;
        }
        
        blockquote {
            border-left: 3px solid #ccc;
            margin: 25px 0;
            padding: 0 25px;
            color: #555;
            font-style: italic;
        }
        
        code {
            background-color: #f6f8fa;
            padding: 2px 4px;
            border-radius: 3px;
            font-family: 'Courier New', Courier, monospace;
            font-size: 0.9em;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            padding: 20px;
            overflow-x: auto;
            margin: 25px 0;
        }
        
        pre code {
            background: none;
            padding: 0;
        }
        
        img {
            max-width: 100%;
            height: auto;
            margin: 25px 0;
            border-radius: 3px;
        }
        
        hr {
            border: none;
            border-top: 1px solid #ddd;
            margin: 35px 0;
        }
        
        footer {
            margin-top: 40px;
            padding-top: 15px;
            border-top: 1px solid #ddd;
            text-align: center;
            color: #555;
            font-size: 0.85em;
        }
        
        footer a {
            color: #555;
            text-decoration: none;
            margin: 0 8px;
        }
        
        footer a:hover {
            text-decoration: underline;
        }
        
        @media (max-width: 600px) {
            body {
                padding: 15px;
                font-size: 0.95em;
            }
            
            nav {
                flex-direction: column;
                align-items: flex-start;
                gap: 10px;
            }
            
            .nav-links {
                font-size: 0.8em;
            }
            
            .nav-links a {
                margin-left: 0;
                margin-right: 12px;
            }
            
            .article-title {
                font-size: 1.4em;
            }
        }
        
        @media (max-width: 480px) {
            body {
                font-size: 0.9em;
                padding: 12px;
            }
            
            .site-title {
                font-size: 1em;
            }
            
            .nav-links {
                font-size: 0.75em;
            }
            
            .article-title {
                font-size: 1.3em;
            }
        }
        
        @media (prefers-color-scheme: dark) {
            body {
                background-color: #111;
                color: #eee;
            }
            
            nav {
                border-bottom-color: #444;
            }
            
            .site-title, .nav-links a, .article-title, h1, h2, h3, h4, h5, h6 {
                color: #eee;
            }
            
            .article-date {
                color: #ccc;
            }
            
            blockquote {
                border-left-color: #555;
                color: #ccc;
            }
            
            code {
                background-color: #2d3748;
                color: #e2e8f0;
            }
            
            pre {
                background-color: #2d3748;
            }
            
            hr, footer {
                border-color: #444;
            }
            
            footer, footer a {
                color: #ccc;
            }
        }
    </style>
</head>
<body>
    <nav>
        <a href="../index.html" class="site-title">✏️ AIニュース</a>
        <div class="nav-links">
            <a href="../index.html">ホーム</a>
            <a href="./archive.html">アーカイブ</a>
            <a href="../feed.xml">RSS</a>
            <a href="https://github.com/YIPG/ainews">GitHub</a>
        </div>
    </nav>

    <main>
        <p><strong>Gemini がすべてを制す</strong></p>
<p>Google が本日<a href="https://developers.googleblog.com/en/introducing-gemini-2-5-flash-image/">発表</a>しました。</p>
<p><img alt="" src="https://resend-attachments.s3.amazonaws.com/CmV1VbHZ6LMkkFy" /></p>
<p>そして<a href="https://x.com/lmarena_ai/status/1960343469370884462">LMArena の結果</a>は明らかです。</p>
<p><img alt="" src="https://resend-attachments.s3.amazonaws.com/ZQ9sedBbikWDU6f" /></p>
<hr />
<h1 id="ai-twitter-recap">AI Twitter Recap</h1>
<p><strong>Gemini 2.5 Flash Image（コードネーム “nano-banana”）が画像編集分野を席巻</strong></p>
<ul>
<li><strong>モデル概要・機能・提供状況</strong>：コミュニティで匿名の “nano-banana” と呼ばれていたモデルが、Google DeepMind により <strong>Gemini‑2.5‑Flash‑Image‑Preview</strong> として正式確認されました。キャラクターの一貫性、自然言語による精密な編集、複数画像の合成、正確なテキスト描画に強みを持つ最先端の画像編集・生成モデルです。Gemini アプリ、Google AI Studio/API で利用可能で、評価サイトにも早期に登場しました（<a href="https://twitter.com/GoogleDeepMind/status/1960341906790957283">@GoogleDeepMind</a>、<a href="https://twitter.com/sundarpichai/status/1960342316415087049">@sundarpichai</a>、<a href="https://twitter.com/Google/status/1960342356881723469">@Google</a>、<a href="https://twitter.com/_philschmid/status/1960344026437026056">docs</a>、<a href="https://twitter.com/omarsar0/status/1960344569356431634">pricing</a>）。</li>
<li><strong>ベンチマークと大規模利用</strong>：Image Edit Arena において、Gemini 2.5 Flash Image は次点モデルに対して <strong>約170〜180 Elo</strong> の大差をつけ、2週間で500万票以上、そのうち本モデル単独で250万票以上を獲得し、Arena史上最大の差を記録しました。コミュニティのランキングで画像編集1位、テキストから画像生成でもトップクラスです（<a href="https://twitter.com/lmarena_ai/status/1960343469370884462">@lmarena_ai</a>、<a href="https://twitter.com/lmarena_ai/status/1960342813599760516">reveal</a>、<a href="https://twitter.com/cdngdev/status/1960355432037560697">usage spike</a>、<a href="https://twitter.com/ArtificialAnlys/status/1960388401401880898">Artificial Analysis</a>）。価格は <strong>100万出力トークンあたり30ドル</strong>（1画像あたり約1,290トークン、<strong>約0.039ドル/画像</strong>）（<a href="https://twitter.com/_philschmid/status/1960344024151199765">@_philschmid</a>、<a href="https://twitter.com/andrew_n_carr/status/1960345460067148128">@andrew_n_carr</a>）。複数ターンの会話型編集、人物の一貫した再描画、暗黙の「世界知識」を活用した編集などのデモも公開されています（<a href="https://twitter.com/skirano/status/1960343968320737397">@skirano</a>、<a href="https://twitter.com/omarsar0/status/1960347789637878171">@omarsar0</a>）。</li>
<li><strong>エコシステムでの利用</strong>：すでにサードパーティプラットフォームやランキング（Yupp、LMArena バトルモード、OpenRouter など）に統合されており、コミュニティによるプロンプトガイドも展開中です（<a href="https://twitter.com/yupp_ai/status/1960345648424800750">@yupp_ai</a>、<a href="https://twitter.com/xanderatallah/status/1960358164693438934">@xanderatallah</a>、<a href="https://twitter.com/OfficialLoganK/status/1960343135436906754">@OfficialLoganK</a>）。</li>
</ul>
<p><strong>新モデルとオープンソースリリース</strong></p>
<ul>
<li><strong>Nous Research Hermes 4（オープンウェイト）</strong>：操作性、拒否率の低さ、数学・コーディング・STEM分野での高性能を重視したハイブリッド推論モデル。Hugging Face と OpenRouter で提供され、「thinking」モードの切替が可能です（<a href="https://twitter.com/NousResearch/status/1960416954457710982">@NousResearch</a>、<a href="https://twitter.com/Teknium1/status/1960420619620901135">weights</a>、<a href="https://twitter.com/OpenRouterAI/status/1960436262923592065">OpenRouter</a>、<a href="https://twitter.com/jon_durbin/status/1960434806740717720">toggle</a>）。</li>
<li><strong>NVIDIA Nemotron Nano 9B V2（小型推論モデル）</strong>：NVIDIA が開発した Mamba‑Transformer ハイブリッド型、128k コンテキスト対応モデル（Llama 非依存）。<strong>NVIDIA Open Model License</strong> で公開され、推論/非推論モードをサポート。&lt;10B モデルとしてトップ性能とされ、6.6兆トークンの事前学習サブセットも公開（<a href="https://twitter.com/dl_weekly/status/1960321337248944130">@dl_weekly</a>、<a href="https://twitter.com/ArtificialAnlys/status/1960504310309249045">@ArtificialAnlys</a>、<a href="https://twitter.com/ArtificialAnlys/status/1960504316550373657">NVIDIA blog</a>）。</li>
<li><strong>InternVL3.5（VLM）</strong>：OpenAI の gpt‑oss 系をベースにした初の VLM 群が登場。gpt‑oss または Qwen3 を LLM バックボーンとする32種のモデルを展開（<a href="https://twitter.com/mervenoyann/status/1960298636610326564">@mervenoyann</a>）。</li>
<li><strong>Ollama v0.11.7</strong>：DeepSeek v3.1（ハイブリッド「thinking」）をアプリ/CLI/API/SDKでサポート、Turbo モードをプレビュー提供（<a href="https://twitter.com/ollama/status/1960463433515852144">@ollama</a>）。</li>
<li><strong>Apple Silicon ローカルスタック</strong>：「Osaurus」は MLX ベースの Apple Silicon ネイティブ LLM サーバー（約7MB）で、Ollama より約20%高速。コミュニティが小型モデルを MLX に移植中（<a href="https://twitter.com/geekbb/status/1960166766338023759">@geekbb</a>、<a href="https://twitter.com/LiMzba/status/1960277996172149103">@LiMzba</a>）。</li>
<li>その他：Liquid AI の LFM2‑VL シリーズ（<a href="https://twitter.com/dl_weekly/status/1960387356889928174">@dl_weekly</a>）、学生による LFM2 のフランス語ファインチューニング（FFT＋マージ）（<a href="https://twitter.com/maximelabonne/status/1960288489838092456">@maximelabonne</a>）。</li>
</ul>
<p><strong>エージェント、API、開発者向けツール</strong></p>
<ul>
<li><strong>Claude for Chrome（リサーチプレビュー）</strong>：Anthropic が1,000人向けにブラウザ統合型アクションエージェントを試験提供。特にプロンプトインジェクション防御など安全性を重視（<a href="https://twitter.com/AnthropicAI/status/1960417002469908903">@AnthropicAI</a>、<a href="https://twitter.com/AnthropicAI/status/1960417004202156391">safety note</a>）。</li>
<li><strong>OpenAI API 変更</strong>：Assistants API を廃止し <strong>Responses API</strong> に統合（2026年8月26日終了予定）。Responses ではコードインタープリタ、永続会話、MCP、コンピュータ利用をサポート。GPT‑5 では「reasoning tokens」がターン間で保持されます。Web検索機能にドメインフィルタ、ソース表示を追加し、価格を <strong>$10/1K calls</strong> に値下げ（<a href="https://twitter.com/OpenAIDevs/status/1960409187122602172">@OpenAIDevs</a>、<a href="https://twitter.com/OpenAIDevs/status/1960425260576334274">pricing update</a>）。</li>
<li><strong>エージェント設計と評価</strong>：Cline 氏は、2023年のマルチエージェントオーケストレーションやコードベース索引型RAG、命令オーバーロードなどのパターンが、現在では単純な設計に劣る場合が多いと指摘（<a href="https://twitter.com/cline/status/1960175630907306325">thread</a>、<a href="https://twitter.com/cline/status/1960175691212968289">blog</a>）。TransluceAI の Docent alpha は大規模な行動分析を自動化（報酬ハッキング、命令違反検出）、主要ラボや評価機関がテスト中（<a href="https://twitter.com/TransluceAI/status/1960411239919837654">launch</a>）。Weave＋Tavily は追跡可能な最新リサーチエージェントのレシピを公開（<a href="https://twitter.com/weave_wb/status/1960428416236445931">Weave</a>）。LangGraph Studio はインタラクティブデバッグとトレースUXを改善（<a href="https://twitter.com/LangChainAI/status/1960442209918218491">@LangChainAI</a>）。Weaviate の Elysia はテキスト以外も動的表示できる「agentic RAG」UIを提供（<a href="https://twitter.com/weaviate_io/status/1960335442521346220">@weaviate_io</a>）。Beam は OSS の「デコレータからサーバーレス」フレームワークを提供（<a href="https://twitter.com/_avichawla/status/1960228287516684505">@_avichawla</a>）。</li>
</ul>
<p><strong>トレーニング、RL、最適化</strong></p>
<ul>
<li><strong>GRPO のコード解説</strong>：Qwen 2.5 に GRPO を適用して 2048 ゲームを学習させる手順を解説、実行可能コードと動画付き（<a href="https://twitter.com/jayendra_ram/status/1960157842620498107">@jayendra_ram</a>）。コミュニティでは「LLM の RL はKVキャッシュをメモリに収める調整だ」という冗談も（<a href="https://twitter.com/finbarrtimbers/status/1960177754655359110">@finbarrtimbers</a>）。</li>
<li><strong>RL フレームワーク比較</strong>：verl（Ray/DataProto基盤、SGLang統合、671Bまでスケール）、AReal（Ant の非同期RL）、Nemo‑RL（NVIDIA、高性能だが採用は遅め）、Zhipu の Slime（SGLang/Megatron最適化）を比較。オンポリシーはクリーンだが、オフポリシーが実務では有利な場合が多い（<a href="https://twitter.com/ZhihuFrontier/status/1960175371330208073">summary</a>）。</li>
<li><strong>長コンテキストと圧縮</strong>：Hugging Face Trainer が <strong>コンテキスト並列</strong> をサポートし、10万トークン以上のシーケンス長に対応（<a href="https://twitter.com/m_sirovatka/status/1960338030902096067">@m_sirovatka</a>）。vLLM の LLM Compressor v0.7.0 は QuIP、SpinQuant、混合精度、MoE（Llama‑4）対応、NVFP4/FP8混合を追加（<a href="https://twitter.com/vllm_project/status/1960432740672921934">@vllm_project</a>）。Adam のスケール不変性の限界（epsilon調整）や通信効率向上のための適応バッチング（AdLoCo）に関する研究も（<a href="https://twitter.com/sedielem/status/1960329585972641797">@sedielem</a>、<a href="https://twitter.com/papers_anon/status/1960225989008748900">@papers_anon</a>）。</li>
<li><strong>データパイプラインの進化</strong>：「軽いフィルタで大量データ」から、LLMベースの厳格なフィルタ＋リプレイ、さらに <strong>LLM リフレーズ</strong> によるサンプルあたりの情報量増加へ移行（Nemotron‑CC、WRAP、REWIREなど）。複数エポック学習が再び支持され、収穫逓減を受け入れる傾向（<a href="https://twitter.com/lvwerra/status/1960346415051247748">@lvwerra</a>）。</li>
</ul>
<p><strong>システム・インフラ関連</strong></p>
<ul>
<li><strong>Google TPUv7 アーキテクチャ（Hot Chips）</strong>：TPUv7（別名 v6p/“ghostfish”）の初公開ブロック図。HBM3e 8スタック、中規模のシストリックアレイ4基、<strong>3Dトーラス</strong>で最大9,216台をスケール接続。OCSにより障害ドメインの影響範囲を縮小（<a href="https://twitter.com/SemiAnalysis_/status/1960424664741634094">@SemiAnalysis_</a>）。</li>
<li><strong>プラットフォーム</strong>：zml/llmd が TPU 上で動作し、prefill/decode ページングアテンションを1フラグで実行（<a href="https://twitter.com/steeve/status/1960333418467664332">@steeve</a>）。Hugging Face Diffusers は Flax を廃止し PyTorch 優先へ（<a href="https://twitter.com/RisingSayak/status/1960333842553897296">@RisingSayak</a>）。Prime クラスターで H100/H200/B200 のマルチノード Slurm サポートが追加（<a href="https://twitter.com/jannik_stra/status/1960375622003196127">@jannik_stra</a>）。</li>
</ul>
<p><strong>ベンチマークと推論研究</strong></p>
<ul>
<li><strong>推論・数学</strong>：IneqMath がジャッジやデータ追加、ローカル vLLM サポート、継続更新型リーダーボードを導入。SOTAは GPT‑5（medium, 30K）が47%達成、最高のオープンモデル（gpt‑oss‑120B, 10K）は23.5%（<a href="https://twitter.com/lupantech/status/1960384184842879444">@lupantech</a>）。Stanford の UQ ベンチマークは未解決問題の解法能力を検証し、一部は専門家検証を通過（<a href="https://twitter.com/Muennighoff/status/1960391987917402509">@Muennighoff</a>）。MIRAGE はグラフ検索強化型の多段推論を提案（<a href="https://twitter.com/omarsar0/status/1960447282110980187">@omarsar0</a>）。ニューロン特徴の「過密化」が敵対的脆弱性に関連するという解釈可能性の新知見も（<a href="https://twitter.com/GoodfireAI/status/1960378734852046859">@GoodfireAI</a>）。また、スケーリング則の議論は2017/2020以前から存在し、NIPS 1993 の学習曲線とテスト誤差予測に遡れるとの指摘も（<a href="https://twitter.com/jxmnop/status/1960314100715528627">@jxmnop</a>）。</li>
</ul>
<p><strong>エンゲージメント上位ツイート</strong></p>
<ul>
<li><strong>Gemini 2.5 Flash Image（バナナ三部作）</strong>：Sundar Pichai 氏や Google DeepMind による発表・デモが大きな反響（<a href="https://twitter.com/sundarpichai/status/1960340452604785008">@sundarpichai</a>、<a href="https://twitter.com/GoogleDeepMind/status/1960341906790957283">@GoogleDeepMind</a>、<a href="https://twitter.com/googleaistudio/status/1960344388560904213">@googleaistudio</a>）。</li>
<li><strong>Anthropic のエージェント戦略</strong>：Claude for Chrome リサーチプレビュー、安全なブラウザ操作に注力（<a href="https://twitter.com/AnthropicAI/status/1960417002469908903">@AnthropicAI</a>）。</li>
<li><strong>コミュニティの評価</strong>：Demis Hassabis 氏が Gemini 2.5 Image を「Elo差で最高」と評価（<a href="https://twitter.com/demishassabis/status/1960355658059891018">@demishassabis</a>）、Oriol Vinyals 氏が利用状況とArenaでの話題性に言及（<a href="https://twitter.com/OriolVinyalsML/status/1960343791283433842">@OriolVinyalsML</a>）。</li>
<li><strong>Reid Hoffman 氏の比喩</strong>：「1万プロンプトは新たな1万時間」という言葉が練習による習熟の時代精神を表現（<a href="https://twitter.com/reidhoffman/status/1960392913130541551">@reidhoffman</a>）。</li>
<li><strong>Scale AI × 米陸軍</strong>：米陸軍との<strong>9,900万ドル</strong>契約を発表（<a href="https://twitter.com/alexandr_wang/status/1960195704275743035">@alexandr_wang</a>）。</li>
</ul>
    </main>

    <footer>
        <p>
            <a href="https://github.com/YIPG/ainews">GitHub</a>
            <a href="https://news.smol.ai/">news.smol.ai</a>
        </p>
    </footer>
</body>
</html>