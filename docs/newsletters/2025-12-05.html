<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NeurIPSの静かな終わり | AIニュース</title>
    <meta name="description" content="NeurIPSの静かな終わり - AIニュース 2025-12-05。最新のAI技術動向を日本語でお届け。">
    <meta name="keywords" content="AI,人工知能,ニュースレター,2025-12-05,機械学習,深層学習,日本語">
    <meta name="author" content="AIニュース">
    <link rel="canonical" href="https://yipg.github.io/ainews/docs/newsletters/2025-12-05.html">
    
    <!-- Open Graph meta tags -->
    <meta property="og:title" content="NeurIPSの静かな終わり | AIニュース">
    <meta property="og:description" content="NeurIPSの静かな終わり - AIニュース 2025-12-05。最新のAI技術動向を日本語でお届け。">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://yipg.github.io/ainews/docs/newsletters/2025-12-05.html">
    <meta property="og:image" content="https://yipg.github.io/ainews/newsletters/og/2025-12-05.png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:image:type" content="image/png">
    <meta property="og:site_name" content="AIニュース">
    <meta property="og:locale" content="ja_JP">
    <meta property="article:published_time" content="2025-12-05T09:00:00+00:00">
    <meta property="article:author" content="AIニュース">
    <meta property="article:section" content="AI技術ニュース">
    
    <!-- Twitter Card meta tags -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="NeurIPSの静かな終わり | AIニュース">
    <meta name="twitter:description" content="NeurIPSの静かな終わり - AIニュース 2025-12-05。最新のAI技術動向を日本語でお届け。">
    <meta name="twitter:image" content="https://yipg.github.io/ainews/newsletters/og/2025-12-05.png">
    
    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>✏️</text></svg>">
    <link rel="alternate icon" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAACXBIWXMAAA7EAAAOxAGVKw4bAAAA">
    
    <!-- RSS Feed -->
    <link rel="alternate" type="application/rss+xml" title="AIニュース RSS Feed" href="../feed.xml">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: Verdana, Geneva, sans-serif;
            font-size: 1em;
            line-height: 1.7;
            letter-spacing: 0.02em;
            max-width: 720px;
            margin: 0 auto;
            padding: 20px;
            background-color: #fff;
            color: #111;
            word-wrap: break-word;
        }
        
        nav {
            margin-bottom: 25px;
            padding-bottom: 15px;
            border-bottom: 1px solid #ddd;
            display: flex;
            align-items: center;
            justify-content: space-between;
            flex-wrap: nowrap;
        }
        
        .site-title {
            font-size: 1.1em;
            font-weight: bold;
            color: #111;
            text-decoration: none;
            flex-shrink: 0;
        }
        
        .site-title:hover {
            text-decoration: underline;
        }
        
        .nav-links {
            font-size: 0.85em;
            white-space: nowrap;
        }
        
        .nav-links a {
            color: #111;
            text-decoration: none;
            margin-left: 12px;
        }
        
        .nav-links a:hover {
            text-decoration: underline;
        }
        
        
        h1, h2, h3, h4, h5, h6 {
            margin: 35px 0 20px 0;
            line-height: 1.3;
            color: #111;
            letter-spacing: 0.01em;
        }
        
        h1 { font-size: 1.5em; }
        h2 { font-size: 1.3em; }
        h3 { font-size: 1.1em; }
        
        p {
            margin: 20px 0;
        }
        
        a {
            color: #0969da;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin: 20px 0;
            padding-left: 30px;
        }
        
        li {
            margin: 8px 0;
        }
        
        blockquote {
            border-left: 3px solid #ccc;
            margin: 25px 0;
            padding: 0 25px;
            color: #555;
            font-style: italic;
        }
        
        code {
            background-color: #f6f8fa;
            padding: 2px 4px;
            border-radius: 3px;
            font-family: 'Courier New', Courier, monospace;
            font-size: 0.9em;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            padding: 20px;
            overflow-x: auto;
            margin: 25px 0;
        }
        
        pre code {
            background: none;
            padding: 0;
        }
        
        img {
            max-width: 100%;
            height: auto;
            margin: 25px 0;
            border-radius: 3px;
        }
        
        hr {
            border: none;
            border-top: 1px solid #ddd;
            margin: 35px 0;
        }
        
        footer {
            margin-top: 40px;
            padding-top: 15px;
            border-top: 1px solid #ddd;
            text-align: center;
            color: #555;
            font-size: 0.85em;
        }
        
        footer a {
            color: #555;
            text-decoration: none;
            margin: 0 8px;
        }
        
        footer a:hover {
            text-decoration: underline;
        }
        
        @media (max-width: 600px) {
            body {
                padding: 15px;
                font-size: 0.95em;
            }
            
            nav {
                flex-direction: column;
                align-items: flex-start;
                gap: 10px;
            }
            
            .nav-links {
                font-size: 0.8em;
            }
            
            .nav-links a {
                margin-left: 0;
                margin-right: 12px;
            }
            
            .article-title {
                font-size: 1.4em;
            }
        }
        
        @media (max-width: 480px) {
            body {
                font-size: 0.9em;
                padding: 12px;
            }
            
            .site-title {
                font-size: 1em;
            }
            
            .nav-links {
                font-size: 0.75em;
            }
            
            .article-title {
                font-size: 1.3em;
            }
        }
        
        @media (prefers-color-scheme: dark) {
            body {
                background-color: #111;
                color: #eee;
            }
            
            nav {
                border-bottom-color: #444;
            }
            
            .site-title, .nav-links a, .article-title, h1, h2, h3, h4, h5, h6 {
                color: #eee;
            }
            
            .article-date {
                color: #ccc;
            }
            
            blockquote {
                border-left-color: #555;
                color: #ccc;
            }
            
            code {
                background-color: #2d3748;
                color: #e2e8f0;
            }
            
            pre {
                background-color: #2d3748;
            }
            
            hr, footer {
                border-color: #444;
            }
            
            footer, footer a {
                color: #ccc;
            }
        }
    </style>
</head>
<body>
    <nav>
        <a href="../index.html" class="site-title">✏️ AIニュース</a>
        <div class="nav-links">
            <a href="../index.html">ホーム</a>
            <a href="./archive.html">アーカイブ</a>
            <a href="../feed.xml">RSS</a>
            <a href="https://github.com/YIPG/ainews">GitHub</a>
        </div>
    </nav>

    <main>
        <p><strong>NeurIPSの静かな終わり</strong></p>
<h1 id="ai-twitter">AI Twitterまとめ</h1>
<p><strong>推論・コーディングモデルと推論インフラ：vLLM 0.12.0、NVIDIA CUDA Tile、Transformers v5、エージェント運用</strong></p>
<ul>
<li>
<p><strong>vLLM: DeepSeek対応 + エンジン刷新</strong><br />
  vLLMはDeepSeek‑V3.2の「thinking」モード向けに最適化レシピを提供しました。これにはtokenizerやtool-callパーサ、正しいchat_templateの使用（"reasoning"を使用し、"reasoning_content"は使用しない）などが含まれます。Tencent Cloudの計算資源提供に感謝が示されています。<br />
  また、vLLM v0.12.0ではGPU Model Runner V2（GPU常駐ブロックテーブル + Tritonネイティブサンプラー）、長文コンテキストprefillのためのPrefill Context Parallel基盤、EAGLE推測デコード改善、NVFP4/W4A8/AWQ量子化などが追加されました。新しいベースラインはPyTorch 2.9.0 + CUDA 12.9です。</p>
</li>
<li>
<p><strong>CUDA Tile: 高レベルGPUプログラミング</strong><br />
  NVIDIAはCUDA Tile IRとcuTile Pythonを発表し、スレッドレベルSIMTからタイルベースカーネルへの移行を推進しています。これによりTensor Cores/TMAsに適合し、GPU世代を超えた性能互換性を目指します。現行ツールはBlackwellクラスGPUを対象としており、既存GPUへの移植性は限定的です。</p>
</li>
<li>
<p><strong>Transformers v5 RC: マルチモーダルany-to-anyパイプライン</strong><br />
  Hugging FaceはAutoModelForMultimodalLMとany-to-anyパイプラインを追加し、複数入力・複数出力（例：Gemma3n全モダリティ→テキスト、Qwen3‑Omniテキスト+音声）を可能にしました。</p>
</li>
<li>
<p><strong>エージェントプラットフォームの更新</strong>  </p>
</li>
<li>LangChainはコンテンツモデレーションミドルウェアを追加し、入力・出力・ツール結果をプログラム可能にフィルタリングできるようにしました。また、LLM呼び出し以外のコスト追跡（カスタムツール/APIコストを統合トレースに記録）も追加しました。DeepAgents CLIはTerminal Bench 2.0で約42.7%を記録し、Claude Codeと同等の性能を示しました。</li>
<li>Together AIとMetaのAIチームはTorchForge上で長期的エージェントワークフローを支える本番対応RLを開始しました。</li>
<li>SonarSourceはSonarQube MCPサーバを公開し、Claude CodeやCursorに企業向け静的解析（バグ、脆弱性、カバレッジ）を統合しました。</li>
<li>Kimi CLIはJetBrains IDEとのACP統合を追加しました。Clineはgpt‑5.1‑codex‑maxを追加しました。</li>
<li>
<p>quantoで量子化モデルをコンパイル可能になりました（Qwen3‑VLのメモリ使用に注意）。</p>
</li>
<li>
<p><strong>エコシステム経済</strong><br />
  OpenRouterの新しい調査とダッシュボードでは「コーディングがキラーアプリ」との見方が広がっています。推論モデルはOpenRouter使用の50%以上を占め、中国製クローズドモデル（DeepSeek、Qwen3、Kimi K2、GLM）が大きなトラフィックを牽引しています。市場は二極化しており、高付加価値のコーディングにはプレミアムモデル、ロールプレイやクリエイティブ用途には安価・オープンモデルが使われています。</p>
</li>
</ul>
<hr />
<p><strong>Kling 2.6ネイティブ音声、Runway Gen‑4.5、Qwen3‑TTS、Gemini 3 Proマルチモーダル</strong></p>
<ul>
<li>
<p><strong>Klingのアップグレード</strong><br />
  Kling Video 2.6は初めてネイティブ同期音声（音声、効果音、環境音）を搭載しました。Kling O1の「Element/Subject Library」は永続的な被写体記憶と一貫性を提供し、テンプレートやローンチ週のプレゼント企画も行われました。</p>
</li>
<li>
<p><strong>Runway Gen‑4.5 "Whisper Thunder"</strong><br />
  世界観構築のための細かな美的制御を強化しました。併せてLight‑X（制御可能な4Dビデオレンダリング）、BulletTime（時間とカメラ制御の分離）、Live Avatar Streaming（リアルタイム音声駆動アバター）などの研究成果も発表されました。</p>
</li>
<li>
<p><strong>大規模TTSアップデート</strong><br />
  AlibabaはQwen3‑TTSを発表し、49以上の声、10言語＋中国方言、自然なプロソディを備え、リアルタイム・オフラインAPIを提供しました。</p>
</li>
<li>
<p><strong>Gemini 3 Proマルチモーダル</strong><br />
  Googleは複雑な文書をHTML/LaTeXに変換する「derendering」、スクリーン理解、ロボティクス/XR向けの空間軌跡生成、高FPSビデオ解析の「thinking」モードを紹介しました。</p>
</li>
<li>
<p><strong>ライブ嗜好シグナル</strong><br />
  YuppのライブリーダーボードではOpus 4.5 Onlineモデルが使用率トップに急上昇。画像分野ではBytePlus Seedream 4.5が急成長し、Moondreamは鮮明な空撮セグメンテーションをデモしました。</p>
</li>
</ul>
<hr />
<p><strong>評価、リーダーボード、野外でのエージェント運用</strong></p>
<ul>
<li>
<p><strong>ArenaとARC</strong><br />
  LM Arenaは「Arena Expert」を導入し、最難関プロンプトでthinkingモデルが非thinkingモデルより平均+24ポイント高い結果を示しました。ARC Prize 2025のグランプリは未だ獲得者なしで、主催者は2025年を改善ループの年と位置付けています。</p>
</li>
<li>
<p><strong>現場でのエージェント</strong>  </p>
</li>
<li>MAP研究では生産性向上が確認される一方、信頼性が最大の課題であり、単純で制御可能なパターン＋人間による監督が主流です。</li>
<li>オフポリシーRLの堅牢性では、Dr. GRPOは崩壊し、Kimi K2やTBAアプローチは収束。小さなレシピ変更が鍵であることが判明しました。</li>
<li>
<p>GEPAはプロンプトを迅速に書き換え、小規模テスト/修正サイクルで抽出精度を2倍以上に向上させました。</p>
</li>
<li>
<p><strong>OpenRouter使用傾向の変化</strong><br />
  推論型モデルはo1から1年未満でトークン使用の50%を超え、中国製クローズドモデルへの傾斜が顕著です。</p>
</li>
</ul>
<hr />
<p><strong>オープンモデル、データセット、ツール</strong></p>
<ul>
<li>
<p><strong>オープンウェイト画像生成</strong><br />
  FLUX.2 [dev]はオープンウェイトのテキスト→画像でトップ、画像編集で2位を獲得しました。小型版FLUX.2 [klein]はApache‑2.0で公開されました。MeituanはLongCat‑ImageとLongCat‑Image‑EditをApache‑2.0で公開しました。</p>
</li>
<li>
<p><strong>データセットと手法</strong><br />
  MixtureVitaeはBooks2のようなライセンスリスクなしで数学・コードに特化した事前学習データセットを発表しました。IntelのSignRoundV2は極低ビットPTQでの進展を報告しました。</p>
</li>
<li>
<p><strong>ツール内での著述・研究エージェント</strong><br />
  PaperDebuggerはOverleaf用マルチエージェントプラグインで、批評・書き換え・研究・スコア付けを行い、文献検索や引用表を生成します。PosterCopilotはグラフィックデザイン向けにレイヤー編集とレイアウト推論を追加しました。</p>
</li>
<li>
<p><strong>その他のOSS</strong><br />
  VLQM‑1.5B‑Coderは英語→ManimアニメーションコードをMLX上でローカルファインチューニングしました。AnswerDotAIのclipmd Chrome拡張はDOMをMarkdownやスクリーンショットに変換します。</p>
</li>
</ul>
<hr />
<p><strong>NeurIPSとコミュニティのハイライト</strong></p>
<ul>
<li>
<p><strong>推論とアラインメントの焦点</strong><br />
  Yejin Choiの基調講演ではEPO（Entropy‑Regularized Policy Optimization）などの推論研究が紹介されました。Sakana AIの「Continuous Thought Machine」はTransformerの深さではなくNeural ODEによる連続ダイナミクスでテスト時計算をスケーリングします。</p>
</li>
<li>
<p><strong>募集、求人、プログラム</strong><br />
  OpenAI Residencyの応募が開始され、複数チームが基礎的MLスキルを持つエンジニアを募集しています。GoogleのGemini 3 Vibe Codingハッカソンでは50万ドル分のAPIクレジットが提供されます。Arena、Sakana AI、LlamaIndexも研究職を募集しています。DeepMindはイベントや多言語AMAのページを公開しました。</p>
</li>
</ul>
<hr />
<p><strong>トップツイート（エンゲージメント順）</strong></p>
<ul>
<li>GoogleのGemini 3 Vibe Codingハッカソン：50万ドル分のAPIクレジット賞</li>
<li>Amanda AskellによるAIの倫理・アイデンティティ・意識に関するAMA</li>
<li>Qwen3‑TTS：49以上の声、10言語＋方言、リアルタイム/オフラインAPI</li>
<li>「2026年には、あなたがモデルにプロンプトを与えるのか、モデルがあなたにプロンプトを与えるのか、その境界が曖昧になる」</li>
<li>OpenAI Residency応募開始</li>
<li>Cloudflare障害によるツールへの影響（Claude、WorkOSなど）</li>
</ul>
<hr />
<p><strong>画像生成と編集：FLUX.2 [dev]とLongCat‑Image‑Edit</strong></p>
<ul>
<li><strong>オープンウェイトT2Iと編集</strong><br />
  Black Forest LabsのFLUX.2 [dev]はオープンウェイトT2Iでトップ、編集で2位となりました。FLUX.2 [klein]はApache‑2.0で商用利用可能です。MeituanのLongCat‑Image‑EditはApache‑2.0で公開され、デモも提供されています。</li>
</ul>
<hr />
<h1 id="ai-reddit">AI Redditまとめ</h1>
<h2 id="rlocalllama-rlocalllm">/r/LocalLlama + /r/localLLMまとめ</h2>
<h3 id="1-ai">1. スポーツ分析におけるAI</h3>
<ul>
<li>
<p><strong>RF-DETR, SAM2, SmolVLM2によるバスケットボールAI</strong><br />
  RF-DETRで選手と番号検出、SAM2で選手追跡、SmolVLM2で番号認識を行い、SigLIP、UMAP、K-Meansでチームクラスタリング、ホモグラフィーで視点変換と軌跡補正を実施。シュート検出と分類も統合されています。サッカーへの応用可能性も指摘されています。</p>
</li>
<li>
<p><strong>「何も所有せず、幸せになる」ハードウェアサービス化の潮流</strong><br />
  消費者が物理的ハードウェアを所有せず、クラウドベースのRAMやストレージを利用する傾向が強まっています。データセンター向けRAMの方が利益率が高いことが背景にあり、資本主義的動機が主因とされています。</p>
</li>
</ul>
<hr />
<h2 id="ai">技術色の薄いAIサブレまとめ</h2>
<h3 id="1-ai_1">1. 職場でのAI利用</h3>
<ul>
<li><strong>Anthropicの調査：多くの労働者がAIを日常利用も69%が職場で隠す</strong><br />
  86%がAIで生産性向上を感じる一方、69%は職場での使用にスティグマを感じています。仕事削減や上司の抵抗が背景にあります。</li>
</ul>
<h3 id="2">2. 画像生成とアニメーションツール</h3>
<ul>
<li>
<p><strong>Z-image Turbo + SteadyDancer</strong><br />
  SteadyDancerは動画全体で参照画像との一致率100%を維持し、Wan2.2 Animateより安定性が高いとされています。環境との相互作用や脚部の動きの破綻など技術的課題も議論されています。</p>
</li>
<li>
<p><strong>Detail Daemon + ZIT</strong><br />
  ファンタジー風アート作品で、Detail DaemonとZITの組み合わせが効果的とされています。統合方法や代替ツールの利用例も共有されています。</p>
</li>
</ul>
<h3 id="3">3. ユーモラス・クリエイティブなイラスト</h3>
<ul>
<li>
<p><strong>Lol 😂</strong><br />
  デジタルインフラの複雑さをユーモラスに描いたミーム。</p>
</li>
<li>
<p><strong>Alphabet of Internal organs</strong><br />
  内臓のアルファベット図。AI画像生成の解剖学的精度の課題も指摘されています。</p>
</li>
<li>
<p><strong>Nah ts is crazy</strong><br />
  ダウンロード時間の微妙な変化をネタにしたミーム。</p>
</li>
<li>
<p><strong>cat tryna make bread</strong><br />
  猫がこねる動作をAIで再現した動画。</p>
</li>
<li>
<p><strong>Careless Whisper | Romantic Jedi Cover</strong><br />
  スター・ウォーズと楽曲の融合をAIで実現した創作カバー。</p>
</li>
</ul>
<hr />
<h1 id="ai-discord">AI Discordまとめ</h1>
<p><strong>1. 次世代GPUソフトウェア：CUDA 13.1、cuTile、Verified Sparse Attention</strong></p>
<ul>
<li>NVIDIAはcuTileライブラリを公開し、PythonベースでTileIRをコンパイル可能にしました。</li>
<li>Sparse Attentionは論文多数にもかかわらず実用化が進んでいませんが、VATTENTIONが初の実用的手法を提案。</li>
<li>RLでチューニングしたCUDA-L2カーネルがcuBLASを上回る性能を示しました。</li>
</ul>
<p><strong>2. LLMベンチマーク、利用動向、新興モデル</strong></p>
<ul>
<li>OpenRouterとa16zが100兆トークンの利用分析を発表。</li>
<li>Gemini 3はOpus 4.5より高コストで低性能との報告。</li>
<li>Qwen 1.5‑110Bは2枚の80GB GPUで大規模MoEモデル並みの性能を達成。</li>
</ul>
<p><strong>3. ツール指向・コスト意識のエージェント設計</strong></p>
<ul>
<li>モデル非依存のツールオーケストレーターがトークン使用を最大99%削減。</li>
<li>MCPでのトークン計測方法が議論され、tiktokenやAnthropic APIが推奨されました。</li>
</ul>
<p><strong>4. ハードウェア動向</strong></p>
<ul>
<li>TinyCorpが1Uサイズで8GPU搭載の水冷サーバを予告。</li>
<li>NVIDIAがPascal/Voltaのサポート終了。</li>
<li>Qwen4BがApple Siliconで高いトークン生成速度を記録。</li>
</ul>
<p><strong>5. トレーニング、量子化、小規模モデル</strong></p>
<ul>
<li>EleutherAIが16GB未満VRAMでの小規模LMトレーニングパイプラインを構築。</li>
<li>4Bit‑Forgeが大規模LLMの4ビット量子化を民主化。</li>
<li>HRM/TRMモデルが少パラメータでLLMを凌ぐ性能を示す事例が共有されました。</li>
</ul>
    </main>

    <footer>
        <p>
            <a href="https://github.com/YIPG/ainews">GitHub</a>
            <a href="https://news.smol.ai/">news.smol.ai</a>
        </p>
    </footer>
</body>
</html>