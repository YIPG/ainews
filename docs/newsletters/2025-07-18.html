<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mistralがオープンモデルの世界に復帰！ | AIニュース</title>
    <meta name="description" content="Mistralがオープンモデルの世界に復帰！ - AIニュース 2025-07-18。最新のAI技術動向を日本語でお届け。">
    <meta name="keywords" content="AI,人工知能,ニュースレター,2025-07-18,機械学習,深層学習,日本語">
    <meta name="author" content="AIニュース">
    <link rel="canonical" href="https://yipg.github.io/ainews/newsletters/2025-07-18.html">
    
    <!-- Open Graph meta tags -->
    <meta property="og:title" content="Mistralがオープンモデルの世界に復帰！ | AIニュース">
    <meta property="og:description" content="Mistralがオープンモデルの世界に復帰！ - AIニュース 2025-07-18。最新のAI技術動向を日本語でお届け。">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://yipg.github.io/ainews/newsletters/2025-07-18.html">
    <meta property="og:site_name" content="AIニュース">
    <meta property="og:locale" content="ja_JP">
    <meta property="article:published_time" content="2025-07-18T09:00:00+00:00">
    <meta property="article:author" content="AIニュース">
    <meta property="article:section" content="AI技術ニュース">
    
    <!-- Twitter Card meta tags -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Mistralがオープンモデルの世界に復帰！ | AIニュース">
    <meta name="twitter:description" content="Mistralがオープンモデルの世界に復帰！ - AIニュース 2025-07-18。最新のAI技術動向を日本語でお届け。">
    
    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>✏️</text></svg>">
    <link rel="alternate icon" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAACXBIWXMAAA7EAAAOxAGVKw4bAAAA">
    
    <!-- RSS Feed -->
    <link rel="alternate" type="application/rss+xml" title="AIニュース RSS Feed" href="../feed.xml">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: Verdana, Geneva, sans-serif;
            font-size: 1em;
            line-height: 1.7;
            letter-spacing: 0.02em;
            max-width: 720px;
            margin: 0 auto;
            padding: 20px;
            background-color: #fff;
            color: #111;
            word-wrap: break-word;
        }
        
        nav {
            margin-bottom: 25px;
            padding-bottom: 15px;
            border-bottom: 1px solid #ddd;
            display: flex;
            align-items: center;
            justify-content: space-between;
            flex-wrap: nowrap;
        }
        
        .site-title {
            font-size: 1.1em;
            font-weight: bold;
            color: #111;
            text-decoration: none;
            flex-shrink: 0;
        }
        
        .site-title:hover {
            text-decoration: underline;
        }
        
        .nav-links {
            font-size: 0.85em;
            white-space: nowrap;
        }
        
        .nav-links a {
            color: #111;
            text-decoration: none;
            margin-left: 12px;
        }
        
        .nav-links a:hover {
            text-decoration: underline;
        }
        
        
        h1, h2, h3, h4, h5, h6 {
            margin: 35px 0 20px 0;
            line-height: 1.3;
            color: #111;
            letter-spacing: 0.01em;
        }
        
        h1 { font-size: 1.5em; }
        h2 { font-size: 1.3em; }
        h3 { font-size: 1.1em; }
        
        p {
            margin: 20px 0;
        }
        
        a {
            color: #0969da;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin: 20px 0;
            padding-left: 30px;
        }
        
        li {
            margin: 8px 0;
        }
        
        blockquote {
            border-left: 3px solid #ccc;
            margin: 25px 0;
            padding: 0 25px;
            color: #555;
            font-style: italic;
        }
        
        code {
            background-color: #f6f8fa;
            padding: 2px 4px;
            border-radius: 3px;
            font-family: 'Courier New', Courier, monospace;
            font-size: 0.9em;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            padding: 20px;
            overflow-x: auto;
            margin: 25px 0;
        }
        
        pre code {
            background: none;
            padding: 0;
        }
        
        img {
            max-width: 100%;
            height: auto;
            margin: 25px 0;
            border-radius: 3px;
        }
        
        hr {
            border: none;
            border-top: 1px solid #ddd;
            margin: 35px 0;
        }
        
        footer {
            margin-top: 40px;
            padding-top: 15px;
            border-top: 1px solid #ddd;
            text-align: center;
            color: #555;
            font-size: 0.85em;
        }
        
        footer a {
            color: #555;
            text-decoration: none;
            margin: 0 8px;
        }
        
        footer a:hover {
            text-decoration: underline;
        }
        
        @media (max-width: 600px) {
            body {
                padding: 15px;
                font-size: 0.95em;
            }
            
            nav {
                flex-direction: column;
                align-items: flex-start;
                gap: 10px;
            }
            
            .nav-links {
                font-size: 0.8em;
            }
            
            .nav-links a {
                margin-left: 0;
                margin-right: 12px;
            }
            
            .article-title {
                font-size: 1.4em;
            }
        }
        
        @media (max-width: 480px) {
            body {
                font-size: 0.9em;
                padding: 12px;
            }
            
            .site-title {
                font-size: 1em;
            }
            
            .nav-links {
                font-size: 0.75em;
            }
            
            .article-title {
                font-size: 1.3em;
            }
        }
        
        @media (prefers-color-scheme: dark) {
            body {
                background-color: #111;
                color: #eee;
            }
            
            nav {
                border-bottom-color: #444;
            }
            
            .site-title, .nav-links a, .article-title, h1, h2, h3, h4, h5, h6 {
                color: #eee;
            }
            
            .article-date {
                color: #ccc;
            }
            
            blockquote {
                border-left-color: #555;
                color: #ccc;
            }
            
            code {
                background-color: #2d3748;
                color: #e2e8f0;
            }
            
            pre {
                background-color: #2d3748;
            }
            
            hr, footer {
                border-color: #444;
            }
            
            footer, footer a {
                color: #ccc;
            }
        }
    </style>
</head>
<body>
    <nav>
        <a href="../index.html" class="site-title">✏️ AIニュース</a>
        <div class="nav-links">
            <a href="../index.html">ホーム</a>
            <a href="./archive.html">アーカイブ</a>
            <a href="../feed.xml">RSS</a>
        </div>
    </nav>

    <main>
        <h1 id="mistral">Mistralがオープンモデルの世界に復帰！</h1>
<p><a href="https://x.com/miramurati/status/1945166365834535247">Miraの20億ドルのThinking Machines資金調達</a>が予想されていた一方で、Mistralは突如として新しい音声認識モデル「Voxtral」を発表しました。このモデルは「Whisper large-v3を包括的に上回り」、「GPT-4o mini TranscribeやGemini 2.5 Flashをすべてのタスクで凌駕する」とされています。</p>
<p><img alt="" src="https://resend-attachments.s3.amazonaws.com/3gD9JqDjWuDJD1m" /></p>
<p>このような資格不要の圧倒的な性能は歓迎されるべきものであり、さらにオープンモデルである点が魅力的です。</p>
<p>Voxtral 3BおよびVoxtral 24Bモデルは、以下のような特徴を備え、単なる音声認識を超えた能力を提供します：</p>
<ul>
<li><strong>長いコンテキスト</strong>：32kトークンのコンテキスト長により、最大30分の音声の文字起こしや、最大40分の音声理解が可能です。</li>
<li><strong>組み込みのQ&amp;Aおよび要約機能</strong>：音声内容に直接質問したり、構造化された要約を生成することが可能で、ASR（自動音声認識）と言語モデルを別々に連携させる必要がありません。</li>
<li><strong>ネイティブな多言語対応</strong>：自動言語検出機能と、英語、スペイン語、フランス語、ポルトガル語、ヒンディー語、ドイツ語、オランダ語、イタリア語など、世界で広く使用されている言語において最先端の性能を発揮します。これにより、グローバルなオーディエンスに対応する単一のシステムを提供できます。</li>
<li><strong>音声から直接関数呼び出し</strong>：ユーザーの音声意図に基づいてバックエンド関数やワークフロー、API呼び出しを直接トリガーすることが可能で、中間的な解析ステップを必要とせずに音声インタラクションを実行可能なシステムコマンドに変換します。</li>
<li><strong>テキスト理解能力</strong>：言語モデルのバックボーンである「Mistral Small 3.1」のテキスト理解能力を保持しています。</li>
</ul>
<p>非常に興味深い内容です。以前報告を見送った<a href="https://mistral.ai/news/magistral">MistralのMagistral推論モデル</a>（<a href="https://www.youtube.com/watch?v=_vNFJcb8S_M">優れた論文</a>が公開されています）とは異なり、Voxtralはほぼ即座に実用化されると確信しています。</p>
<hr />
<h1 id="ai-twitter-recap">AI Twitter Recap</h1>
<h2 id="kimi-k2"><strong>Kimi K2の登場と性能</strong></h2>
<ul>
<li><strong>Kimi K2、非推論型MoEが西洋モデルに挑戦</strong>：<strong>Moonshot AI</strong>による<strong>Kimi K2</strong>のリリースが注目を集めています。このモデルの性能とその起源について議論が活発です。<a href="https://twitter.com/teortaxesTex/status/1944856509734961596">@teortaxesTex</a>は、<strong>Kimi</strong>が約200人のチームによって比較的少ないGPU予算で構築されたことを指摘し、西洋企業がなぜこれに匹敵するものを生み出せないのか疑問を呈しています。<a href="https://twitter.com/jeremyphoward/status/1944864781695113385">@jeremyphoward</a>は、<strong>K2</strong>が「推論モデルではない」と強調し、<strong>Mixture of Experts (MoE)</strong>アーキテクチャで非常に少ないアクティブトークンを使用しているため、安価で高速であると述べています。<a href="https://twitter.com/scaling01/status/1944850575470027243">@scaling01</a>はその優れたレポート生成能力を称賛し、<a href="https://twitter.com/zacharynado/status/1944945039647629548">@zacharynado</a>は「オープンウェイトの非推論モデルの中で最も優れたもの」と評価しています。</li>
<li><strong>Groqでの超高速推論と幅広いプラットフォーム対応</strong>：<strong>Kimi K2</strong>の<strong>Groq</strong>ハードウェアでの性能が注目されています。<a href="https://twitter.com/teortaxesTex/status/1944950183051321542">@teortaxesTex</a>は、185 t/sの速度を報告し、これにより<strong>K2</strong>が「Sonnet 4よりも即座に魅力的」となり、1Tパラメータモデルをそのチップに収めるという印象的な成果を示しています。モデルは<strong>Together AI</strong>（<a href="https://twitter.com/togethercompute/status/1944952034840732138">リンク1</a>、<a href="https://twitter.com/togethercompute/status/1945143838911128019">リンク2</a>）、<strong>DeepInfra</strong>（<a href="https://twitter.com/jeremyphoward/status/1944939322735780260">$0.55/$2.20</a>）、および単一の<strong>M4 Max 128GB</strong> Macでローカル実行可能であると<a href="https://twitter.com/reach_vb/status/1944997786329460978">@reach_vb</a>が指摘しています。</li>
<li><strong>ツール統合と開発者リソース</strong>：<strong>Kimi K2</strong>は開発者ツールへの迅速な統合が進んでいます。<strong>Moonshot AI</strong>は、マルチターンツール呼び出しを改善するためのHugging Faceリポジトリの<a href="https://twitter.com/Kimi_Moonshot/status/1945050874067476962">バグ修正</a>を発表しました。<strong>LangChain</strong>は<strong>Groq</strong>でのモデル公式サポートを<a href="https://twitter.com/_philschmid/status/1944847828599054713">発表</a>し、<a href="https://twitter.com/Hacubu/status/1945144499228811676">@Hacubu</a>もこれに言及しています。さらに、<strong>Cline</strong>は<a href="https://twitter.com/cline/status/1945164549134672373">Moonshot AIをプロバイダーとして追加</a>しました。<a href="https://twitter.com/bigeagle_xd/status/1945087963408351728">@yawnxyz</a>はGoogle MapsとチャットするChrome拡張機能をデモンストレーションしています。</li>
</ul>
<h2 id="ai"><strong>新しいモデル：音声、モーションキャプチャ、AIコンパニオン</strong></h2>
<ul>
<li><strong>Mistralがオープンソース音声モデル「Voxtral」をリリース</strong>：<strong>Mistral AI</strong>は<strong>Voxtral</strong>をリリースしました。<a href="https://twitter.com/GuillaumeLample/status/1945161150900924490">@GuillaumeLample</a>はこれを「世界最高（かつオープン）の音声認識モデル」と主張しています。<a href="https://twitter.com/reach_vb/status/1945135982023520623">@reach_vb</a>はこのリリースに興奮し、音声LMがテキスト能力を失うことが多いという課題を指摘しつつ、<a href="https://twitter.com/reach_vb/status/1945140430288417007">Voxtralがこの問題を回避している</a>ようだと述べています。モデルはAPI、Le Chat、Hugging Faceを通じて利用可能です。<a href="https://twitter.com/teortaxesTex/status/1945133462395957621">@teortaxesTex</a>は、このリリースが「文字起こしアプリ市場を再活性化する」と信じています。</li>
<li><strong>xAIがGrokコンパニオンとアバターを導入</strong>：<strong>xAI</strong>は<strong>Grok</strong>アバターとコンパニオンを展開し、すぐに話題となりました。<a href="https://twitter.com/chaitualuru/status/1945053158071255257">@chaitualuru</a>はこの機能が「日本で再びトップに立った」と述べています。<a href="https://twitter.com/ebbyamir/status/1944902771599450237">@ebbyamir</a>はアニメの少女ペルソナ「Ani」を含むさまざまな例を共有し、<a href="https://twitter.com/shaneguML/status/1945003636439814430">@shaneguML</a>は市場を考えると予測可能であると述べています。</li>
<li><strong>Runwayが高度なモーションキャプチャ用Act-Twoを導入</strong>：<strong>RunwayML</strong>は次世代モーションキャプチャモデル<strong>Act-Two</strong>を発表しました。<a href="https://twitter.com/c_valenzuelab/status/1945190630449172587">@c_valenzuelab</a>は「生成品質の大幅な改善と手のサポート」を強調しています。また、モデルを使用したルネサンスのボーカルパーカッションの創造的なデモを<a href="https://twitter.com/c_valenzuelab/status/1945219029192286717">共有</a>しています。</li>
<li><strong>GoogleがGeminiを強化し、トップランクの埋め込みと新機能を追加</strong>：<strong>Google DeepMind</strong>は最初の<strong>Gemini Embedding</strong>モデルが一般利用可能となり、<a href="https://twitter.com/demishassabis/status/1944870402251219338">MTEBリーダーボードで1位</a>にランクインしたと発表しました。さらに、<a href="https://twitter.com/demishassabis/status/1944939563170062804">@demishassabis</a>は写真を音付き動画に変換する新しいGemini機能を共有しています。</li>
<li><strong>その他の注目すべきモデルとアップデート</strong>：<strong>LGのEXAONE 4</strong>は14Tトークンでトレーニングされた32Bモデルであり、<a href="https://twitter.com/teortaxesTex/status/1944947588006076664">推論モードと非推論モードで最前線モデルに近い性能を示しています</a>。<strong>Kling AI</strong>は水、光、動きの処理における精度を示すビデオ生成能力を<a href="https://twitter.com/Kling_ai/status/1945095794127683640">デモンストレーション</a>しています。</li>
</ul>
<h2 id="_1"><strong>ツール、インフラストラクチャ、開発</strong></h2>
<ul>
<li><strong>エージェント型コーディングアシスタントが注目を集める</strong>：<strong>AnthropicのClaude Code</strong>は強力なツールとして注目されており、<a href="https://twitter.com/claude_code/status/1944944964708000083">@claude_code</a>がローカルファイルシステムタスクの一般エージェントとして使用するためのヒントを提供しています。その人気は急上昇しており、<a href="https://twitter.com/kylebrussell/status/1945132555604251007">@kylebrussell</a>は友人が有料プランにアップグレードしていると述べています。一方、<strong>Perplexity</strong>は<strong>Comet</strong>ブラウザに<a href="https://twitter.com/AravSrinivas/status/1944861476692615333">音声モード</a>や<a href="https://twitter.com/AravSrinivas/status/1945232153609978273">メールボックスの整理機能</a>などの機能を迅速に追加しています。<a href="https://twitter.com/AravSrinivas/status/1945136929218953577">@AravSrinivas</a>は、ツールをシームレスに統合し、ユーザーがモードを切り替える必要がないようにすることを目指していると述べています。</li>
<li><strong>ベクトルデータベースとフレームワークの進化</strong>：<strong>Qdrant</strong>は<strong>Qdrant Cloud Inference</strong>を開始し、ユーザーが<a href="https://twitter.com/qdrant_engine/status/1945090285039464518">クラウスターで直接埋め込みを生成、保存、インデックス化</a>できるようにしました。これには<strong>CLIP</strong>のような密、疎、およびマルチモーダルモデルのサポートが含まれます。<strong>LlamaIndex</strong>と<strong>Google AI</strong>は、<a href="https://twitter.com/jerryjliu0/status/1944882346731430127">Gemini 2.5 Proを使用したマルチエージェント深層研究システムの構築</a>に関するチュートリアルで協力し、<strong>LangChain</strong>は<strong>Redis</strong>や<strong>Tavily</strong>などのパートナーとイベントを開催して<a href="https://twitter.com/LangChainAI/status/1944905481069437210">新しいAI Gatewayスタック</a>を紹介しています。</li>
<li><strong>オンデバイスAIと専門フレームワーク</strong>：<strong>AppleのMLX</strong>フレームワークは拡大を続けており、<a href="https://twitter.com/awnihannun/status/1944904396606988655">@awnihannun</a>が純粋なC++への移植（<strong>mlx-lm.cpp</strong>）と<a href="https://twitter.com/awnihannun/status/1944893455202967921">tvOSのサポート</a>を発表しています。モバイル分野では、<a href="https://twitter.com/maximelabonne/status/1945110321938514335">@maximelabonne</a>がiOSおよびAndroidでローカルLLMを搭載したアプリを構築するための開発者プラットフォーム<strong>LEAP</strong>を発表しました。</li>
<li><strong>データの利用可能性と微調整</strong>：<a href="https://twitter.com/maximelabonne/status/1945018242290082047">@maximelabonne</a>は<strong>LFM2</strong>モデルが<strong>Axolotl</strong>を使用して微調整可能になったと発表しました。データに関しては、<a href="https://twitter.com/code_star/status/1944890857347539045">@code_star</a>が<strong>FineWeb</strong>および<strong>FineWeb-Edu</strong>が2025年1月から6月の<strong>CommonCrawl</strong>スナップショットを含むようになったとリツイートしました。主要なオープンソースの貢献として、<a href="https://twitter.com/ClementDelangue/status/1945185890294255741">@ClementDelangue</a>が<strong>米国判例法の99%</strong>がHugging Faceでオープンソース化されたと共有しました。</li>
</ul>
<h2 id="ai_1"><strong>研究、評価、AI安全性</strong></h2>
<ul>
<li><strong>業界全体でChain of Thought（CoT）モニタリングを推進</strong>：<strong>OpenAI</strong>、<strong>Anthropic</strong>、学術界のリーダーによって支持されたクロスインスティテューショナルな論文が、AI推論のモニタリング可能性を維持するよう研究所に促しています。<strong>OpenAI</strong>は<a href="https://twitter.com/OpenAI/status/1945156362859589955">エージェントシステムを監視するためにCoTを使用する研究を支持</a>していると述べています。<a href="https://twitter.com/woj_zaremba/status/1945158231321706894">@woj_zaremba</a>、<a href="https://twitter.com/merettm/status/1945157403315724547">@merettm</a>、<a href="https://twitter.com/NeelNanda5/status/1945156291577700542">@NeelNanda5</a>、<a href="https://twitter.com/Yoshua_Bengio/status/1945216792051232973">@Yoshua_Bengio</a>などの主要人物が強く支持を表明しており、モデルの思考プロセスへの可視性が重要な安全性の贈り物であると主張しています。</li>
<li><strong>「コンテキストロット」と長いコンテキストウィンドウの限界</strong>：<strong>Chroma</strong>の技術報告書は、<a href="https://twitter.com/swyx/status/1944848537092809177">入力トークンを増やすと、単純なタスクでもLLMの性能が低下する</a>ことを明らかにしました。この報告書「コンテキストロット」は、113kトークンの会話履歴で<strong>30%の精度低下</strong>などの問題を示しています。<a href="https://twitter.com/imjaredz/status/1944855623301988602">@imjaredz</a>は、「100万トークンのコンテキストウィンドウは嘘だ」と結論付け、コンテキストは慎重に設計されるべきだと述べています。</li>
<li><strong>AIを活用したセキュリティと新しい研究方向</strong>：<strong>Google</strong>は<a href="https://twitter.com/sundarpichai/status/1945113799297536313">AIエージェント「Big Sleep」が差し迫ったエクスプロイトを検出して阻止した</a>と発表し、サイバーセキュリティにおけるAIの重要な利用例を示しました。その他の研究では、<a href="https://twitter.com/lateinteraction/status/1944941744782512389">@lateinteraction</a>がRustベースのColBERTモデルをWebAssembly（WASM）にコンパイルしてクライアント側で実行するプロジェクトを強調しました。<a href="https://twitter.com/teortaxesTex/status/1944868734247788641">@teortaxesTex</a>は<strong>Memory Mosaics v2</strong>に関する論文を指摘し、これは<strong>8倍</strong>多くのトークンでトレーニングされたトランスフォーマーを上回る性能を示しているとされています。</li>
<li><strong>データ汚染と評価パラダイム</strong>：トレーニングにおけるデータ汚染の課題が<a href="https://twitter.com/francoisfleuret/status/1944997748807172555">@francoisfleuret</a>によって強調され、「1799年12月31日までの数学でトレーニングし、その後のデータで検証する」という提案がなされています。これは、記憶に依存しない堅牢な評価方法の必要性を反映しています。</li>
</ul>
<h2 id="_2"><strong>企業戦略と業界の動向</strong></h2>
<ul>
<li><strong>Metaのスーパーインテリジェンスビジョンとオープンソース論争</strong>：Mark Zuckerbergの巨大AIスーパークラスター計画が大きな話題となっています。<strong>Meta AI</strong>は彼のビジョンを<a href="https://twitter.com/AIatMeta/status/1945182467088113920">「世界中の人々に個人的なスーパーインテリジェンスを提供する」</a>と共有しました。この動きは懸念を引き起こしており、<a href="https://twitter.com/Yuchenj_UW/status/1944962450954313841">@Yuchenj_UW</a>は<strong>Meta</strong>が「もう一つのOpenAI」に変わりつつあることで、西洋が「中国にオープンソースAIの存続を頼らざるを得なくなるかもしれない」と述べています。</li>
<li><strong>M&amp;A活動と予測</strong>：<strong>Cognition</strong>が<strong>Windsurf</strong>を買収し、Googleを含む入札競争が報じられました。<a href="https://twitter.com/swyx/status/1944902499510653020">@swyx</a>は、<strong>MistralがAppleに買収される可能性</strong>や<strong>Mistralの一部がMetaに買収される可能性</strong>、および<a href="http://character.ai/"><strong>Character.aiがPerplexityに買収される可能性</strong></a>を含む「6つの予測」を投稿しました。</li>
<li><strong>新しいベンチャーとグローバル展開</strong>：<strong>Andrew Ng</strong>は新しいアドバイザリーファーム<strong>AI Aspire</strong>の立ち上げを発表し、<a href="https://twitter.com/AndrewYNg/status/1945148766962729370"><strong>Bain &amp; Company</strong>と提携</a>して企業のAI戦略を支援します。<strong>Cohere</strong>は<a href="https://twitter.com/aidangomez/status/1944913553640558638">韓国ソウルに初のアジアオフィスを開設</a>します。新しいスタートアップ<strong>Thinking Machines Lab</strong>は<a href="https://twitter.com/lilianweng/status/1945184437185966149">野心的なマルチモーダルAIプログラムのための採用</a>を発表しました。</li>
<li><strong>長期的な努力と実行の重要性</strong>：<a href="https://twitter.com/AravSrinivas/status/1944895074774737130">@AravSrinivas</a>は現在のAI競争を「10年間の長期的な努力」と表現し、誰にとっても成功が保証されていないと述べています。<a href="https://twitter.com/andrew_n_carr/status/1944889836424355852">@andrew_n_carr</a>は「oaiで定期的に手作業でデータをラベル付けしていた」と述べ、実行と集中したチームの重要性を強調しています。</li>
</ul>
<h2 id="_3"><strong>ユーモア、ミーム、文化</strong></h2>
<ul>
<li><strong>共感できるコメント</strong>：<a href="https://twitter.com/stephenroller/status/1945096001959698791">@stephenroller</a>の「ミレニアル世代は『lol』を電報の最後のSTOPのように使うlol」という観察が最も「いいね」を集めました。<a href="https://twitter.com/willdepue/status/1944889768812089707">@willdepue</a>は新しい最大の侮辱を提案しました：「あなたは根本的に好奇心がない、それには治療法がない。」</li>
<li><strong>業界内ジョーク</strong>：<a href="https://twitter.com/jeremyphoward/status/1944876105393168394">@jeremyphoward</a>の「管理職：世界が本当に必要としているものは新しいvscodeフォークだ」というジョークが冗長なプロジェクトの感覚を捉えました。<a href="https://twitter.com/dylan522p/status/1945032974434537945">@dylan522p</a>はモデルを<strong>fp4</strong>に量子化した結果の混乱を描いたミームを投稿しました。</li>
<li><strong>Grokコンパニオンの熱狂</strong>：<strong>xAI</strong>のコンパニオンの発売によりミームが氾濫し、<a href="https://twitter.com/ebbyamir/status/1944961018649829797">@ebbyamir</a>が新機能でタイムラインが支配されている投稿をリツイートしました。</li>
<li><strong>開発者の経験</strong>：<a href="https://twitter.com/skalskip92/status/1945142384578240748">@skalskip92</a>は「何をしているのか全く分からないが、それでも動作する時」というキャプション付きの人気動画を投稿し、ソフトウェア開発における共通の感情を捉えました。</li>
</ul>
<hr />
<h1 id="ai-reddit-recap">AI Reddit Recap</h1>
<h2 id="rlocalllama-rlocalllm-recap">/r/LocalLlama + /r/localLLM Recap</h2>
<h3 id="1-kimi-k2api">1. Kimi K2モデルのベンチマーク、APIアクセス、コミュニティミーム</h3>
<ul>
<li><a href="https://i.redd.it/q48f55vcpwcf1.jpeg"><strong>Kimi K2が創造的なライティングベンチマークでトップに</strong></a> (<a href="https://www.reddit.com/r/LocalLLaMA/comments/1lzywie/kimi_k2_tops_creative_writing_benchmark/">スコア: 300、コメント: 63</a>)：<strong>この棒グラフは、創造的なライティングベンチマークでさまざまな言語モデルをランク付けしており、Kimi K2が平均スコア8.56でトップに立ち、DeepSeek V3、Gemma 27B、Gemini 2.5 Proなどの主要な代替モデルに比べて創造的なライティングタスクで優れた性能を示しています。この視覚的な比較は、Kimi K2が現在のモデル創造性ベンチマークで優位性を持っていることを示す実証的な証拠を提供します。</strong>複数のコメントは、DeepSeek V3 0324がGemma 27Bよりも実際の創造的なライティング使用で劣るというベンチマーク結果の正確性に疑問を呈し、Kimi K2の認識された優位性に対する懐疑的な意見を示しています。<ul>
<li>複数のユーザーがKimi K2、DeepSeek V3 0324、Gemma 27B、Gemini 2.5 Proを創造的なライティングタスクで比較しています。一部のコメントは、DeepSeek V3 0324がGemma 27Bを創造的なライティングで大幅に上回ると主張し、個人的なテストでは大きな品質差があると示唆しています。一方、他のコメントはK2がDeepSeekやGemini 2.5 Proよりも大幅に優れているわけではないと主張しています。これらの比較は、著名なオープンおよびプロプライエタリモデル間の主観的な性能認識を反映しています。</li>
<li>技術的に洞察力のあるコメントは、Kimi K2が創造的なライティングベンチマークで優れた性能を発揮する能力をその潜在的なコーディング能力に関連付けています。コメントは、さまざまな制約と構造化された出力（例：複数の要素を持つ物語）を統合する必要があるタスクで優れることが、プログラム合成や複雑なソフトウェア計画の実行に必要なスキルと密接に関連していると主張しています。証拠として、彼らはベンチマーク結果とClineでのコード生成信頼性のテスト結果との相関を観察しています。</li>
<li>議論はタスク固有のモデル性能に分岐しています：一部のユーザーは、Kimi K2がロールプレイではあまり一貫性がなく面白くないと感じており、他のモデルに比べてマルチターンや会話形式でのコンテキストと物語のエンゲージメントを維持するのに苦労していると示唆しています。各モデルの強みのニュアンスは、正確な創造的ライティングタスク（物語構造、RP、制約の遵守など）に依存しているようです。</li>
</ul>
</li>
<li><a href="https://openrouter.ai/moonshotai/kimi-k2"><strong>Kimi K2：ローカルで実行できない人々のための安価で高速なAPIアクセス</strong></a> (<a href="https://www.reddit.com/r/LocalLLaMA/comments/1m0cgnl/kimi_k2_cheap_and_fast_api_access_for_those_who/">スコア: 146、コメント: 64</a>)：<strong>投稿は、オープンウェイトKimi-K2モデル（<a href="https://huggingface.co/moonshotai/Kimi-K2-Instruct">moonshotai/Kimi-K2-Instruct</a>）への新しいAPIエンドポイントの利用可能性を強調しており、DeepInfraが最も低価格のAPI料金（</strong><code>$0.55/$2.20</code> <strong>in/out百万トークン）を提供し、Groqが最も高い推論速度（約</strong><code>250トークン/秒</code> <strong>）を提供していると述べています。ただし、料金は高めです。投稿者は、Kimi-K2のAPIアクセスがClaude Haiku 3.5、GPT-4.1、Gemini 2.5 Proなどの閉鎖モデルよりも安価であると強調し、許容的なオープンウェイトモデルの価値を強調しています。すべてのプロバイダーは<a href="https://openrouter.ai/moonshotai/kimi-k2">OpenRouter</a>にリストされています。無料バリアントも言及されています。詳細については<a href="https://deepinfra.com/moonshotai/Kimi-K2-Instruct">DeepInfra料金</a>および<a href="https://console.groq.com/docs/model/moonshotai/kimi-k2-instruct">Groqドキュメント</a>を参照してください。</strong>トップコメントは、（1）公式Moonshot APIを使用する方が好ましいかどうか（さらに低価格の料金を提供している）、（2）Kimi-K2のAnthropic互換APIエンドポイントが特定の環境変数を設定することでClaude Codeインターフェースを可能にすることを指摘し、安価な（ただし遅い）Claude互換推論を提供すること、（3）ほとんどのユーザーにとって「ローカル」アクセスが高いハードウェア要件のために現実的でないことへの懐疑的な意見を挙げています。<ul>
<li>コメントの一つは、Kimi K2のAnthropic互換APIの利点を強調しており、ユーザーがANTHROPIC_AUTH_TOKENとANTHROPIC_BASE_URLをMoonshotのエンドポイントに設定することで、Claude Codeなどのクライアントを簡単にリダイレクトできることを指摘しています。このアプローチは公式Anthropicアクセスよりも「遅いがはるかに安価」であり、互換性と経済性を必要とする開発者にとって費用対効果の高いソリューションとなっています。</li>
<li>無料プランについての明確化があります：Kimi K2は1日あたり最大500kトークンの無料使用を提供しており、これはかなりの許容量です。ただし、Kimi K2がコンテキストキャッシュなどの高度な機能をサポートしているかどうかは不明であり、これが特定の高スループットまたはコンテキスト感知タスクの性能や費用対効果に影響を与える可能性があります。</li>
<li>Kimi-K2の主なHuggingFaceリポジトリ（https://huggingface.co/moonshotai/Kimi-K2-Instruct）が参照されており、コメントはほとんどのユーザー（「99.9%」）が大規模モデルのローカル推論に必要なハードウェアを持っていない現実を強調しており、安価でアクセス可能なAPIエンドポイントの需要がローカル展開よりも高いことを示しています。</li>
</ul>
</li>
<li><a href="https://i.redd.it/nl35mhaybxcf1.jpeg"><strong>ありがとう、Unsloth！あなたたちは伝説です！（今はDDR5の256GBが必要です）</strong></a> (<a href="https://www.reddit.com/r/LocalLLaMA/comments/1m021nx/thank_you_unsloth_you_guys_are_legends_now_i_just/">スコア: 222、コメント: 27</a>)：<strong>画像は、UnslothがKimi K2-1T MoE大規模言語モデルの1.8ビットバージョンに使用した動的量子化プロセスを古典的な映画のシーンに例えたミームです。動的量子化はモデルサイズとメモリ要件を削減するための技術であり、タイトルとコメントが示すように、256GBのDDR5のような非常に高いハードウェア要件なしでKimi K2-1T MoEのような巨大モデルを実行するために重要です。このミームは超低ビット量子化の最近の革新を認識しており、モデル効率を劇的に向上させる可能性があります。</strong>コメントは、さらに積極的なモデルサイズ削減（例：「蒸留された32b以下のモデル」や「0.11ビットバージョン」のリクエスト）への関心を示し、極端なメモリと計算効率を求めるコミュニティの願望を反映しています。また、Unslothチームへの感謝が表明され、これがしばらくの間必要な最大モデルサイズであることを願う声があり、巨大モデルの実行の課題を示しています。<ul>
<li>Ardalokは量子化戦略について議論し、DeepSeekのようなモデルが効率性のためにより高い量子化レベルを使用できる可能性を示唆しています（おそらくint4/int8または類似のスキームを参照）。また、Unslothの作業が研究にとって価値がある一方で、他のセットアップが実用的な展開にとって優れている可能性があることを示唆しています。特にリソースが制約された環境では。</li>
<li>oh_my_right_legは実用的な展開について質問し、DDR5 RAMで大規模モデルを実行する際のプロンプトおよび生成フェーズのトークン毎秒（token/s）などの性能指標を具体的に尋ねています。また、専門家モデルパラメータをGPU VRAMにロードしながらモデルの残りをシステムDDR5に保存する（MoEアーキテクチャやVLLMなどのツールを使用する）方法について質問し、VRAMが限られているがシステムRAMが豊富なハードウェアで速度とメモリ要件のバランスを取るための潜在的なアプローチを強調しています。</li>
</ul>
</li>
</ul>
<h3 id="2-aimetaexaonevoxtralllama-4">2. AIモデルのローンチとインフラストラクチャのマイルストーン（Meta、EXAONE、Voxtral、Llama 4）</h3>
<ul>
<li><a href="https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-32B"><strong>EXAONE 4.0 32B</strong></a> (<a href="https://www.reddit.com/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/">スコア: 278、コメント: 101</a>)：<a href="https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-32B">**EXAONE 4.0-32B</a>は、LG AI Researchによる30.95Bパラメータの多言語LLMであり、ハイブリッドアテンション（ローカル/グローバル混合比3:1、グローバルにはRoPEなし）、QK-Reorder-Norm（Q/Kプロジェクション後のRMSNorm、Post-LN）、131kトークンのコンテキストウィンドウ、GQA（40アテンションヘッド、8キーバリューヘッド）を特徴としています。モデルはデュアルモード（推論モードと非推論モードの切り替え可能）、エージェントツール使用をサポートし、LiveCodeBenchを含むほとんどの領域でQwen 3 32Bを上回るベンチマーク性能を提供します。その多言語サポートは英語、韓国語、スペイン語に限定されています。展開にはカスタム<a href="https://huggingface.co/docs/transformers/main/en/model_doc/exaone">transformersフォーク</a>が必要であり、公式サポートはTensorRT-LLMに限定されています。商業利用を禁止し、競争を禁止する厳しい非商業ライセンスでリリースされており、商業ライセンスには別途交渉が必要です。**トップコメントは、Qwen 3 32Bに対するモデルのベンチマークの強み、商業利用を妨げる制限的な非商業ライセンス、比較的狭い多言語サポート（3言語のみ）について議論しています。<ul>
<li>EXAONE 4.0 32Bは、ほとんどのベンチマークでQwen 3 32Bを上回っており、LiveCodeBenchのような専門的なベンチマークを含む、競合他社に対する技術的進歩を強調しています。</li>
<li>モデルのライセンスは厳密に非商業的であり、明示的な許可なしでは商業展開や派生利用を禁止しています。また、競合モデルの開発にモデルやその出力を使用することを制限しており、スタートアップや研究環境での採用を制限する可能性があります。</li>
<li>EXAONE 4.0 32Bの多言語サポートは現在、英語、韓国語、スペイン語の3言語に限定されています。これは、より広範な多言語能力を目指す一部の主要なオープンモデルと比較して著しく制限されています。</li>
</ul>
</li>
<li><a href="https://i.redd.it/584vdadc4xcf1.png"><strong>Metaが1GWスーパークラスターを初めて実現する研究所になる予定</strong></a> (<a href="https://www.reddit.com/r/LocalLLaMA/comments/1m0115d/meta_on_track_to_be_first_lab_with_a_1gw/">スコア: 185、コメント: 84</a>)：<strong>画像は、Metaが初の1GW（ギガワット）スーパークラスターを立ち上げる予定であることを示す発表を紹介しており、データセンターとAI計算インフラストラクチャにおける大きな飛躍を示しています。Meta Superintelligence Labsは、PrometheusやHyperionを含む複数のマルチGWクラスターを設立する予定であり、業界で利用可能なAI計算能力と研究能力をリードすることを目指した大規模な投資を強調しています。このマイルストーンは、ハードウェア取得とデータセンターエンジニアリングの両方の進歩を反映しています。</strong>コメントは、このような急速な計算拡張の持続可能性について懐疑的であり、歴史的な軍拡競争に例え、成長と株価上昇を追求するこの取り組みが最終的にこれらの企業にとって持続可能であるかどうかについて懸念を表明しています。<ul>
<li>コメントの一つは、計算能力を増やすことが製品の品質を保証するものではないと指摘し、Llama 4のケースを引用して、リソースが大幅に投入されても望ましい結果に結びつかない場合があることを示しています。これは、スーパークラスターを拡大してモデルトレーニングを行う際に観察されることがある「収益の減少」や「非効率性」を強調しています。</li>
<li>Metaの生成AI製品の現状を考慮すると、計算インフラストラクチャへの多額の投資戦略に懐疑的な意見があり、ユーザーエンゲージメントが低く、モデル性能が印象的でないことを証拠として、計算投資がビジネスや技術的な結果を保証するものではないと述べています。</li>
<li>現在のAI計算競争の持続可能性について懸念が表明されており、過剰な投資が最終的に大企業にも害を及ぼす可能性がある歴史的なシナリオに例えられています。特に、具体的な結果（より良いモデル、広範な採用）がすぐに実現されない場合には。</li>
</ul>
</li>
<li><a href="https://huggingface.co/mistralai/Voxtral-Mini-3B-2507"><strong>mistralai/Voxtral-Mini-3B-2507 · Hugging Face</strong></a> (<a href="https://www.reddit.com/r/LocalLLaMA/comments/1m0k22v/mistralaivoxtralmini3b2507_hugging_face/">スコア: 261、コメント: 45</a>)：<a href="https://huggingface.co/mistralai/Voxtral-Mini-3B-2507">**Voxtral-Mini-3B-2507</a>は、MistralAIのMinistral-3Bをベースにした3Bパラメータのマルチモーダルモデル（音声-テキスト）であり、最先端の音声文字起こし、堅牢な多言語サポート、文字起こしモード、直接音声Q&amp;A/要約、音声からの関数呼び出しを提供し、<strong>32kトークン</strong>のコンテキストウィンドウとvLLMベースのPython推論（GPU：bf16/fp16で約9.5GB）を備えています。公開音声データセットで競争力のあるWERをベンチマークしながら、強力なテキスト能力を維持しています。また、より大きな24Bパラメータの兄弟モデル<a href="https://huggingface.co/mistralai/Voxtral-Small-24B-2507">Voxtral-Small-24B-2507</a>も強調されています。**議論は、より大きなモデルバリアントの存在を指摘し、モデル性能のスケーリングと比較ベンチマークに対するコミュニティの関心を示しています。<ul>
<li>Voxtral Miniモデルは、文字起こしタスクでOpenAI Whisperを上回り、価格が半分以下であると報告されています。追加の技術的特徴として、自動言語認識と英語、スペイン語、フランス語、ポルトガル語、ヒンディー語、ドイツ語、オランダ語、イタリア語などの主要言語での最先端の文字起こし性能が含まれています。</li>
<li>Voxtral Miniは音声からテキストへのモデル（音声から文字起こしではない）として説明されており、音声-テキスト変換において2番目に優れたオープンモデルとして位置付けられています。より大きなVoxtral 24BモデルはStepfun Audio Chatモデルよりも能力が劣ると考えられていますが、効率的なパラメータ数（<code>24B</code>対<code>132B</code>）を提供しており、性能と効率の間で強力なトレードオフを提供しています。</li>
<li>Voxtralモデルの24Bパラメータバリアントが利用可能であり（<a href="https://huggingface.co/mistralai/Voxtral-Small-24B-2507">リンク</a>）、異なる計算ニーズを持つユーザーに柔軟性を提供し、モデルサイズと性能の間でより多くの選択肢を提供しています。</li>
</ul>
</li>
<li><a href="https://analyticsindiamag.com/global-tech/meta-plans-to-abandon-llama-4-behemoth-but-why/"><strong>さて、もし誰かがLlama 4 Behemothを待っていたなら、それは消えました</strong></a> (<a href="https://www.reddit.com/r/LocalLLaMA/comments/1m0g2mk/well_if_anyone_was_waiting_for_llama_4_behemoth/">スコア: 349、コメント: 112</a>)：<strong>Metaは、2TパラメータモデルであるLlama 4 Behemothのオープンソース化計画を技術的な失敗のために中止したと報じられています。メモリに収めるためのチャンク化されたアテンションの使用が長いコンテキスト推論を劣化させ、トレーニング中にMixture of Experts（MoE）ルーティングを切り替えることで不安定性を引き起こしたことが主な原因です。さらに、データの重複排除が不十分であり、アブレーション研究が不完全であり、長いコンテキスト能力の評価インフラストラクチャが不十分であるなどの問題がありました。これらの失敗により、Metaは新しいスーパーインテリジェンスラボの下で閉鎖モデルに焦点を移しました。技術的な批判とエンジニアリングプロセスの失敗についての詳細は<a href="https://analyticsindiamag.com/global-tech/meta-plans-to-abandon-llama-4-behemoth-but-why/">記事</a>にまとめられています。</strong>トップコメントは、失敗した試みの後でもオープンウェイトがまだ価値があるかどうかについて議論しており、一部のユーザーはMetaが過去の失敗から学び、改善されたオープンLlama 5をリリースする代わりにモデルを閉鎖する理由を疑問視しています。また、チャンク化されたアテンションと不安定な専門家ルーティングの負の影響についての技術的な教訓が議論されています。<ul>
<li>コメントの一つは、Llama 4 Behemothプロジェクトにおける特定のアーキテクチャとトレーニングエラーについて議論しており、アテンションチャンク化を変更することでモデルの推論能力に影響を与え、トレーニング中に専門家ルーティング方法を変更することで品質に悪影響を与えた可能性があると指摘しています。これは、トレーニング中の主要な介入がモデル品質に与えるリスクを強調しています。</li>
<li>別のユーザーは、失敗した反復のためにモデルウェイトへのアクセスを閉鎖する理由について疑問を呈し、過去の失敗からオープンに学び、改善されたLlama 5をリリースすることが望ましい戦略であると示唆しています。これは、オープンウェイトリリースがスケーリングの課題に直面する中で、コミュニティの懸念を反映しています。</li>
<li>技術的な感情が業界の傾向に関して表明されており、Behemothの問題により、32BまたはA3B MoEのスケールを超える将来のオープンモデルに対する懐疑的な意見があり、「SaaSが勝った」という信念が示されています。これは、オープンリリースがスケーリングの課題に直面する中で、特にオープンリリースがスケーリングの課題に直面する中で、プロプライエタリな大規模モデルへのシフトを示しています。</li>
</ul>
</li>
</ul>
<h3 id="3-ai">3. AI使用トレンド、コミュニティ分析、ローカル推論ミーム</h3>
<ul>
<li><a href="https://www.reddit.com/gallery/1m0d0vz"><strong>AIが職場で実際にどのように使用されているかを調査するために5,000以上のReddit投稿を分析しました（コーディング以外）</strong></a> (<a href="https://www.reddit.com/r/LocalLLaMA/comments/1m0d0vz/analyzed_5k_reddit_posts_to_see_how_people_are/">スコア: 171、コメント: 70</a>)：<strong>5,000以上のReddit投稿のデータセットが分析され、知識労働者によるAIの非コーディング、職場での使用例を調査しました。主な発見には、倫理的リスクに関する報告が比較的少ない（</strong><code>7.9%</code> <strong>のLLMユーザー）ことや、長文コンテンツ生成などの主要な使用例が含まれています。分析方法や職場アプリケーションの分類法は詳細に指定されていません。</strong>コメントは、<code>7.9%</code>の倫理的リスク統計の正確性に疑問を呈し、政策関連のアストロターフィングやボットによる汚染の可能性を示唆し、データセットが限定的またはLLM使用パターンの広範な代表性を持たない可能性があると指摘しています。<ul>
<li>コメントの一つは、「倫理的リスク」に関するLLMユーザーの7.9%という発見に疑問を呈し、この統計が政策研究所のボットによって生成された可能性がある「アストロターフ」コメントによって膨らんでいる可能性を示唆しています。また、データセットの代表性について懐疑的な意見を示しています。</li>
<li>別の技術的懸念は、データセットの小さなサイズと範囲について提起されており、LLMの使用例（数学など）が多く存在するにもかかわらず、これらが分析で過小評価されていると報告されています。これはデータ収集におけるサンプリングまたは分類バイアスを示唆しています。</li>
</ul>
</li>
<li><a href="https://i.redd.it/r05r0wfvn2df1.png"><strong>完全に軽量なローカル推論...</strong></a> (<a href="https://www.reddit.com/r/LocalLLaMA/comments/1m0nutb/totally_lightweight_local_inference/">スコア: 150、コメント: 23</a>)：<strong>ミームは、大規模言語モデルのローカル推論におけるRAM使用量の持続的な高さを風刺的に描いており、積極的な量子化（例：3.5ビットへの削減）後でも、ストレージサイズに対するRAM要件が依然として高いことを示しています。画像は、量子化されたモデルが依然として大量のRAMを必要とし、元のウェイトまたは軽く圧縮されたウェイトのサイズに近づくことがあるという問題を強調しています。これは、消費者ハードウェアで大規模モデルを展開する際の実際的なボトルネックを示しています。</strong>コメントは、量子化数学と実際のRAM要求の不一致を指摘し、推論の実用性と効率性について議論しています。また、メモリ要件を軽減するための潜在的な緩和策としてファイルバックされたmmapを言及しています。<ul>
<li>軽量なローカル推論の主張について懐疑的な意見があり、特に大規模モデルを消費者ハードウェアで効率的に実行する可能性について、数学が主張されたリソース/レイテンシーの主張を支持していないようです。</li>
<li>コメントの一つは、ファイルバックされた<code>mmap</code>を使用してメモリ効率の良いモデル読み込みを行う技術を強調しており、限られたRAMを持つシステムでより大きなモデルをロードすることを可能にする仮想メモリを活用しています。</li>
<li>4ビット量子化方法への関心が表明されており、モデルサイズを縮小し推論コストを削減する可能性が認識されていますが、他の量子化戦略との比較や詳細は提供されていません。</li>
</ul>
</li>
</ul>
<hr />
<p>以上が翻訳結果です。</p>
    </main>

    <footer>
        <p>
            <a href="https://github.com/YIPG/ainews">GitHub</a>
            <a href="https://news.smol.ai/">news.smol.ai</a>
        </p>
    </footer>
</body>
</html>