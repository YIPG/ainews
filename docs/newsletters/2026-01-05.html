<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>静かな一日 | AIニュース</title>
    <meta name="description" content="静かな一日 - AIニュース 2026-01-05。最新のAI技術動向を日本語でお届け。">
    <meta name="keywords" content="AI,人工知能,ニュースレター,2026-01-05,機械学習,深層学習,日本語">
    <meta name="author" content="AIニュース">
    <link rel="canonical" href="https://yipg.github.io/ainews/docs/newsletters/2026-01-05.html">
    
    <!-- Open Graph meta tags -->
    <meta property="og:title" content="静かな一日 | AIニュース">
    <meta property="og:description" content="静かな一日 - AIニュース 2026-01-05。最新のAI技術動向を日本語でお届け。">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://yipg.github.io/ainews/docs/newsletters/2026-01-05.html">
    <meta property="og:image" content="https://yipg.github.io/ainews/newsletters/og/2026-01-05.png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:image:type" content="image/png">
    <meta property="og:site_name" content="AIニュース">
    <meta property="og:locale" content="ja_JP">
    <meta property="article:published_time" content="2026-01-05T09:00:00+00:00">
    <meta property="article:author" content="AIニュース">
    <meta property="article:section" content="AI技術ニュース">
    
    <!-- Twitter Card meta tags -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="静かな一日 | AIニュース">
    <meta name="twitter:description" content="静かな一日 - AIニュース 2026-01-05。最新のAI技術動向を日本語でお届け。">
    <meta name="twitter:image" content="https://yipg.github.io/ainews/newsletters/og/2026-01-05.png">
    
    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>✏️</text></svg>">
    <link rel="alternate icon" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAACXBIWXMAAA7EAAAOxAGVKw4bAAAA">
    
    <!-- RSS Feed -->
    <link rel="alternate" type="application/rss+xml" title="AIニュース RSS Feed" href="../feed.xml">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: Verdana, Geneva, sans-serif;
            font-size: 1em;
            line-height: 1.7;
            letter-spacing: 0.02em;
            max-width: 720px;
            margin: 0 auto;
            padding: 20px;
            background-color: #fff;
            color: #111;
            word-wrap: break-word;
        }
        
        nav {
            margin-bottom: 25px;
            padding-bottom: 15px;
            border-bottom: 1px solid #ddd;
            display: flex;
            align-items: center;
            justify-content: space-between;
            flex-wrap: nowrap;
        }
        
        .site-title {
            font-size: 1.1em;
            font-weight: bold;
            color: #111;
            text-decoration: none;
            flex-shrink: 0;
        }
        
        .site-title:hover {
            text-decoration: underline;
        }
        
        .nav-links {
            font-size: 0.85em;
            white-space: nowrap;
        }
        
        .nav-links a {
            color: #111;
            text-decoration: none;
            margin-left: 12px;
        }
        
        .nav-links a:hover {
            text-decoration: underline;
        }
        
        
        h1, h2, h3, h4, h5, h6 {
            margin: 35px 0 20px 0;
            line-height: 1.3;
            color: #111;
            letter-spacing: 0.01em;
        }
        
        h1 { font-size: 1.5em; }
        h2 { font-size: 1.3em; }
        h3 { font-size: 1.1em; }
        
        p {
            margin: 20px 0;
        }
        
        a {
            color: #0969da;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin: 20px 0;
            padding-left: 30px;
        }
        
        li {
            margin: 8px 0;
        }
        
        blockquote {
            border-left: 3px solid #ccc;
            margin: 25px 0;
            padding: 0 25px;
            color: #555;
            font-style: italic;
        }
        
        code {
            background-color: #f6f8fa;
            padding: 2px 4px;
            border-radius: 3px;
            font-family: 'Courier New', Courier, monospace;
            font-size: 0.9em;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            padding: 20px;
            overflow-x: auto;
            margin: 25px 0;
        }
        
        pre code {
            background: none;
            padding: 0;
        }
        
        img {
            max-width: 100%;
            height: auto;
            margin: 25px 0;
            border-radius: 3px;
        }
        
        hr {
            border: none;
            border-top: 1px solid #ddd;
            margin: 35px 0;
        }
        
        footer {
            margin-top: 40px;
            padding-top: 15px;
            border-top: 1px solid #ddd;
            text-align: center;
            color: #555;
            font-size: 0.85em;
        }
        
        footer a {
            color: #555;
            text-decoration: none;
            margin: 0 8px;
        }
        
        footer a:hover {
            text-decoration: underline;
        }
        
        @media (max-width: 600px) {
            body {
                padding: 15px;
                font-size: 0.95em;
            }
            
            nav {
                flex-direction: column;
                align-items: flex-start;
                gap: 10px;
            }
            
            .nav-links {
                font-size: 0.8em;
            }
            
            .nav-links a {
                margin-left: 0;
                margin-right: 12px;
            }
            
            .article-title {
                font-size: 1.4em;
            }
        }
        
        @media (max-width: 480px) {
            body {
                font-size: 0.9em;
                padding: 12px;
            }
            
            .site-title {
                font-size: 1em;
            }
            
            .nav-links {
                font-size: 0.75em;
            }
            
            .article-title {
                font-size: 1.3em;
            }
        }
        
        @media (prefers-color-scheme: dark) {
            body {
                background-color: #111;
                color: #eee;
            }
            
            nav {
                border-bottom-color: #444;
            }
            
            .site-title, .nav-links a, .article-title, h1, h2, h3, h4, h5, h6 {
                color: #eee;
            }
            
            .article-date {
                color: #ccc;
            }
            
            blockquote {
                border-left-color: #555;
                color: #ccc;
            }
            
            code {
                background-color: #2d3748;
                color: #e2e8f0;
            }
            
            pre {
                background-color: #2d3748;
            }
            
            hr, footer {
                border-color: #444;
            }
            
            footer, footer a {
                color: #ccc;
            }
        }
    </style>
</head>
<body>
    <nav>
        <a href="../index.html" class="site-title">✏️ AIニュース</a>
        <div class="nav-links">
            <a href="../index.html">ホーム</a>
            <a href="./archive.html">アーカイブ</a>
            <a href="../feed.xml">RSS</a>
            <a href="https://github.com/YIPG/ainews">GitHub</a>
        </div>
    </nav>

    <main>
        <p><strong>静かな一日</strong></p>
<hr />
<h1 id="ai-twitter">AI Twitterまとめ</h1>
<p><strong>注目度の高かったツイート</strong></p>
<ul>
<li><strong>ベトナムの成長ストーリー</strong>：バイラルな投稿が、製造業の高度化を背景にベトナムがタイを抜き東南アジア第2の経済になると予測。一方でタイは観光依存が強いと指摘 <a href="https://twitter.com/okaythenfuture/status/2008023248706089221">tweet</a>。</li>
<li><strong>Microsoftが1-bit推論をオープンソース化との噂</strong>：Microsoftが<code>bitnet.cpp</code>を公開し、非常に大規模なモデルをCPUで高速かつ省エネで推論可能にしたとの高エンゲージメント投稿 <a href="https://twitter.com/simplifyinAI/status/2008195754092065050">tweet</a>（ツイート情報として扱い、詳細はリポジトリやドキュメントで要確認）。</li>
<li><strong>ロボティクスのニュース</strong>：Google DeepMindがBoston DynamicsとGemini Robotics＋Atlasハードウェアに関する研究提携を発表 <a href="https://twitter.com/GoogleDeepMind/status/2008283100254494916">post</a>、Demis Hassabisによるフォローアップ <a href="https://twitter.com/demishassabis/status/2008307002699612586">post</a>。</li>
</ul>
<hr />
<p><strong>エージェント型コーディングの一般化：ハーネス、メモリ、そして「ソフトウェアエンジニアリング時代」の議論</strong></p>
<ul>
<li><strong>「実用性の閾値」＋ワークフローの変化</strong>：複数の実務者が、モデルがソフトウェアエンジニアリングにおいて「使える」レベルに達したと主張。もはや「コードが書けるか？」ではなく「どうエージェントを管理・構成するか？」が課題に <a href="https://twitter.com/gdb/status/2007938049209254002">@gdb</a>、<a href="https://twitter.com/tekbog/status/2007928317236949387">@tekbog</a>は「コードは常に簡単な部分だった」と述べる。<a href="https://twitter.com/ZechenZhang5/status/2007917489397920186">@ZechenZhang5</a>は「vibe coding」を<strong>agentic coding</strong>と呼び、人間の注意・監督を希少資源として強調。</li>
<li><strong>次のインフラ層としてのエージェントハーネス</strong>：Philipp Schmidは2026年は<strong>Agent Harnesses</strong>の年になると予測。長期タスクのライフサイクル、ツールポリシー、HITL、計画フック、「コンテキスト耐久性」を標準化し、ベンチマークからユーザー体験への橋渡しを行うと主張 <a href="https://twitter.com/_philschmid/status/2008175408923959574">@_philschmid</a>。<a href="https://twitter.com/kchonyc/status/2008146568265007407">@kchonyc</a>は「設計パターン＞モデル差分」と述べ、<a href="https://twitter.com/Vtrivedy10/status/2008197837410938931">@Vtrivedy10</a>は「オープンハーネス」を求める。</li>
<li><strong>コーディングエージェントの永続メモリ</strong>：「Claude-Mem」はローカルSQLiteベースのメモリプラグインで、ツール使用や観察の圧縮セマンティック要約を保存し、少ないトークンで作業再開やツール呼び出しを可能にする（「Endless Mode」）<a href="https://twitter.com/LiorOnAI/status/2008161724902355118">@LiorOnAI</a>、リポジトリリンクは<a href="https://twitter.com/LiorOnAI/status/2008161726345134449">こちら</a>。</li>
<li><strong>仕様問題／抽象化への反発</strong>：エージェントに10万行のコードを出力させるのは誤った抽象化であり、会話以外の意図指定方法や意図を保持・構成できる中間表現が必要とする反論。DSPyはこの「仕様責任」をうまく扱っていると評価 <a href="https://twitter.com/lateinteraction/status/2008215241004605922">@lateinteraction</a>ほか。UX／抽象化を上位に引き上げるべきとの主張。</li>
<li><strong>実務的なスケーリング課題：並列エージェント＋権限リスク</strong>：多数のエージェントを並行実行する「ウィンドウスワイプ」ワークフローで頻繁にクラッシュするとの報告 <a href="https://twitter.com/itsclivetime/status/2007975171219771758">@itsclivetime</a>、広範な権限で夜間稼働させることへの懸念も <a href="https://twitter.com/JFPuget/status/2008133619911381457">@JFPuget</a>。</li>
</ul>
<hr />
<p><strong>オープンツール＋推論効率化：プルーニング、軽量vLLMクローン、メモリ／VRAM計算機、そして（噂の）1-bit CPU推論</strong></p>
<ul>
<li><strong>統合プルーニングコードベース（JAX）</strong>：<strong>LLM-Pruning Collection</strong>が公開され、ブロック／レイヤー／重みレベルの手法（Minitron, ShortGPT, Wanda, SparseGPT, LLM-Pruner）を再現・ベンチマーク可能。GPU（FMS-FSDP）＋TPU（MaxText）対応 <a href="https://twitter.com/liuzhuang1234/status/2007930641061740556">@liuzhuang1234</a>。</li>
<li><strong>推論エンジンの断片化（良い意味で）</strong>：vLLMは教育・実験用の最小実装（<code>nanovllm</code>, <code>minivllm</code>, <code>tiny-llm</code>）の波を紹介し、自身もコアアーキテクチャを簡素化・拡張性向上へリファクタ <a href="https://twitter.com/vllm_project/status/2007993964742500396">@vllm_project</a>。</li>
<li><strong>デプロイ用モデルサイズ計算</strong>：<code>hf-mem</code>はHugging FaceのsafetensorsリポジトリのVRAMをメタデータから推定。軽量CLIは<code>uvx</code>で提供 <a href="https://twitter.com/alvarobartt/status/2008214540463341826">@alvarobartt</a>。</li>
<li><strong>Apple Siliconでのローカルトレーニング／推論の利便性</strong>：Unsloth-MLXがMac上でのローカルファインチューニングを可能にするAPIを提供 <a href="https://twitter.com/_ARahim_/status/2008221602283225371">@ <em>ARahim</em></a>。Mawjによる「MLX Engine Revolution」改善も報告 <a href="https://twitter.com/7alkiumi/status/2008082410009956507">@7alkiumi</a>。</li>
<li><strong>Microsoft <code>bitnet.cpp</code>の噂</strong>：Microsoftが<code>bitnet.cpp</code>を公開し、最大100BパラメータのLLMをCPUで1-bit推論可能にしたとの投稿 <a href="https://twitter.com/simplifyinAI/status/2008195754092065050">@simplifyinAI</a>。対応アーキテクチャ、精度差、カーネル対応範囲、GPU量子化ベースラインとの比較など検証が必要。</li>
</ul>
<hr />
<p><strong>モデルリリース、ベンチマーク、マルチモーダル進展（＋LLM物理学的懐疑論）</strong></p>
<ul>
<li><strong>新しい小型推論モデル（7Bクラス）</strong>：TIIの<strong>Falcon H1R-7B</strong>は<strong>mamba-transformerハイブリッド</strong>で<strong>256kコンテキスト</strong>、数学・コーディング性能が高いとされる <a href="https://twitter.com/mervenoyann/status/2008140906814468442">@mervenoyann</a>。別投稿ではAIME24で88％、AIME25で83％との報告 <a href="https://twitter.com/kimmonismus/status/2008188516329542010">@kimmonismus</a>。</li>
<li><strong>大規模MoEのトレーニングレシピ（EXAONE）</strong>：LGの<strong>K-EXAONE 236B MoE（23Bアクティブ）</strong>技術レポートが、Muon、WSD LRスケジュール、FP8、DeepSeek負荷分散、SWA、MTP、GRPO変種AGAPO＋独自の嗜好学習を含む具体的スタックを紹介 <a href="https://twitter.com/eliebakouch/status/2008182861791170674">@eliebakouch</a>。</li>
<li><strong>画像モデルのランキング変動</strong>：ArenaはQwen画像モデルの順位上昇を報告。<strong>Qwen-Image-Edit-2511</strong>が画像編集でオープンモデル1位、<strong>Qwen-Image-2512</strong>がテキスト→画像でオープンモデル2位 <a href="https://twitter.com/arena/status/2008238877589258449">@arena</a>。</li>
<li><strong>ベンチマークの信頼性と「ノイズ」議論</strong>：評価ノイズや不正の懸念から、変数を制御した「LLM物理学」が必要との主張。小型モデルがアーキテクチャの真実を明らかにする可能性を指摘 <a href="https://twitter.com/GenAI_is_real/status/2007919179274543610">@GenAI_is_real</a>。SWE-benchは「パッチ再利用検出」を追加し、約6.7％の完全一致を除外。</li>
<li><strong>拡散によるマルチモーダル推論</strong>：<strong>DiffThinker</strong>は画像間拡散による推論を提案し、空間精度向上、推論コスト制御、並列候補推論、MLLMとの補完的効果を主張 <a href="https://twitter.com/yafuly/status/2008098428375470556">@yafuly</a>。</li>
</ul>
<hr />
<p><strong>LLM向けRLと評価：GRPO「++」、Cascade RL、推論の信頼性</strong></p>
<ul>
<li><strong>GRPO実践は「GRPO++」</strong>：Cameron WolfeがGRPOの安定化テクニックをまとめたガイドを公開。非対称クリッピング、動的サンプリング、長さバイアス修正、報酬整形、標準偏差正規化の暴走防止、マルチエンジンロールアウトの重要度サンプリング補正などを紹介。</li>
<li><strong>Cascade RL（順次ドメインRL）</strong>：NVIDIAの<strong>Cascade RL</strong>は異種検証方式を混合するよりも、ドメインを順次訓練する方が忘却を減らすと主張。Nemotron-Cascade-8BはLiveCodeBench v6で71.1％、14BモデルはIOI 2025銀メダル獲得。</li>
<li><strong>小型モデルのプロセス信頼性</strong>：「Right-for-Wrong-Reasons」論文は7〜9Bモデルの正答の50〜69％が誤った推論過程を含むと報告。Reasoning Integrity Score（RIS）を導入し、RAGが推論の整合性を改善する一方、自己批判プロンプトは悪化させる可能性を指摘。</li>
</ul>
<hr />
<p><strong>現場のエージェント：コンテスト優勝、文書パイプライン、企業導入、ACIという節目</strong></p>
<ul>
<li><strong>Sakana AIが最適化コンテスト優勝</strong>：Sakanaの<strong>ALE-Agent</strong>がAtCoder Heuristic Contest 058で1位を獲得。複数の最先端モデルを用いた推論時スケーリング、並列コード生成、近傍探索を活用。</li>
<li><strong>文書規模の自動化</strong>：LLM駆動のOCR→翻訳→LaTeX変換パイプラインで1964年のソ連教科書330ページを処理し、TikZで17の図を再構築。</li>
<li><strong>企業導入の進行速度</strong>：ある事例では、導入からPOCまで約2ヶ月、その後急速に多国展開し、8桁ARRの契約に至ったと報告。</li>
<li><strong>Mustafa Suleymanの「ACI」テスト</strong>：<strong>Artificial Capable Intelligence</strong>を次の節目とし、エージェントが合法的に10万ドルを100万ドルにできるかを問う。</li>
</ul>
<hr />
<p><strong>安全性、悪用、ガバナンス摩擦（＋エンゲージメント誘因問題）</strong></p>
<ul>
<li><strong>NCII／画像悪用の懸念</strong>：Margaret Mitchellが非合意の性的画像（NCII）の増加と対応の遅れを指摘。</li>
<li><strong>Grok「脱衣」機能への反発</strong>：ユーザー所有写真のみ編集可能にするなどの制限が容易に可能だが、未対応は嫌がらせやCSAMリスクを助長すると批判。</li>
<li><strong>エンゲージメント誘因が対立を促進</strong>：「戦争や暴力」がエンゲージメントを高める傾向があり、プラットフォームのランキング決定が国家の進路に影響し得ると警告。</li>
<li><strong>採用：リスク評価職</strong>：DeepMind AGI SafetyがGemini向けの壊滅的リスク評価・軽減の研究エンジニアを募集。</li>
</ul>
<hr />
<h1 id="ai-reddit">AI Redditまとめ</h1>
<h2 id="rlocalllama-rlocalllm">/r/LocalLlama + /r/localLLMまとめ</h2>
<h3 id="1-ai">1. ローカライズAIモデルのリリース</h3>
<ul>
<li><strong>台湾文化対応モデル</strong>：Twinkle AIがGoogle Gemma 3をベースに台湾のスラングや地理、ミームを理解する<strong>gemma-3-4B-T1-Instruct</strong>を公開。ZH-tw対応データセットや英語出力性能への関心が寄せられる。</li>
<li><strong>Llama 3.3 8Bの「abliteration」版</strong>：リークされたとされるLlama 3.3 8B 128kモデルを、知能損失を最小化しつつコンプライアンス最適化。KL発散&lt;0.05を達成。IFevalスコア向上と引き換えに多言語性能低下。</li>
</ul>
<h3 id="2-aillm">2. AI／LLM向けオープンソースツール</h3>
<ul>
<li><strong>EasyWhisperUI</strong>：OpenAI Whisperモデル用のクロスプラットフォームGPU対応UI。Electron化でセットアップ簡略化、Vulkan（Windows）やMetal（macOS）対応。Parakeet対応の要望も。</li>
<li><strong>ローカルLLMによるノート／会議記録</strong>：Markdown＋埋め込みのローカル知識ベース、Apple Intelligenceによるオンデバイス音声処理でクラウド不要。プライバシーや遅延削減の利点が議論される。</li>
<li><strong>AI Judgment Trailデモ</strong>：実行された／スキップされた判断をログ化し、ポリシー逸脱を可視化するパターンを紹介。</li>
</ul>
<h3 id="3-llm">3. LLMの予算・ハードウェア検討</h3>
<ul>
<li><strong>予算内LLMセットアップ相談</strong>：GTX 970からRTX 3060 12GBへのアップグレード検討。小型モデルや量子化での運用に適し、RAM増設が推奨される。</li>
<li><strong>LinuxでのRTX 5060 TI運用</strong>：NvidiaのLinux対応は2022年以降改善。RedHat系ではCUDAインストールが容易。</li>
<li><strong>軽量モデルによるライブ配信コメント</strong>：Llama 3.1 8Bが性能と資源使用のバランスに優れると評価。</li>
<li><strong>ローカルモデルのパラメータ数アンケート</strong>：Kimi K2モデルの効率性やMOEモデルの需要が議論される。</li>
<li><strong>RTX Pro 6000の価格動向懸念</strong>：メモリ価格や他モデルの値上げ傾向から、価格上昇の可能性が指摘される。</li>
</ul>
<h2 id="ai">技術色の薄いAIサブレまとめ</h2>
<h3 id="1-ai_1">1. クリエイティブ向けオープンソースAIツール</h3>
<ul>
<li><strong>写真をGame Boy ROM化</strong>：SpriteSwap-Studioが写真を4色・256タイル・8KB RAM制約下でROM化。依存関係の柔軟化提案あり。</li>
<li><strong>Brie's Lazy Character Control Suite更新</strong>：Qwen Edit 2511採用でキャラクター制御精度向上。ハードウェア要件やワークフロー改善案が議論される。</li>
</ul>
<h3 id="2-ai">2. AI活用のデザイン／生産性ツール</h3>
<ul>
<li><strong>Claude用UI改善スキル</strong>：8年のプロダクトデザイン経験を凝縮したスキルでUI品質向上。既存スキルとの比較やUX改善の限界が議論される。</li>
<li><strong>CartShame Chrome拡張</strong>：買い物カゴの金額を労働時間換算で表示し購買抑制を狙う。</li>
</ul>
<h3 id="3-ai">3. AI生成画像のコンセプトと批評</h3>
<ul>
<li><strong>「暗い秘密」画像プロンプト</strong>：廃れた技術とデジタル存在の持続をテーマにした映画的コンセプト。</li>
<li><strong>ChatGPTの口調変化への不満</strong>：5.2版で安全性バイアスが強まり、的外れで高圧的な応答が増えたとの批判。</li>
<li><strong>キャラクター一貫性の確立</strong>：Jurassic Parkと90年代シットコム「Dinosaurs」の融合プロジェクト。</li>
<li><strong>高精細CGの驚き</strong>：Twisted Metalのキャラクター描写の進化に驚嘆。</li>
</ul>
<hr />
<h1 id="ai-discord">AI Discordまとめ</h1>
<p>（以下、各Discordチャンネルでの主な話題を要約）</p>
<p><strong>1. 新モデル＆ベンチマーク</strong>
- Falcon-H1R-7BやThoughtWeaver-8B-Reasoning-Expのリリース。
- ImpossibleBenchによる「不可能タスク」時の不正率測定。
- Qwen画像モデルがImage Arenaで上位獲得。</p>
<p><strong>2. RL/GRPOと評価</strong>
- GRPOでLLMの推論効率30％向上を狙う試み。
- Qwen2.5のGRPO＋LoRAトレーニングハンドブック公開。
- GEPA評価でスコアと勝率の乖離が議論。</p>
<p><strong>3. 圧縮＆トレーニング可視化</strong>
- Sparseによるファインチューニングモデルの損失なし圧縮。
- dfloat-11による損失なしLLM圧縮案。
- nvCOMPによるGPU圧縮速度向上。</p>
<p><strong>4. エージェント基盤</strong>
- MCPの機能交渉は「広告」でありハンドシェイクではないとの説明。
- コンテナだけでは不十分なサンドボックス議論。
- Claude CodeやGas Townなど新たなエージェントツールの登場。</p>
<p><strong>5. GPU＆カーネル</strong>
- DGX SparkとJetson Thorの比較。
- B200 GPUによる2-CTA GEMMの実装例。
- CUDA RustによるPython統合カーネル実験。</p>
<p>（その他、各Discordでの詳細な議論やリンクは省略）</p>
    </main>

    <footer>
        <p>
            <a href="https://github.com/YIPG/ainews">GitHub</a>
            <a href="https://news.smol.ai/">news.smol.ai</a>
        </p>
    </footer>
</body>
</html>