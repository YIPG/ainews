<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>オープンモデルにとっての大きな勝利 | AIニュース</title>
    <meta name="description" content="オープンモデルにとっての大きな勝利 - AIニュース 2025-10-27。最新のAI技術動向を日本語でお届け。">
    <meta name="keywords" content="AI,人工知能,ニュースレター,2025-10-27,機械学習,深層学習,日本語">
    <meta name="author" content="AIニュース">
    <link rel="canonical" href="https://yipg.github.io/ainews/docs/newsletters/2025-10-27.html">
    
    <!-- Open Graph meta tags -->
    <meta property="og:title" content="オープンモデルにとっての大きな勝利 | AIニュース">
    <meta property="og:description" content="オープンモデルにとっての大きな勝利 - AIニュース 2025-10-27。最新のAI技術動向を日本語でお届け。">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://yipg.github.io/ainews/docs/newsletters/2025-10-27.html">
    <meta property="og:image" content="https://yipg.github.io/ainews/newsletters/og/2025-10-27.png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:image:type" content="image/png">
    <meta property="og:site_name" content="AIニュース">
    <meta property="og:locale" content="ja_JP">
    <meta property="article:published_time" content="2025-10-27T09:00:00+00:00">
    <meta property="article:author" content="AIニュース">
    <meta property="article:section" content="AI技術ニュース">
    
    <!-- Twitter Card meta tags -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="オープンモデルにとっての大きな勝利 | AIニュース">
    <meta name="twitter:description" content="オープンモデルにとっての大きな勝利 - AIニュース 2025-10-27。最新のAI技術動向を日本語でお届け。">
    <meta name="twitter:image" content="https://yipg.github.io/ainews/newsletters/og/2025-10-27.png">
    
    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>✏️</text></svg>">
    <link rel="alternate icon" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAACXBIWXMAAA7EAAAOxAGVKw4bAAAA">
    
    <!-- RSS Feed -->
    <link rel="alternate" type="application/rss+xml" title="AIニュース RSS Feed" href="../feed.xml">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: Verdana, Geneva, sans-serif;
            font-size: 1em;
            line-height: 1.7;
            letter-spacing: 0.02em;
            max-width: 720px;
            margin: 0 auto;
            padding: 20px;
            background-color: #fff;
            color: #111;
            word-wrap: break-word;
        }
        
        nav {
            margin-bottom: 25px;
            padding-bottom: 15px;
            border-bottom: 1px solid #ddd;
            display: flex;
            align-items: center;
            justify-content: space-between;
            flex-wrap: nowrap;
        }
        
        .site-title {
            font-size: 1.1em;
            font-weight: bold;
            color: #111;
            text-decoration: none;
            flex-shrink: 0;
        }
        
        .site-title:hover {
            text-decoration: underline;
        }
        
        .nav-links {
            font-size: 0.85em;
            white-space: nowrap;
        }
        
        .nav-links a {
            color: #111;
            text-decoration: none;
            margin-left: 12px;
        }
        
        .nav-links a:hover {
            text-decoration: underline;
        }
        
        
        h1, h2, h3, h4, h5, h6 {
            margin: 35px 0 20px 0;
            line-height: 1.3;
            color: #111;
            letter-spacing: 0.01em;
        }
        
        h1 { font-size: 1.5em; }
        h2 { font-size: 1.3em; }
        h3 { font-size: 1.1em; }
        
        p {
            margin: 20px 0;
        }
        
        a {
            color: #0969da;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin: 20px 0;
            padding-left: 30px;
        }
        
        li {
            margin: 8px 0;
        }
        
        blockquote {
            border-left: 3px solid #ccc;
            margin: 25px 0;
            padding: 0 25px;
            color: #555;
            font-style: italic;
        }
        
        code {
            background-color: #f6f8fa;
            padding: 2px 4px;
            border-radius: 3px;
            font-family: 'Courier New', Courier, monospace;
            font-size: 0.9em;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            padding: 20px;
            overflow-x: auto;
            margin: 25px 0;
        }
        
        pre code {
            background: none;
            padding: 0;
        }
        
        img {
            max-width: 100%;
            height: auto;
            margin: 25px 0;
            border-radius: 3px;
        }
        
        hr {
            border: none;
            border-top: 1px solid #ddd;
            margin: 35px 0;
        }
        
        footer {
            margin-top: 40px;
            padding-top: 15px;
            border-top: 1px solid #ddd;
            text-align: center;
            color: #555;
            font-size: 0.85em;
        }
        
        footer a {
            color: #555;
            text-decoration: none;
            margin: 0 8px;
        }
        
        footer a:hover {
            text-decoration: underline;
        }
        
        @media (max-width: 600px) {
            body {
                padding: 15px;
                font-size: 0.95em;
            }
            
            nav {
                flex-direction: column;
                align-items: flex-start;
                gap: 10px;
            }
            
            .nav-links {
                font-size: 0.8em;
            }
            
            .nav-links a {
                margin-left: 0;
                margin-right: 12px;
            }
            
            .article-title {
                font-size: 1.4em;
            }
        }
        
        @media (max-width: 480px) {
            body {
                font-size: 0.9em;
                padding: 12px;
            }
            
            .site-title {
                font-size: 1em;
            }
            
            .nav-links {
                font-size: 0.75em;
            }
            
            .article-title {
                font-size: 1.3em;
            }
        }
        
        @media (prefers-color-scheme: dark) {
            body {
                background-color: #111;
                color: #eee;
            }
            
            nav {
                border-bottom-color: #444;
            }
            
            .site-title, .nav-links a, .article-title, h1, h2, h3, h4, h5, h6 {
                color: #eee;
            }
            
            .article-date {
                color: #ccc;
            }
            
            blockquote {
                border-left-color: #555;
                color: #ccc;
            }
            
            code {
                background-color: #2d3748;
                color: #e2e8f0;
            }
            
            pre {
                background-color: #2d3748;
            }
            
            hr, footer {
                border-color: #444;
            }
            
            footer, footer a {
                color: #ccc;
            }
        }
    </style>
</head>
<body>
    <nav>
        <a href="../index.html" class="site-title">✏️ AIニュース</a>
        <div class="nav-links">
            <a href="../index.html">ホーム</a>
            <a href="./archive.html">アーカイブ</a>
            <a href="../feed.xml">RSS</a>
            <a href="https://github.com/YIPG/ainews">GitHub</a>
        </div>
    </nav>

    <main>
        <h1 id="_1">オープンモデルにとっての大きな勝利</h1>
<p>4か月前に<a href="https://news.smol.ai/issues/25-06-16-chinese-models">MiniMax M1</a>を発表したHailuo AIが、MiniMax M2を発表しました（<a href="https://agent.minimax.io/">無料チャットボット</a>、<a href="https://huggingface.co/MiniMaxAI/MiniMax-M2">モデルウェイト</a>、<a href="https://github.com/MiniMax-AI/MiniMax-M2">GitHub</a>、<a href="https://platform.minimax.io/docs/guides/text-transformers-deployment">ドキュメント</a>）。今回の発表では、非常に高い23倍のスパース性（<a href="https://news.smol.ai/issues/25-09-11-qwen3-next">Qwen-Nextの方が依然として上回る</a>）や、オープンソースとしては最先端の性能を謳っています。</p>
<p><a href="https://resend-attachments.s3.amazonaws.com/OZkMn5R3OhUaghC">人工分析インテリジェンス指数 v3.0 における各AIモデルの性能スコアを示す棒グラフ（MiniMax M2を含む）</a></p>
<p>一方で、<a href="https://x.com/ArtificialAnlys/status/1982714153375854998">非常に冗長な出力をするモデル</a>であることや、<a href="https://x.com/eliebakouch/status/1982835325992149348">技術レポートが公開されなかった</a>点などの懸念もあります。しかし総じて、幅広いベンチマークでクローズドな最先端モデルに迫る非常に優れたモデルローンチとなっています。</p>
<p><a href="https://resend-attachments.s3.amazonaws.com/Nf8xxEXVjO6xZMR">各種タスクにおけるAIモデルの性能ベンチマークを示す棒グラフ（MiniMax M2を赤で強調し、他モデルと比較）</a></p>
<hr />
<h1 id="ai-twitter">AI Twitterまとめ</h1>
<p><strong>MiniMax M2 オープンウェイト公開：コーディング／エージェント向けスパースMoE、高評価、アーキテクチャ解説</strong></p>
<ul>
<li><strong>MiniMax M2（オープンウェイト、MITライセンス）</strong>：MiniMaxはM2を公開しました。これは総パラメータ約200〜230BのスパースMoEモデルで、<strong>有効パラメータは10B</strong>。 “Agent &amp; Code Native”として位置づけられています。API経由で期間限定無料提供、価格は「Claude Sonnetの8%」、速度は約2倍（MiniMax発表）で、MITライセンス。<strong>vLLM</strong>でDay-0サポートされ、Hugging Face、ModelScope、OpenRouter、Baseten、Clineなどで利用可能です。発表と利用可能性はこちら：<a href="https://twitter.com/MiniMax__AI/status/1982674798649160175"> @MiniMax__AI</a>、<a href="https://twitter.com/vllm_project/status/1982675383091916856">@vllm_project</a>ほか。</li>
<li><strong>ベンチマークとコスト</strong>：Artificial Analysis Indexでオープンウェイトとして史上最高スコアを記録し、全体で5位。ツール利用や指示追従（Tau2、IFBenchなど）に強みがあり、汎用タスクではDeepSeek V3.2やQwen3-235Bに劣る場合も。API価格は<strong>入力100万トークンあたり$0.3、出力100万トークンあたり$1.2</strong>と報告。ただし冗長性が高く（評価で約1.2億トークン消費）、実コストに影響。FP8で4×H100に収容可能。詳細スコアは<a href="https://twitter.com/ArtificialAnlys/status/1982714153375854998">@ArtificialAnlys</a>参照。</li>
<li><strong>アーキテクチャ補足（推測の修正）</strong>：初期にはGPT-OSS的なFullAttn+SWAハイブリッドと推測されましたが、エンジニアが<strong>フルアテンション</strong>であると明言。事前学習中にSWAや“lightning/linear”も試したが、多段推論性能が低下したため採用せず。QK-Norm、GQA、部分RoPE、共有なしのMoEなどを使用。コミュニティは“sigmoid routing”や“MTP”も観測。</li>
<li><strong>エコシステムとツール</strong>：vLLMやsglangにDay-0対応PRが入り、ModelScopeやBasetenなど展開経路が拡大中。</li>
</ul>
<p><strong>ポストトレーニングと推論：On-Policy Distillationの再評価、長期推論ベンチ、エージェントフレームワーク</strong></p>
<ul>
<li><strong>On-Policy Distillation（OPD）の再浮上</strong>：OPDは、教師モデルのlogprobを密な監督信号として用い、生徒モデルを自身のロールアウトで訓練する手法。数学推論やチャット品質でRLに匹敵または上回る結果を、計算資源を大幅に削減して達成（例：1800時間OPD vs 18000時間RL）。Gemma 2/3やQwen3-Thinkingでも採用例あり。</li>
<li><strong>RLによるコード性能の注意点</strong>：RLはpass@1を向上させるが、pass@32,64,128,256では改善せず、モード崩壊の兆候があるとの報告。</li>
<li><strong>長期推論（R-HORIZON）</strong>：数学／コード／エージェントタスクを連鎖させる新ベンチマークで、最先端モデルも連鎖長が伸びると急激に性能低下。RLVR+GRPO訓練でAIME24スコアが向上。</li>
<li><strong>Recursive LMと長文コンテキスト</strong>：ルートLMと環境LMを組み合わせ、進化するコンテキストを蓄積し処理する手法。長文ベンチマークで高性能を示す。</li>
</ul>
<p><strong>アーキテクチャとアテンション設計：線形アテンション離れ、MoEの知見、コンテキスト圧縮</strong></p>
<ul>
<li><strong>Linear/SWAからフルアテンションへの移行</strong>：大規模化で推論性能低下が確認され、効率より性能を優先してフルアテンションに回帰する動き。</li>
<li><strong>Qwen3 MoEの解析</strong>：深さ方向のアップサイクリングやルーティング詳細が分析され、可視化の重要性が強調。</li>
<li><strong>Glyphによる長文圧縮</strong>：Zhipu AIのGlyphは長文を画像化しVLMで処理、3〜4倍のトークン圧縮を性能低下なしで実現。</li>
</ul>
<p><strong>インフラと性能：10万GPU規模の集団通信、FP8の実用化、ハードウェア動向</strong></p>
<ul>
<li><strong>MetaのNCCLX</strong>：10万GPU超の大規模クラスタ向け集団通信ライブラリを公開。</li>
<li><strong>FP8トレーニングの成功例</strong>：融合FP8演算子とハイブリッド線形設計で最大5倍のカーネル速度、スループット77%向上を実現。</li>
<li><strong>DGX Sparkの懸念</strong>：消費電力が公称の半分程度、性能も低下との報告。</li>
<li><strong>vLLMアップデート</strong>：Parallel LoRA実行、ロックフリー並列、FlashAttention 2対応で推論3〜4倍高速化。</li>
</ul>
<p><strong>フレームワーク、ライブラリ、コース</strong></p>
<ul>
<li><strong>LangChain/Graph v1</strong>：プロバイダ統一のコンテンツブロック、<code>create_agent</code>抽象化、スタック構造の明確化。無料コースも提供。</li>
<li><strong>Hugging Face Hub v1.0</strong>：大規模データセットのストリーミング対応、CLI刷新。</li>
<li><strong>Keras 3.12</strong>：GPTQ量子化API、蒸留API、PyGrainデータセット対応など。</li>
</ul>
<p><strong>安全性、エンタープライズ、ベンチマーク</strong></p>
<ul>
<li><strong>Anthropicの企業向けシェア拡大</strong>：OpenAIを上回る企業向けLLM APIシェアを獲得。金融向けClaudeも発表。</li>
<li><strong>OpenAIのモデル仕様更新とメンタルヘルス対応</strong>：170人超の臨床医と協議し、センシティブな会話での失敗率を65〜80%削減。</li>
<li><strong>新しい能力追跡</strong>：Epochが透明性の高い能力指数ECIを公開。</li>
</ul>
<p><strong>エンゲージメント上位ツイート</strong></p>
<ul>
<li><a href="https://twitter.com/StefanFSchubert/status/1982688279796625491">AnthropicがOpenAIを企業向けLLM API市場で上回る</a> (3.7k)</li>
<li><a href="https://twitter.com/OpenAI/status/1982858555805118665">OpenAI：170人超の臨床医がChatGPTのセンシティブ対応を改善</a> (3.1k)</li>
<li><a href="https://twitter.com/GladiaLab/status/1982818213206315120">LLMは可逆的で入力復元可能</a> (2.7k)</li>
<li><a href="https://twitter.com/MiniMax__AI/status/1982674798649160175">MiniMax：「M2をオープンソース化、Claude Sonnetの8%の価格で約2倍速」</a> (2.4k)</li>
<li><a href="https://twitter.com/Yuchenj_UW/status/1982658436182712750">DeepSeekが取引ベンチで新記録</a> (2.6k)</li>
</ul>
<hr />
<h1 id="ai-reddit">AI Redditまとめ</h1>
<h2 id="rlocalllama-rlocalllm">/r/LocalLlama + /r/localLLM</h2>
<h3 id="1">1. シリコンバレーでのオープンソースモデル採用</h3>
<ul>
<li><a href="https://www.reddit.com/r/LocalLLaMA/comments/1ohdl9q/silicon_valley_is_migrating_from_expensive/"><strong>シリコンバレーが高価なクローズドモデルから安価なオープンソースへ移行</strong></a>：Chamath Palihapitiya氏が、OpenAIやAnthropicより性能とコスト効率が優れるとしてKimi K2への移行を発表。Kimi K2 0905モデルはGroq上でツール呼び出し性能68.21%を記録。既存のLLaMA 70Bでも対応可能との懐疑的意見もあり。</li>
</ul>
<p>（以下、同様の形式で全文を日本語化）</p>
    </main>

    <footer>
        <p>
            <a href="https://github.com/YIPG/ainews">GitHub</a>
            <a href="https://news.smol.ai/">news.smol.ai</a>
        </p>
    </footer>
</body>
</html>