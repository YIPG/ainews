<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>よくやった、中国AI | AIニュース</title>
    <meta name="description" content="よくやった、中国AI - AIニュース 2025-12-22。最新のAI技術動向を日本語でお届け。">
    <meta name="keywords" content="AI,人工知能,ニュースレター,2025-12-22,機械学習,深層学習,日本語">
    <meta name="author" content="AIニュース">
    <link rel="canonical" href="https://yipg.github.io/ainews/docs/newsletters/2025-12-22.html">
    
    <!-- Open Graph meta tags -->
    <meta property="og:title" content="よくやった、中国AI | AIニュース">
    <meta property="og:description" content="よくやった、中国AI - AIニュース 2025-12-22。最新のAI技術動向を日本語でお届け。">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://yipg.github.io/ainews/docs/newsletters/2025-12-22.html">
    <meta property="og:image" content="https://yipg.github.io/ainews/newsletters/og/2025-12-22.png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:image:type" content="image/png">
    <meta property="og:site_name" content="AIニュース">
    <meta property="og:locale" content="ja_JP">
    <meta property="article:published_time" content="2025-12-22T09:00:00+00:00">
    <meta property="article:author" content="AIニュース">
    <meta property="article:section" content="AI技術ニュース">
    
    <!-- Twitter Card meta tags -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="よくやった、中国AI | AIニュース">
    <meta name="twitter:description" content="よくやった、中国AI - AIニュース 2025-12-22。最新のAI技術動向を日本語でお届け。">
    <meta name="twitter:image" content="https://yipg.github.io/ainews/newsletters/og/2025-12-22.png">
    
    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>✏️</text></svg>">
    <link rel="alternate icon" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAACXBIWXMAAA7EAAAOxAGVKw4bAAAA">
    
    <!-- RSS Feed -->
    <link rel="alternate" type="application/rss+xml" title="AIニュース RSS Feed" href="../feed.xml">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: Verdana, Geneva, sans-serif;
            font-size: 1em;
            line-height: 1.7;
            letter-spacing: 0.02em;
            max-width: 720px;
            margin: 0 auto;
            padding: 20px;
            background-color: #fff;
            color: #111;
            word-wrap: break-word;
        }
        
        nav {
            margin-bottom: 25px;
            padding-bottom: 15px;
            border-bottom: 1px solid #ddd;
            display: flex;
            align-items: center;
            justify-content: space-between;
            flex-wrap: nowrap;
        }
        
        .site-title {
            font-size: 1.1em;
            font-weight: bold;
            color: #111;
            text-decoration: none;
            flex-shrink: 0;
        }
        
        .site-title:hover {
            text-decoration: underline;
        }
        
        .nav-links {
            font-size: 0.85em;
            white-space: nowrap;
        }
        
        .nav-links a {
            color: #111;
            text-decoration: none;
            margin-left: 12px;
        }
        
        .nav-links a:hover {
            text-decoration: underline;
        }
        
        
        h1, h2, h3, h4, h5, h6 {
            margin: 35px 0 20px 0;
            line-height: 1.3;
            color: #111;
            letter-spacing: 0.01em;
        }
        
        h1 { font-size: 1.5em; }
        h2 { font-size: 1.3em; }
        h3 { font-size: 1.1em; }
        
        p {
            margin: 20px 0;
        }
        
        a {
            color: #0969da;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin: 20px 0;
            padding-left: 30px;
        }
        
        li {
            margin: 8px 0;
        }
        
        blockquote {
            border-left: 3px solid #ccc;
            margin: 25px 0;
            padding: 0 25px;
            color: #555;
            font-style: italic;
        }
        
        code {
            background-color: #f6f8fa;
            padding: 2px 4px;
            border-radius: 3px;
            font-family: 'Courier New', Courier, monospace;
            font-size: 0.9em;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            padding: 20px;
            overflow-x: auto;
            margin: 25px 0;
        }
        
        pre code {
            background: none;
            padding: 0;
        }
        
        img {
            max-width: 100%;
            height: auto;
            margin: 25px 0;
            border-radius: 3px;
        }
        
        hr {
            border: none;
            border-top: 1px solid #ddd;
            margin: 35px 0;
        }
        
        footer {
            margin-top: 40px;
            padding-top: 15px;
            border-top: 1px solid #ddd;
            text-align: center;
            color: #555;
            font-size: 0.85em;
        }
        
        footer a {
            color: #555;
            text-decoration: none;
            margin: 0 8px;
        }
        
        footer a:hover {
            text-decoration: underline;
        }
        
        @media (max-width: 600px) {
            body {
                padding: 15px;
                font-size: 0.95em;
            }
            
            nav {
                flex-direction: column;
                align-items: flex-start;
                gap: 10px;
            }
            
            .nav-links {
                font-size: 0.8em;
            }
            
            .nav-links a {
                margin-left: 0;
                margin-right: 12px;
            }
            
            .article-title {
                font-size: 1.4em;
            }
        }
        
        @media (max-width: 480px) {
            body {
                font-size: 0.9em;
                padding: 12px;
            }
            
            .site-title {
                font-size: 1em;
            }
            
            .nav-links {
                font-size: 0.75em;
            }
            
            .article-title {
                font-size: 1.3em;
            }
        }
        
        @media (prefers-color-scheme: dark) {
            body {
                background-color: #111;
                color: #eee;
            }
            
            nav {
                border-bottom-color: #444;
            }
            
            .site-title, .nav-links a, .article-title, h1, h2, h3, h4, h5, h6 {
                color: #eee;
            }
            
            .article-date {
                color: #ccc;
            }
            
            blockquote {
                border-left-color: #555;
                color: #ccc;
            }
            
            code {
                background-color: #2d3748;
                color: #e2e8f0;
            }
            
            pre {
                background-color: #2d3748;
            }
            
            hr, footer {
                border-color: #444;
            }
            
            footer, footer a {
                color: #ccc;
            }
        }
    </style>
</head>
<body>
    <nav>
        <a href="../index.html" class="site-title">✏️ AIニュース</a>
        <div class="nav-links">
            <a href="../index.html">ホーム</a>
            <a href="./archive.html">アーカイブ</a>
            <a href="../feed.xml">RSS</a>
            <a href="https://github.com/YIPG/ainews">GitHub</a>
        </div>
    </nav>

    <main>
        <p><strong>よくやった、中国AI</strong></p>
<p>Z.aiの<a href="https://z.ai/blog/glm-4.7">GLM 4.7</a>とBaiduのERNIE 5.0は注目されましたが、前者は段階的な改良、後者は未公開のため今回は対象外となりました。</p>
<p>一方で、先端エージェント研究所からは3つの新しいAIE CODEトークが公開されています。</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=ShuJ_CN6zr4">Factory AI</a></li>
<li><a href="https://www.youtube.com/watch?v=gvIAkmZUEZY">Amp Code</a></li>
<li><a href="https://www.youtube.com/watch?v=MLhAA9yguwM">Repit Agent</a></li>
</ul>
<p>ぜひご覧ください。</p>
<hr />
<h1 id="ai-twitter">AI Twitterまとめ</h1>
<p><strong>オープンウェイトモデルの新展開：GLM‑4.7、MiMo‑V2‑Flash、画像／動画モデルの動向</strong></p>
<ul>
<li><strong>Zhipu AIのGLM‑4.7リリースと即時エコシステム採用</strong> : Zhipuは<strong>GLM‑4.7</strong>をGLM‑4.6からの大きな進歩と位置付け、<strong>コーディング、複雑な推論、ツール利用</strong>の改善を強調しています（HF上のウェイト、技術ブログ、ホスト型チャットあり）。リリース直後からHFツール経由で利用可能となり、OpenRouterやLM Arena Code Arenaにも登場。WebDevリーダーボードでオープンモデル1位、全体6位を獲得し、GLM‑4.6比で+83ポイントの向上。実務者からは「インタリーブ思考」の挙動変化が指摘され、公式APIでのベンチマーク推奨の声も。</li>
<li><strong>Xiaomi MiMo‑V2‑Flash：実用性重視のMoEモデル</strong> : <strong>MiMo‑V2‑Flash</strong>はコスト・速度・展開性に最適化され、リーダーボード上位狙いではなく現場導入を意識。少ないパラメータで強力なオープンウェイトモデルに匹敵するとの主張もあり、Zhihuではエージェントワークフローや価格（例：入力トークン100万あたり0.1ドル）に関する議論が活発。vLLMは公式のサービングレシピを公開し、コンテキスト長・レイテンシ・KVキャッシュ、DP/TP/EP設定など具体的な調整方法を提示。</li>
<li><strong>オープンウェイトのテキスト→画像競争が激化</strong> : Artificial Analysisは<strong>Z‑Image Turbo</strong>をImage Arenaでのオープンウェイト画像生成モデル1位と報告。6Bパラメータ、Apache‑2.0ライセンス、Alibaba Cloudでの価格比較（例：画像1,000枚あたり5ドル）も提示。</li>
<li><strong>動画モデルは制御性と長編一貫性に進展</strong> : <strong>Kling 2.6 Motion Control</strong>が注目され、ユーザーデモやダンス／アクション制御、falによる即日提供が話題。研究面ではMemFlowが長時間ストリーミング物語向けの適応型メモリ検索を提案。</li>
</ul>
<p><strong>本番環境のエージェント：プロトコル、オーケストレーション、メモリ、サンドボックス、観測性重視のエンジニアリング</strong></p>
<ul>
<li><strong>GoogleのA2UIプロトコル</strong> : エージェントがインタラクティブUIを生成できるオープンソースプロトコル<strong>A2UI</strong>を公開。チャット専用からUI生成へと役割を拡張する動き。</li>
<li><strong>フレームワーク混在が標準に</strong> : 1,575件のエージェントプロジェクト調査で、上位スター獲得プロジェクトの96%が複数フレームワークを組み合わせていることが判明。課題はロジック不具合、終了検知、ツール連携、バージョン互換性など。</li>
<li><strong>メモリパターンと永続化の重要性</strong> : LangChainはOracle支援の永続ストレージ付きエージェントハブと「6つのメモリパターン」を紹介。モデルIQよりも状態・再現性・監査性が制約要因に。</li>
<li><strong>サンドボックス化／非同期実行の実用化</strong> : コーディングエージェントを隔離環境で動作させる事例が増加。Runloop＋DeepAgentsやClaude CodeをModalサンドボックスで動かす事例、git効率化ツールzagiなどが登場。</li>
<li><strong>観測性の欠如が課題</strong> : モデル性能低下の多くは指示の曖昧さやコンテキスト不足が原因であり、LangSmithなどのトレースツールで初めて明らかになると指摘。バックエンド開発同様、計測・ログ・評価を重視すべきとの声。</li>
</ul>
<p><strong>ベンチマーク、評価の政治、進歩の測定方法（METR, Arena, FrontierMath, SWE-bench）</strong></p>
<ul>
<li><strong>METR型評価と検証ボトルネック</strong> : 強化学習の進歩はタスク長より検証時間に制約されるとの見方。能力と検証時間の関係を可視化する提案も。</li>
<li><strong>Arenaによるモデル評価の影響力</strong> : GLM‑4.7のCode Arena順位上昇やBaiduのERNIE‑5.0‑Preview‑1203がLM Arenaテキスト部門上位に。</li>
<li><strong>SWE‑benchでオープンモデルが追い上げ</strong> : GLM‑4.7が73.8%、Kimi K2 Thinkingが73.4%、DeepSeek‑V3.2が73.1%、Claude Sonnet 4.5が77.2%と、クローズドモデルに迫る性能。</li>
<li><strong>FrontierMathのアクセス格差</strong> : 中国のオープンウェイトモデルは最先端に比べ約7か月遅れ、OpenAIはTier 1〜3データ／解答の多くを独占しているとの指摘。</li>
</ul>
<p><strong>RL、蒸留、安全／セキュリティループ：現在スケールしているものと不足しているもの</strong></p>
<ul>
<li><strong>「RLの年」から「蒸留の年」へ</strong> : 蒸留が製品や展開で注目。Gemini 3 Flashが蒸留事前学習を使用しているとの噂も。</li>
<li><strong>RLインフラの民主化</strong> : <strong>OpenTinker</strong>はLLM向けのクライアント／サーバ分離型RLフレームワークを提案し、セットアップ時間を約10分の1に短縮。</li>
<li><strong>プロンプトインジェクション対策としてのRL</strong> : OpenAIはブラウザエージェント（ChatGPT Atlas）を自動レッドチーミング＋RL＋迅速な緩和ループで強化。</li>
<li><strong>アルゴリズム進歩 vs 計算資源</strong> : Sergey Brinの「計算はデザート、アルゴリズムはメインディッシュ」という発言が共有され、純粋なスケーリング論へのカウンターとして注目。</li>
</ul>
<p><strong>ロボティクス＆エンボディドAI：Reachy Miniの勢い、RL転移の難しさ、動画アクションモデル</strong></p>
<ul>
<li><strong>Reachy Miniがホリデー向けロボティクスプラットフォームに</strong> : 簡単セットアップと洗練されたUXが評価され、ローカルアシスタント構築計画も。</li>
<li><strong>シミュレーションから実機、さらにロボット間転移も困難</strong> : 完璧なシミュレーターでも実機への転移は性能低下し、同一設計の3Dプリント機間でも差が生じる事例。</li>
<li><strong>「LLMがロボットを制御」以外の学習スタック拡大</strong> : mimic-videoなどの動画アクションモデルや「Robot Olympics」タスクでのファインチューニング結果が共有。</li>
</ul>
<p><strong>エンジニアにとって重要な文化的シグナル：誤作動、LLM精神病、UIの使いやすさ</strong></p>
<ul>
<li><strong>「LLM精神病」／妄想の話題が増加</strong> : 数学証明などでモデルが専門家をも惑わす事例があり、検証プロセスの重要性が強調。</li>
<li><strong>コーディングエージェントのUIが製品差別化要因に</strong> : Claude CodeのUI（計画モード、編集依頼など）がCodexより優れているとの比較が繰り返され、コンテキストエンジニアリングの重要性が再認識。</li>
</ul>
<hr />
<h1 id="ai-reddit">AI Redditまとめ</h1>
<h2 id="rlocalllama-rlocalllm">/r/LocalLlama + /r/localLLM</h2>
<h3 id="1-ai2023">1. 主要なオープンソースAIモデルリリース2023</h3>
<ul>
<li><strong>2023年の主要オープンソースリリース</strong> : Deepseekの推論モデル、Qwenのビジョン・画像編集モデル、Alibabaのフォトリアル画像生成モデル、GoogleのGemma 3、MetaのSAMモデル、NvidiaのNemontron 3などが紹介され、中国企業の存在感が強調されました。米国企業は3社のみ。Deepseekの今後のリリースに期待する声や、小型モデルでのMistral性能に関する議論も。</li>
<li><strong>Soprano-80M</strong> : Eugene氏開発の新TTSモデルで、15ms未満のレイテンシ、2000倍リアルタイム速度、32kHzサンプルレート、超高速ボコーダー、革新的な音声コーデックを採用。Apache 2.0ライセンス。長時間生成時の品質低下やハードウェア条件への疑問も。</li>
</ul>
<h3 id="2-glm-47">2. GLM 4.7のリリースと特徴</h3>
<ul>
<li><strong>GLM 4.7</strong> : 多言語コーディング、UI生成、複雑な推論を強化し、SWE-benchで73.8%、HLEで42.8%を達成。インタリーブ思考、保持思考、ターンレベル思考など新機能を搭載。図を用いた推論・計画も初採用。Sonnet 4.5には及ばないとの見方もあり、Gemini 3 Flashに近い性能との評価も。</li>
</ul>
<h3 id="3-nvidiadgx-sparkunsloth">3. NVIDIAのDGX SparkとUnslothガイド</h3>
<ul>
<li><strong>NVIDIAのUnsloth入門ガイド</strong> : LoRA、FFT、RLによるLLMファインチューニング方法を解説。Nemotron 3ファミリーも紹介。</li>
<li><strong>DGX Spark</strong> : 小規模研究向けのコンパクト計算ユニット。高VRAMと省電力が評価される一方、メモリ帯域幅の不足が指摘。</li>
</ul>
<hr />
<h2 id="ai">技術色の薄いAIサブレディットまとめ</h2>
<h3 id="1-geminiscail">1. GeminiとSCAILモデルの進展</h3>
<ul>
<li><strong>Gemini 3 Flash</strong> : 指の数を正確に数える能力を実証。ジェスチャー認識やHCIへの応用可能性。</li>
<li><strong>SCAIL</strong> : 参照動画の動きを寸法歪みなく再現。モーションキャプチャ代替の可能性も。</li>
<li><strong>Z-Image＋SCAIL</strong> : 複数キャラクターの3D感あるアニメーション生成。高解像度レンダリングに高い計算負荷。</li>
<li><strong>2026年への展望</strong> : 画像モデルのテキスト解釈、動画モデルの進化、FrontierMathやHLEの進展などを踏まえた予測。</li>
</ul>
<h3 id="2-ai">2. AIの創造・エンジニアリング活用</h3>
<ul>
<li><strong>Claudeをエンジニアチーム代わりに使うスタートアップ</strong> : 15歳起業家がほぼコードを書かずに金融リサーチプラットフォームを構築。</li>
<li><strong>母語プロンプトによるローカル文化反映画像生成</strong> : Qwen-3エンコーダ搭載Z-image Turboで地域性のある画像生成。</li>
<li><strong>AI生成画像と実写の見分けテスト</strong> : Gemini生成画像は実写と区別困難、Chatモデル生成は人工的と判別しやすい。</li>
<li><strong>Time-to-Move＋Wan 2.2テスト</strong> : ComfyUIワークフローで手動オブジェクト移動によるアニメーション生成。</li>
</ul>
<h3 id="3-ai">3. AIと知能に関する議論</h3>
<ul>
<li><strong>DeepMind CEOとYann LeCunの論争</strong> : 汎用性は幻想ではないとHassabis氏が反論。</li>
<li><strong>ChatGPTはAIではない？</strong> : LLMは統計モデルであり理解はないとの批判。人間の予測的処理との類似性も議論。</li>
<li><strong>ChatGPTの知られざる有用性</strong> : 音声入力で買い物リスト作成、会話学習、感情サポートなど。</li>
</ul>
<hr />
<h1 id="ai-discord">AI Discordまとめ（要約）</h1>
<p><strong>1. 次世代LLMとベンチマークの世界展開</strong></p>
<ul>
<li>GLM‑4.7がWebDevオープンモデル1位に。</li>
<li>BaiduのERNIE‑5.0がText Arenaで中国モデル最高位。</li>
<li>UpstageのSolar‑Open‑100Bが公開。</li>
<li>Phi4がGPT‑OSS‑20Bを上回る可能性。</li>
</ul>
<p><strong>2. トレーニング・推論性能競争</strong></p>
<ul>
<li>TorchAO v0.15.0がMXFP8 MoEトレーニングを高速化。</li>
<li>QSInferenceが長コンテキストでFlashAttention-2より最大8倍高速。</li>
<li>Strix Halo APUはMoEモデルに有利。</li>
</ul>
<p><strong>3. エージェントフレームワーク・プロトコル・SDKの成熟</strong></p>
<ul>
<li>Vercel AI SDK 6がMCP統合、ローカルエージェント対応。</li>
<li>MCPのトークンコスト問題とキャッシュ提案。</li>
<li>SmolAgentsやDSPyの新機能。</li>
</ul>
<p><strong>4. ファインチューニング、損失設計、安全性／バックドア</strong></p>
<ul>
<li>DPOマスキングで推論モデルのスタイル制御。</li>
<li>MoE vs Denseのコスト比較。</li>
<li>暗黙的バックドアとメタデータ活用による文化的制御。</li>
</ul>
<p><strong>5. 開発者向けアプリ、価格、UX</strong></p>
<ul>
<li>CometブラウザがChromeより低CPU使用。</li>
<li>Grok音声が自然で簡潔。</li>
<li>Okuchatが複数LLM対応。</li>
<li>サブスク価格やクレジット消費への不満。</li>
</ul>
<hr />
<p>このように、最新のAIモデルリリース、ベンチマーク動向、エージェント技術、推論性能改善、安全性、そして開発者向けツールや価格戦略まで幅広い話題が取り上げられています。</p>
    </main>

    <footer>
        <p>
            <a href="https://github.com/YIPG/ainews">GitHub</a>
            <a href="https://news.smol.ai/">news.smol.ai</a>
        </p>
    </footer>
</body>
</html>