<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>厳しい時期の珍しい失敗 | AIニュース</title>
    <meta name="description" content="厳しい時期の珍しい失敗 - AIニュース 2025-12-16。最新のAI技術動向を日本語でお届け。">
    <meta name="keywords" content="AI,人工知能,ニュースレター,2025-12-16,機械学習,深層学習,日本語">
    <meta name="author" content="AIニュース">
    <link rel="canonical" href="https://yipg.github.io/ainews/docs/newsletters/2025-12-16.html">
    
    <!-- Open Graph meta tags -->
    <meta property="og:title" content="厳しい時期の珍しい失敗 | AIニュース">
    <meta property="og:description" content="厳しい時期の珍しい失敗 - AIニュース 2025-12-16。最新のAI技術動向を日本語でお届け。">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://yipg.github.io/ainews/docs/newsletters/2025-12-16.html">
    <meta property="og:image" content="https://yipg.github.io/ainews/newsletters/og/2025-12-16.png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:image:type" content="image/png">
    <meta property="og:site_name" content="AIニュース">
    <meta property="og:locale" content="ja_JP">
    <meta property="article:published_time" content="2025-12-16T09:00:00+00:00">
    <meta property="article:author" content="AIニュース">
    <meta property="article:section" content="AI技術ニュース">
    
    <!-- Twitter Card meta tags -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="厳しい時期の珍しい失敗 | AIニュース">
    <meta name="twitter:description" content="厳しい時期の珍しい失敗 - AIニュース 2025-12-16。最新のAI技術動向を日本語でお届け。">
    <meta name="twitter:image" content="https://yipg.github.io/ainews/newsletters/og/2025-12-16.png">
    
    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>✏️</text></svg>">
    <link rel="alternate icon" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAACXBIWXMAAA7EAAAOxAGVKw4bAAAA">
    
    <!-- RSS Feed -->
    <link rel="alternate" type="application/rss+xml" title="AIニュース RSS Feed" href="../feed.xml">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: Verdana, Geneva, sans-serif;
            font-size: 1em;
            line-height: 1.7;
            letter-spacing: 0.02em;
            max-width: 720px;
            margin: 0 auto;
            padding: 20px;
            background-color: #fff;
            color: #111;
            word-wrap: break-word;
        }
        
        nav {
            margin-bottom: 25px;
            padding-bottom: 15px;
            border-bottom: 1px solid #ddd;
            display: flex;
            align-items: center;
            justify-content: space-between;
            flex-wrap: nowrap;
        }
        
        .site-title {
            font-size: 1.1em;
            font-weight: bold;
            color: #111;
            text-decoration: none;
            flex-shrink: 0;
        }
        
        .site-title:hover {
            text-decoration: underline;
        }
        
        .nav-links {
            font-size: 0.85em;
            white-space: nowrap;
        }
        
        .nav-links a {
            color: #111;
            text-decoration: none;
            margin-left: 12px;
        }
        
        .nav-links a:hover {
            text-decoration: underline;
        }
        
        
        h1, h2, h3, h4, h5, h6 {
            margin: 35px 0 20px 0;
            line-height: 1.3;
            color: #111;
            letter-spacing: 0.01em;
        }
        
        h1 { font-size: 1.5em; }
        h2 { font-size: 1.3em; }
        h3 { font-size: 1.1em; }
        
        p {
            margin: 20px 0;
        }
        
        a {
            color: #0969da;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin: 20px 0;
            padding-left: 30px;
        }
        
        li {
            margin: 8px 0;
        }
        
        blockquote {
            border-left: 3px solid #ccc;
            margin: 25px 0;
            padding: 0 25px;
            color: #555;
            font-style: italic;
        }
        
        code {
            background-color: #f6f8fa;
            padding: 2px 4px;
            border-radius: 3px;
            font-family: 'Courier New', Courier, monospace;
            font-size: 0.9em;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            padding: 20px;
            overflow-x: auto;
            margin: 25px 0;
        }
        
        pre code {
            background: none;
            padding: 0;
        }
        
        img {
            max-width: 100%;
            height: auto;
            margin: 25px 0;
            border-radius: 3px;
        }
        
        hr {
            border: none;
            border-top: 1px solid #ddd;
            margin: 35px 0;
        }
        
        footer {
            margin-top: 40px;
            padding-top: 15px;
            border-top: 1px solid #ddd;
            text-align: center;
            color: #555;
            font-size: 0.85em;
        }
        
        footer a {
            color: #555;
            text-decoration: none;
            margin: 0 8px;
        }
        
        footer a:hover {
            text-decoration: underline;
        }
        
        @media (max-width: 600px) {
            body {
                padding: 15px;
                font-size: 0.95em;
            }
            
            nav {
                flex-direction: column;
                align-items: flex-start;
                gap: 10px;
            }
            
            .nav-links {
                font-size: 0.8em;
            }
            
            .nav-links a {
                margin-left: 0;
                margin-right: 12px;
            }
            
            .article-title {
                font-size: 1.4em;
            }
        }
        
        @media (max-width: 480px) {
            body {
                font-size: 0.9em;
                padding: 12px;
            }
            
            .site-title {
                font-size: 1em;
            }
            
            .nav-links {
                font-size: 0.75em;
            }
            
            .article-title {
                font-size: 1.3em;
            }
        }
        
        @media (prefers-color-scheme: dark) {
            body {
                background-color: #111;
                color: #eee;
            }
            
            nav {
                border-bottom-color: #444;
            }
            
            .site-title, .nav-links a, .article-title, h1, h2, h3, h4, h5, h6 {
                color: #eee;
            }
            
            .article-date {
                color: #ccc;
            }
            
            blockquote {
                border-left-color: #555;
                color: #ccc;
            }
            
            code {
                background-color: #2d3748;
                color: #e2e8f0;
            }
            
            pre {
                background-color: #2d3748;
            }
            
            hr, footer {
                border-color: #444;
            }
            
            footer, footer a {
                color: #ccc;
            }
        }
    </style>
</head>
<body>
    <nav>
        <a href="../index.html" class="site-title">✏️ AIニュース</a>
        <div class="nav-links">
            <a href="../index.html">ホーム</a>
            <a href="./archive.html">アーカイブ</a>
            <a href="../feed.xml">RSS</a>
            <a href="https://github.com/YIPG/ainews">GitHub</a>
        </div>
    </nav>

    <main>
        <p><strong>厳しい時期の珍しい失敗</strong></p>
<p><a href="https://openai.com/index/new-chatgpt-images-is-here/">OpenAIの新しい画像モデル</a>の見出しにある機能は魅力的です。精密な画像編集、創造的なアイデアの実行、指示の理解力向上、テキストやMarkdownのレンダリング精度の大幅改善、旧gpt-image-1の明らかなバグ修正、さらに既知の性能低下部分を自発的に明示するなどです。さらに<a href="https://www.reddit.com/r/singularity/comments/1po98xo/breaking_openai_releases_gptimage15_chatgpt/">LMArenaで1277</a>、<a href="https://xcancel.com/grx_xce/status/2000993261914350070?s=20">Design Arenaで1344</a>、<a href="https://artificialanalysis.ai/image/leaderboard/text-to-image">AA Arenaで1272</a>と、いずれも1位を獲得しています。</p>
<p><img alt="OpenAIのGPT-Image-1.5モデルがImage Arenaランキングで1位を獲得した棒グラフ" src="https://resend-attachments.s3.amazonaws.com/qgLummr8HwDZDzR" /></p>
<p><strong>しかし：</strong> 賞賛はそこまでです。 <a href="https://x.com/fumonzi/status/2000993574150922351?s=20">Twitter</a>、<a href="https://www.reddit.com/r/ChatGPT/comments/1poakus/new_gpt_image_vs_nano_banana_pro/">Reddit</a>、各種Discordコミュニティでの評価は、<a href="https://news.smol.ai/issues/25-11-20-nano-banana-pro">Nano Banana Pro</a>との比較でほぼ否定的です。GPT-Image-1からの進歩は明らかであり、OpenAI全体への批判というよりも、Arenaベンチマークが実際のユーザー嗜好を代表しているかという信頼性に関する厳しい結果と言えます。</p>
<p>能力競争の詳細を追う人にとっては、文脈とタイミングが重要です。もしこれがNBPより前にリリースされていたら、あるいはGemini競合による「Code Red」という物語がなかったら、Image-1.5は十分に良いローンチだったでしょう。今は雰囲気が悪いのです。</p>
<hr />
<h1 id="ai-twitter">AI Twitterまとめ</h1>
<p><strong>XiaomiのMiMo‑V2‑Flash：速度・長文コンテキスト・SWE‑Bench SOTAを狙った309B MoE</strong></p>
<ul>
<li><strong>MiMo‑V2‑Flash（309B MoE; 15B稼働）</strong>：Xiaomiの新しいオープンウェイトモデルは推論効率とエージェント的ワークフローを重視し、<strong>150トークン/秒</strong>、<strong>256Kコンテキスト</strong>、SWE‑Benchでオープンソース最高スコア（Verified: <strong>73.4%</strong>、Multilingual: <strong>71.7%</strong>）を達成しました。アーキテクチャはHybrid Sliding Window Attention（SWA）を採用し、疎なローカルウィンドウと少数のグローバル層を組み合わせ、MTP（multi‑token prediction）による高速デコード、LMSYS/SGLangでの即日提供を実現しています。Xiaomiは「DeepSeek‑V3.2と同等のベンチマーク性能を低レイテンシで達成」と述べています。詳細リンク：<a href="https://twitter.com/XiaomiMiMo/status/2000929154670157939">発表と仕様</a>、技術レポートとコード<a href="https://twitter.com/XiaomiMiMo/status/2000929154670157939">こちら</a>。</li>
<li><strong>エンジニアリングノートとアブレーション</strong>：主任著者Fuli Luo氏によれば、Hybrid SWAは他の線形アテンション変種より優れ、長文コンテキストでは<strong>ウィンドウサイズ128 &gt; 512</strong>、<strong>attention sinksが重要</strong>、3層MTPでコードタスクの受け入れ長が3倍以上、速度が約2.5倍に向上。MOPD（multi‑teacher on‑policy distillation）による事後学習で、SFT+RLの計算量の1/50未満で教師品質を達成。詳細スレッドは<a href="https://twitter.com/luo_fuli14427/status/2001002838953222653">@luo_fuli14427</a>。外部アブレーションではsinkとSWA‑128の512に対する優位性、複雑タスクでのハイブリッド &gt; 密グローバル層の効果が報告されています<a href="https://twitter.com/eliebakouch/status/2000976464443789625">@eliebakouch</a>。期間限定でOpenRouterで無料提供<a href="https://twitter.com/OpenRouterAI/status/2000956004675281094">@OpenRouterAI</a>、SGLang即日性能ノート<a href="https://twitter.com/BanghuaZ/status/2000981251575181723">@BanghuaZ</a>。背景として、主任はDeepSeek‑V2の主要著者です<a href="https://twitter.com/eliebakouch/status/2001006476245262395">@eliebakouch</a>。</li>
</ul>
<p><strong>画像生成の動き：OpenAI GPT Image 1.5（「ChatGPT Images」）とFLUX.2 Max</strong></p>
<ul>
<li><strong>OpenAI GPT Image 1.5</strong>：ChatGPTとAPI向けの新しいフラッグシップモデルで、<strong>指示理解力の強化</strong>、<strong>精密な編集</strong>、テキストレンダリング/ロゴ/顔の改善、<strong>最大4倍の生成速度</strong>を実現。ChatGPTに新しい「Images」機能が追加されました。ドキュメントとAPI：<a href="https://twitter.com/OpenAI/status/2000990989629161873">OpenAI</a>、<a href="https://twitter.com/OpenAIDevs/status/2000992413402456485">OpenAIDevs</a>。Artificial AnalysisとLM Arenaの両方でテキストから画像生成と編集で1位を獲得し、GeminiのNano Banana Proを大きく上回っています。価格は解像度/品質に依存（高品質1MP画像1,000枚で約133ドル、低品質では約9ドル）。リーダーボードと価格分析：<a href="https://twitter.com/arena/status/2001008010399994026">arena</a>、<a href="https://twitter.com/ArtificialAnlys/status/2001016199094948185">ArtificialAnlys</a>、<a href="https://twitter.com/grx_xce/status/2000993261914350070">grx_xce</a>。<ul>
<li>初期比較では、GPT‑Image‑1.5は以前のGPTモデルを上回り、編集精度でNano Banana Proと互角に競合。一部報告ではGeminiが「視覚的IQ」（画像内の数学/迷路推論）で依然優位とされています<a href="https://twitter.com/Yuchenj_UW/status/2001023040763920870">@Yuchenj_UW</a>、<a href="https://twitter.com/Yuchenj_UW/status/2000997359036326290">@Yuchenj_UW</a>。</li>
</ul>
</li>
<li><strong>FLUX.2 [max]（Black Forest Labs）</strong>：ウェブ情報を活用し、最大10枚の参照画像で一貫した編集を可能にする高品質版FLUX.2。テキストから画像生成と編集でランキング2〜3位（価格はT2I画像1,000枚で70ドル、編集1,000枚で140ドル）。発表とホスティング：<a href="https://twitter.com/bfl_ml/status/2000945755125899427">bfl_ml</a>、<a href="https://twitter.com/fal/status/2000945229977829784">fal</a>、<a href="https://twitter.com/arena/status/2000947088738431408">arena</a>。</li>
</ul>
<p><strong>NVIDIAのオープンソース推進：Nemotron‑CascadeとNemotron 3の広範な提供</strong></p>
<ul>
<li><strong>Nemotron‑Cascade（8B/14B）</strong>：NVIDIAが「Cascade RL」というドメインごとの逐次RLパイプラインを導入。14BモデルはLiveCodeBench v5/v6/ProでDeepSeek‑R1‑0528（671B）を上回り、SWE‑Bench Verifiedで<strong>43.1%</strong>（テスト時スケーリングで53.8%）を達成。チームはRLHFによる事前整合を推奨し、後段ドメインでも初期性能を維持または向上。論文/モデル:<a href="https://twitter.com/_weiping/status/2000947255088701628">_weiping</a>、<a href="https://twitter.com/zihan_johan_liu/status/2001011462979117138">zihan_johan_liu</a>、<a href="https://twitter.com/HuggingPapers/status/2001065870676603333">HuggingPapers</a>。</li>
<li><strong>Nemotron 3 Nanoの提供拡大</strong>：OllamaやMLX/LM Studio（Apple Silicon向け）で利用可能になり、小型MoEモデルをローカルワークフローに導入可能に。<a href="https://twitter.com/ollama/status/2000820163231232167">ollama</a>、<a href="https://twitter.com/awnihannun/status/2000974327660077298">awnihannun</a>、<a href="https://twitter.com/lmstudio/status/2001015687003963730">lmstudio</a>。背景として、NVIDIAのオープンソース戦略はハードウェア最適化と密接に連動しており、「ハードウェア定義AI」時代を意識しています<a href="https://twitter.com/TheTuringPost/status/2001087448299065372">@TheTuringPost</a>。</li>
</ul>
<p>（以下、同様の形式で続く）</p>
    </main>

    <footer>
        <p>
            <a href="https://github.com/YIPG/ainews">GitHub</a>
            <a href="https://news.smol.ai/">news.smol.ai</a>
        </p>
    </footer>
</body>
</html>