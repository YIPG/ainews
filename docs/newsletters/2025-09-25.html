<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>もうすぐ到達です！ | AIニュース</title>
    <meta name="description" content="もうすぐ到達です！ - AIニュース 2025-09-25。最新のAI技術動向を日本語でお届け。">
    <meta name="keywords" content="AI,人工知能,ニュースレター,2025-09-25,機械学習,深層学習,日本語">
    <meta name="author" content="AIニュース">
    <link rel="canonical" href="https://yipg.github.io/ainews/docs/newsletters/2025-09-25.html">
    
    <!-- Open Graph meta tags -->
    <meta property="og:title" content="もうすぐ到達です！ | AIニュース">
    <meta property="og:description" content="もうすぐ到達です！ - AIニュース 2025-09-25。最新のAI技術動向を日本語でお届け。">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://yipg.github.io/ainews/docs/newsletters/2025-09-25.html">
    <meta property="og:image" content="https://yipg.github.io/ainews/newsletters/og/2025-09-25.png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:image:type" content="image/png">
    <meta property="og:site_name" content="AIニュース">
    <meta property="og:locale" content="ja_JP">
    <meta property="article:published_time" content="2025-09-25T09:00:00+00:00">
    <meta property="article:author" content="AIニュース">
    <meta property="article:section" content="AI技術ニュース">
    
    <!-- Twitter Card meta tags -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="もうすぐ到達です！ | AIニュース">
    <meta name="twitter:description" content="もうすぐ到達です！ - AIニュース 2025-09-25。最新のAI技術動向を日本語でお届け。">
    <meta name="twitter:image" content="https://yipg.github.io/ainews/newsletters/og/2025-09-25.png">
    
    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>✏️</text></svg>">
    <link rel="alternate icon" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAACXBIWXMAAA7EAAAOxAGVKw4bAAAA">
    
    <!-- RSS Feed -->
    <link rel="alternate" type="application/rss+xml" title="AIニュース RSS Feed" href="../feed.xml">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: Verdana, Geneva, sans-serif;
            font-size: 1em;
            line-height: 1.7;
            letter-spacing: 0.02em;
            max-width: 720px;
            margin: 0 auto;
            padding: 20px;
            background-color: #fff;
            color: #111;
            word-wrap: break-word;
        }
        
        nav {
            margin-bottom: 25px;
            padding-bottom: 15px;
            border-bottom: 1px solid #ddd;
            display: flex;
            align-items: center;
            justify-content: space-between;
            flex-wrap: nowrap;
        }
        
        .site-title {
            font-size: 1.1em;
            font-weight: bold;
            color: #111;
            text-decoration: none;
            flex-shrink: 0;
        }
        
        .site-title:hover {
            text-decoration: underline;
        }
        
        .nav-links {
            font-size: 0.85em;
            white-space: nowrap;
        }
        
        .nav-links a {
            color: #111;
            text-decoration: none;
            margin-left: 12px;
        }
        
        .nav-links a:hover {
            text-decoration: underline;
        }
        
        
        h1, h2, h3, h4, h5, h6 {
            margin: 35px 0 20px 0;
            line-height: 1.3;
            color: #111;
            letter-spacing: 0.01em;
        }
        
        h1 { font-size: 1.5em; }
        h2 { font-size: 1.3em; }
        h3 { font-size: 1.1em; }
        
        p {
            margin: 20px 0;
        }
        
        a {
            color: #0969da;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin: 20px 0;
            padding-left: 30px;
        }
        
        li {
            margin: 8px 0;
        }
        
        blockquote {
            border-left: 3px solid #ccc;
            margin: 25px 0;
            padding: 0 25px;
            color: #555;
            font-style: italic;
        }
        
        code {
            background-color: #f6f8fa;
            padding: 2px 4px;
            border-radius: 3px;
            font-family: 'Courier New', Courier, monospace;
            font-size: 0.9em;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            padding: 20px;
            overflow-x: auto;
            margin: 25px 0;
        }
        
        pre code {
            background: none;
            padding: 0;
        }
        
        img {
            max-width: 100%;
            height: auto;
            margin: 25px 0;
            border-radius: 3px;
        }
        
        hr {
            border: none;
            border-top: 1px solid #ddd;
            margin: 35px 0;
        }
        
        footer {
            margin-top: 40px;
            padding-top: 15px;
            border-top: 1px solid #ddd;
            text-align: center;
            color: #555;
            font-size: 0.85em;
        }
        
        footer a {
            color: #555;
            text-decoration: none;
            margin: 0 8px;
        }
        
        footer a:hover {
            text-decoration: underline;
        }
        
        @media (max-width: 600px) {
            body {
                padding: 15px;
                font-size: 0.95em;
            }
            
            nav {
                flex-direction: column;
                align-items: flex-start;
                gap: 10px;
            }
            
            .nav-links {
                font-size: 0.8em;
            }
            
            .nav-links a {
                margin-left: 0;
                margin-right: 12px;
            }
            
            .article-title {
                font-size: 1.4em;
            }
        }
        
        @media (max-width: 480px) {
            body {
                font-size: 0.9em;
                padding: 12px;
            }
            
            .site-title {
                font-size: 1em;
            }
            
            .nav-links {
                font-size: 0.75em;
            }
            
            .article-title {
                font-size: 1.3em;
            }
        }
        
        @media (prefers-color-scheme: dark) {
            body {
                background-color: #111;
                color: #eee;
            }
            
            nav {
                border-bottom-color: #444;
            }
            
            .site-title, .nav-links a, .article-title, h1, h2, h3, h4, h5, h6 {
                color: #eee;
            }
            
            .article-date {
                color: #ccc;
            }
            
            blockquote {
                border-left-color: #555;
                color: #ccc;
            }
            
            code {
                background-color: #2d3748;
                color: #e2e8f0;
            }
            
            pre {
                background-color: #2d3748;
            }
            
            hr, footer {
                border-color: #444;
            }
            
            footer, footer a {
                color: #ccc;
            }
        }
    </style>
</head>
<body>
    <nav>
        <a href="../index.html" class="site-title">✏️ AIニュース</a>
        <div class="nav-links">
            <a href="../index.html">ホーム</a>
            <a href="./archive.html">アーカイブ</a>
            <a href="../feed.xml">RSS</a>
            <a href="https://github.com/YIPG/ainews">GitHub</a>
        </div>
    </nav>

    <main>
        <p><strong>もうすぐ到達です！</strong></p>
<p>OpenAIのEvalsチームが今年3回目となる新たな評価指標 <a href="https://openai.com/index/gdpval/">GDPVal</a> を発表しました。これはMMLUのような幅広い評価範囲と、SWE-BenchやSWE-Lancerといったエージェント型ベンチマークの深みを組み合わせた「次の論理的ステップ」と位置付けられています。<strong>GDPval</strong>（<a href="https://cdn.openai.com/pdf/d5eb7428-c4e9-4a33-bd86-86dd4bcf12ce/GDPval.pdf#page=6.54">論文全文はこちら</a>）は、GDPの主要セクター（5%以上）から「主にデジタル」な知識労働を抽出して構成されています。</p>
<p>この結果、44職種にわたる1,320のタスクが作成され、平均14年の経験を持つ人間の専門家とモデルを比較評価しました。</p>
<p>結果は非常に示唆的で、OpenAIが自社モデルに有利なバイアスをかけていないこと、そしてOpusが業界専門家の成果にほぼ匹敵していることが示されました。</p>
<p>さらに、モデル性能の推移を見ると、GPTnextが2026年半ばには人間のパフォーマンスに到達する見込みです。</p>
<p>論文内ではAGIという言葉は一切使われていませんが、2018年のOpenAI憲章ではAGIを「経済的に価値のある仕事の大半で人間を上回る高度に自律的なシステム」と定義していました。もし2026年9月にGDPValのペア比較でGPT6が信頼区間50%以上を超える結果を出せば、2018年基準でのAGI達成と言えるでしょう。</p>
<hr />
<h1 id="ai-twitter">AI Twitterまとめ</h1>
<p><strong>OpenAIのGDPvalと実世界評価の現状</strong></p>
<ul>
<li><strong>GDPval（OpenAI）</strong>：OpenAIはGDPvalを発表し、検索・コード・ドキュメントツールの利用や数時間規模の複雑さを伴う、44職種にわたる「経済的価値のある」タスクでモデル性能を評価しました。初期結果では<strong>Claude 4.1 Opus</strong>が多くのカテゴリでトップとなり、人間の業界専門家に迫る、または上回る性能を示しました。GPT‑5「high」は同タスクでOpusに次ぐ結果です。OpenAIは公開サイトと方法論を提供し、政策立案者や労働影響予測の重要指標と位置付けています。発表と議論：<a href="https://twitter.com/OpenAI/status/1971249374077518226"> @OpenAI</a>、<a href="https://twitter.com/kevinweil/status/1971250647778635904"> @kevinweil</a>、<a href="https://twitter.com/gdb/status/1971301844585676930"> @gdb</a>、<a href="https://twitter.com/dejavucoder/status/1971253593404735706"> @dejavucoder</a>、<a href="https://twitter.com/Yuchenj_UW/status/1971254164069212231"> @Yuchenj_UW</a>、<a href="https://twitter.com/LHSummers/status/1971252567981146347"> @LHSummers</a>。</li>
<li><strong>Artificial Analysisによる各種指標</strong>：</li>
<li><strong>Gemini 2.5 Flash/Flash‑Lite（Preview 09‑2025）</strong>：Flashは推論/非推論で+3/+8ポイント、Flash‑Liteは+8/+12ポイントの改善。Flash‑Liteは約40%高速（約887トークン/秒）、出力トークン数50%削減。1Mコンテキスト、ツール利用、ハイブリッド推論モード対応。価格：Flash‑Lite $0.1/$0.4（1M入力/出力）、Flash $0.3/$2.5。ベンチマーク：<a href="https://twitter.com/ArtificialAnlys/status/1971273380335845683"> @ArtificialAnlys</a>、<a href="https://twitter.com/ArtificialAnlys/status/1971273385721356546">フォローアップ</a>。</li>
<li><strong>DeepSeek V3.1 Terminus</strong>：推論モードで+4ポイント、指示追従性能（+15 IFBench）や長文コンテキスト（+12 AA‑LCR）で大幅改善。アーキテクチャは総671B、稼働37B。APIや第三者ホスト（FP4/FP8）で利用可能。<a href="https://twitter.com/ArtificialAnlys/status/1971114096008495501"> @ArtificialAnlys</a>。</li>
<li><strong>AA‑WER（音声認識）</strong>：AMI‑SDM、Earnings‑22、VoxPopuliでの新しい単語誤り率ベンチマーク。トップはGoogle Chirp 2（11.6% WER）、NVIDIA Canary Qwen2.5B（13.2%）、Parakeet TDT 0.6B V2（13.7%）。価格性能のトレードオフも指摘。<a href="https://twitter.com/ArtificialAnlys/status/1971232397921534141"> @ArtificialAnlys</a>、<a href="https://twitter.com/ArtificialAnlys/status/1971232403973943517">価格情報</a>。</li>
</ul>
<p><strong>エージェント型コーディングと製品化されたエージェント</strong></p>
<ul>
<li><strong>Kimi「OK Computer」（K2搭載エージェントモード）</strong>：独自のファイルシステム、ブラウザ、ターミナルを備えたOSのようなエージェント。1M行までのデータからダッシュボード生成などをデモ。OpenRouter上でツールコールの正確性を検証するVendor Verifierも公開。<a href="https://twitter.com/Kimi_Moonshot/status/1971078467560276160"> @Kimi_Moonshot</a>、<a href="https://twitter.com/crystalsssup/status/1971158566343184511"> @crystalsssup</a>、事例<a href="https://twitter.com/crystalsssup/status/1971133240619757794">1</a>、<a href="https://twitter.com/crystalsssup/status/1971183638734832004">2</a>。</li>
<li><strong>GitHub Copilot CLI（パブリックプレビュー）</strong>：ローカルターミナルエージェントでMCP対応。既存のGitHub IDを利用し、スクリプト埋め込み、リクエスト単位の課金。<a href="https://twitter.com/github/status/1971295695853306059"> @github</a>、<a href="https://twitter.com/lukehoban/status/1971391939858792584"> @lukehoban</a>。</li>
<li><strong>Factory AI「Droids」＋5,000万ドル資金調達</strong>：モデル非依存のソフトウェア開発エージェント（CLI/IDE/Slack/Linear/Browser対応）。Terminal‑Benchで1位。コード抽象化を通じて広範な知識労働エージェントを目指す。<a href="https://twitter.com/FactoryAI/status/1971271085653156054"> @FactoryAI</a>、<a href="https://twitter.com/swyx/status/1971310686585356295"> @swyx</a>、<a href="https://twitter.com/tbpn/status/1971322883315314995"> @tbpn</a>。</li>
<li><strong>Ollama Web Search API＋MCPサーバー</strong>：ローカル/クラウドモデルをライブWeb情報に接続。Codex/cline/GooseなどMCPクライアントと互換。<a href="https://twitter.com/ollama/status/1971085470785319349"> @ollama</a>。</li>
<li><strong>Reka Research「Parallel Thinking」</strong>：複数の候補チェーンを生成し、検証モデルで解決するAPIオプション。Research‑Evalで+4.2、SimpleQAで+3.5改善、レイテンシはほぼ変わらず。<a href="https://twitter.com/RekaAILabs/status/1971241107322540194"> @RekaAILabs</a>。</li>
</ul>
<p><strong>動画推論とロボティクス</strong></p>
<ul>
<li><strong>動画モデルによるゼロショット推論（Veo 3）</strong>：DeepMindが知覚→物理→操作→推論にわたる広範なゼロショット能力を提示。「Chain‑of‑Frames」という視覚的CoTを導入。深度や物理ではSOTAに及ばず、コストは高い。<a href="https://twitter.com/arankomatsuzaki/status/1971042970800701809"> @arankomatsuzaki</a>、<a href="https://twitter.com/arankomatsuzaki/status/1971042973153624479">プロジェクト/論文</a>、<a href="https://twitter.com/tkipf/status/1971063116734841248"> @tkipf</a>。</li>
<li><strong>Gemini Robotics 1.5（Google）</strong>：新しい具現化推論スタック（GR 1.5 VLA＋ER）、長文コンテキスト、ツール利用、空間・時間計画、具現間の転移、安全制約対応。Google AI StudioでAPI提供。洗濯物仕分け推論デモあり。<a href="https://twitter.com/GoogleDeepMind/status/1971243947792925005"> @GoogleDeepMind</a>、<a href="https://twitter.com/sundarpichai/status/1971244716046872577"> @sundarpichai</a>、<a href="https://twitter.com/GoogleDeepMind/status/1971243970953879643">API案内</a>、<a href="https://twitter.com/demishassabis/status/1971292365592854602"> @demishassabis</a>。</li>
</ul>
<p><strong>モデル・手法のリリース</strong></p>
<ul>
<li><strong>EmbeddingGemma（Google）</strong>：308Mのエンコーダモデルで、500M未満モデル中MTEBトップ（多言語/英語/コード対応）。約2倍大きいベースラインと同等性能。オンデバイスや高スループット用途に適合。<a href="https://twitter.com/arankomatsuzaki/status/1971041110446465251"> @arankomatsuzaki</a>、<a href="https://twitter.com/osanseviero/status/1971187988806897876">論文まとめ</a>。</li>
<li><strong>ShinkaEvolve（Sakana AI、オープンソース）</strong>：LLMアンサンブルを用いた適応的親サンプリング＆新規性フィルタリングによる進化的プログラム生成フレームワーク。150サンプルで新SOTAの円充填達成など。<a href="https://twitter.com/SakanaAILabs/status/1971081557210489039"> @SakanaAILabs</a>、<a href="https://twitter.com/hardmaru/status/1971081987818745930"> @hardmaru</a>、<a href="https://twitter.com/SakanaAILabs/status/1971214066510332009">レポート</a>。</li>
<li><strong>RLMT &amp; TPT</strong>：</li>
<li>「Language Models that Think, Chat Better」では、Model‑rewarded Thinking（RLMT）によるRLが8BモデルのチャットベンチマークでRLHFを上回ると提案。<a href="https://twitter.com/iScienceLuvr/status/1971154927415329001"> @iScienceLuvr</a>、<a href="https://twitter.com/omarsar0/status/1971215698140819516">ノート</a>。</li>
<li>「Thinking‑Augmented Pre‑Training（TPT）」では、合成ステップバイステップ軌跡により3Bモデルの推論性能を事前学習で約3倍効率化、事後学習で10%以上改善。<a href="https://twitter.com/iScienceLuvr/status/1971155514865352990"> @iScienceLuvr</a>。</li>
</ul>
<p><strong>システム・提供・インフラ</strong></p>
<ul>
<li><strong>Perplexity Search API</strong>：リアルタイムWebインデックスを提供し、LLMやエージェントの情報基盤として高品質・低レイテンシを実現。Google SERPに対する優位性も主張。<a href="https://twitter.com/perplexity_ai/status/1971274917401461236"> @perplexity_ai</a>、<a href="https://twitter.com/perplexity_ai/status/1971275034456207861">記事</a>、<a href="https://twitter.com/AravSrinivas/status/1971275716357656987"> @AravSrinivas</a>。</li>
<li><strong>KV再利用と動的並列化</strong>：</li>
<li><strong>LMCache</strong>：GPU/CPU/ディスク間で任意の繰り返しテキストセグメント（プレフィックス以外も）を再利用するオープンKVキャッシュ層。RAGコストを4〜10倍削減。<a href="https://twitter.com/TheTuringPost/status/1971318599253098559"> @TheTuringPost</a>。</li>
<li><strong>Shift Parallelism（Snowflake）</strong>：負荷に応じてTensor/Sequence Parallelismを動的切替。レイテンシ最大1.5倍低減、スループット50%向上。<a href="https://twitter.com/StasBekman/status/1971262600555135227"> @StasBekman</a>。</li>
<li><strong>Context‑parallel diffusion</strong>：Ring/Ulysses変種のネイティブ対応でマルチGPU拡散モデルを高速化。<a href="https://twitter.com/RisingSayak/status/1971154049698509190"> @RisingSayak</a>。</li>
<li><strong>attnd（ZML）</strong>：UDP上でのCPU向け疎な対数的アテンション。「無限コンテキストへの道」として紹介。<a href="https://twitter.com/steeve/status/1971126773204279495"> @steeve</a>。</li>
<li><strong>エネルギーとハードウェア</strong>：</li>
<li><strong>Microsoft（LLM推論のエネルギー）</strong>：チャットボットの中央値クエリは約0.34Wh、長推論は約4.3Wh（約13倍）。1日10億クエリで約0.9GWh。公的推定は4〜20倍過大との主張。<a href="https://twitter.com/arankomatsuzaki/status/1971059016878240241"> @arankomatsuzaki</a>。</li>
<li><strong>B200スポット価格</strong>：B200スポットインスタンスが一時的に約$0.92/時。<a href="https://twitter.com/johannes_hage/status/1971088953127362703"> @johannes_hage</a>。</li>
</ul>
<p><strong>業界動向とプラットフォーム更新</strong></p>
<ul>
<li><strong>Metaの人材獲得</strong>：拡散・一貫性モデルの先駆者Yang Song氏がOpenAIからMetaへ移籍。<a href="https://twitter.com/iScienceLuvr/status/1971087101203775782"> @iScienceLuvr</a>、<a href="https://twitter.com/Yuchenj_UW/status/1971088866095603858"> @Yuchenj_UW</a>。</li>
<li><strong>ChatGPT Pulse</strong>：OpenAIがProユーザー向けに、文脈や接続アプリからの「プロアクティブ」な日次更新を提供する新機能を展開。<a href="https://twitter.com/OpenAI/status/1971259652684878019"> @OpenAI</a>、<a href="https://twitter.com/sama/status/1971297661748953263"> @sama</a>、<a href="https://twitter.com/fidjissimo/status/1971258542578663829"> @fidjissimo</a>。</li>
<li><strong>Qwenエコシステム</strong>：QwenモデルがLMSYS Arenaに追加（<a href="https://twitter.com/Alibaba_Qwen/status/1971097727477088717"> @Alibaba_Qwen</a>）。Qwen3‑VLが第三者プロバイダ経由で試用可能に。<a href="https://twitter.com/mervenoyann/status/1971168938848551021"> @mervenoyann</a>。</li>
</ul>
<p><strong>エンゲージメント上位ツイート</strong></p>
<ul>
<li><a href="https://twitter.com/paularambles/status/1971234855309672467">「ChatGPTが間違えるとスマホを冷蔵庫に入れる男がいる」</a> — 55,057</li>
<li><a href="https://twitter.com/sama/status/1971297661748953263">Sam AltmanによるChatGPT Pulse紹介（「リアクティブからプロアクティブへ」）</a> — 28,573</li>
<li><a href="https://twitter.com/karpathy/status/1971220449515516391">Karpathy「AIは放射線科医を置き換えていない」（ベンチマーク≠現場）</a> — 7,980</li>
<li><a href="https://twitter.com/Kimi_Moonshot/status/1971078467560276160">Kimi「OK Computer」エージェントモード発表</a> — 2,646</li>
<li><a href="https://twitter.com/OpenAI/status/1971249374077518226">OpenAIによるGDPval発表</a> — 4,144</li>
<li><a href="https://twitter.com/demishassabis/status/1971292365592854602">Demis HassabisによるGemini Robotics 1.5紹介（「ロボットと会話」）</a> — 1,545</li>
</ul>
<hr />
<h1 id="ai-reddit">AI Redditまとめ</h1>
<h2 id="rlocalllama-rlocalllm">/r/LocalLlama + /r/localLLMまとめ</h2>
<h3 id="1-aialibaba-qwen-tencent-hunyuan-image-30">1. 中国AIモデル発表：Alibaba Qwenの極限スケーリング計画 &amp; Tencent Hunyuan Image 3.0</h3>
<ul>
<li><a href="https://i.redd.it/5tm4p90rt9rf1.jpeg"><strong>AlibabaがQwenロードマップを発表、その野心は驚異的！</strong></a>：Qwenロードマップでは、コンテキスト長を<code>1M → 100M</code>トークン、パラメータ数を<code>~1T → 10T</code>、テスト時計算量を<code>64k → 1M</code>トークン、学習データを<code>10T → 100T</code>トークンへ拡大する計画が示されました。さらに「無限規模」の合成データ生成や高度なエージェント機能も強化予定です。コメントでは、100Mコンテキストや1T超モデルの実現可能性に懐疑的な意見が多く、ハードウェアや推論コストの課題が指摘されています。</li>
<li><a href="https://i.redd.it/t8w84ihz1crf1.jpeg"><strong>Tencentが世界最強のオープンソース画像生成モデルHunyuan Image 3.0を9月28日に公開予定</strong></a>：96GB VRAMが必要とされる推論モードがあると噂される大型モデル。ベンチマークや詳細は未公開で、性能主張は検証待ち。コメントでは過去の過剰宣伝例を挙げつつ、FIDやCLIPScoreなどの比較評価を求める声が多いです。</li>
</ul>
<h3 id="2-aifenghua-no3-gpullm">2. ローカルAI代替：Fenghua No.3 GPUとアブリタレートLLMの再調整</h3>
<ul>
<li><a href="https://i.redd.it/kvkovm34x9rf1.png"><strong>中国がCUDA/DirectX対応GPUを開発、NVIDIA独占に挑戦</strong></a>：Fenghua No.3 GPUはDirectX 12、Vulkan 1.2、OpenGL 4.6、CUDA互換を謳っていますが、実際の性能や互換性は未検証。コメントではAMDのHIPやZLUDAのような互換レイヤーの可能性が指摘され、法的・技術的課題への懸念も示されています。</li>
<li><a href="https://www.reddit.com/r/LocalLLaMA/comments/1nq0cp9/important_why_abliterated_models_suck_here_is_a/"><strong>アブリタレートモデルは性能低下を招く、より良いLLMの非検閲化方法</strong></a>：重みの直接編集による非検閲化は推論やツール利用能力を損ない、幻覚率を高める傾向があるとの報告。再調整（ファインチューニング）により部分的に回復可能ですが、元モデルを直接ファインチューニングする方が有効との意見が多いです。</li>
</ul>
<h2 id="ai">技術色の薄いAIサブレまとめ</h2>
<h3 id="1-gemini-robotics-15veo-3">1. Gemini Robotics 1.5とVeo 3のゼロショット動画推論</h3>
<ul>
<li><a href="https://v.redd.it/7c3xep1jpcrf1"><strong>Gemini Robotics 1.5</strong></a>：Google DeepMindが自然言語＋視覚からロボット制御を行う長期・多段階操作モデルを発表。洗濯物仕分けや机の整理などをデモ。コメントでは農業分野への応用可能性も議論されています。</li>
<li><a href="https://v.redd.it/ltzwnm26u9rf1"><strong>動画モデルのゼロショット推論能力（Veo 3）</strong></a>：物理推論やツール使用シミュレーションなど幅広いゼロショット能力を示すとされるが、詳細なベンチマークは未公開。コメントでは動画生成の計算コストやLLMとの統合可能性が議論されています。</li>
</ul>
<h3 id="2-llmapple-vs-anthropicgpt5">2. LLM推論の信頼性：Apple vs Anthropic、GPT‑5の性能低下報告</h3>
<ul>
<li><a href="https://www.reddit.com/r/ChatGPT/comments/1nq9txw/apple_called_out_every_major_ai_company_for_fake/"><strong>Appleが主要AI企業の「偽の推論」を批判、Anthropicが反論</strong></a>：Appleは軽微な言い換えで精度が低下することを指摘。Anthropicは評価方法の問題と反論。コメントではLLMの頑健性や評価方法論について議論が交わされています。</li>
<li><a href="https://www.reddit.com/r/ChatGPT/comments/1nq0kh2/chatgpt_is_in_such_a_bad_state_my_most_novice/"><strong>ChatGPTの性能低下を学生も認識</strong></a>：教育現場での要約タスクで精度低下が顕著との報告。GeminiやClaudeの方が安定しているとの比較も。</li>
</ul>
<hr />
<h1 id="ai-discord">AI Discordまとめ</h1>
<p><strong>1. エージェントツール：Chrome DevTools MCPとPerplexity Search API</strong></p>
<ul>
<li><strong>Chrome DevTools MCP</strong>：GoogleがCDP/Puppeteer経由でChromeを制御できるMCPサーバーのパブリックプレビューを発表。Webタスクの自動化やテストに有用。</li>
<li><strong>Perplexity Search API</strong>：ライブWeb検索結果やページテキスト、フィルタ、出典情報を提供するAPIを公開。Python SDKのストリーミングバグが報告されています。</li>
</ul>
<p><strong>2. コード世界モデルとエージェント実行基盤</strong></p>
<ul>
<li><strong>MetaのCWM</strong>：コード生成と世界モデルを組み合わせたオープンウェイトLLMを発表。プログラムトレース学習によるツール利用理解の向上を狙う。</li>
<li><strong>Modalによるリモートコード実行</strong>：大規模エージェント展開のための柔軟な実行環境を提供。</li>
</ul>
<p><strong>3. GPUシステムと拡散モデルのスケールアップ</strong></p>
<ul>
<li><strong>Hugging Faceのコンテキスト並列拡散</strong>：Ring/Ulysses型の分散アテンションに対応し、マルチGPUでの高解像度生成を効率化。</li>
</ul>
<p><strong>4. 評価とプロアクティブアシスタント</strong></p>
<ul>
<li><strong>OpenAIのGDPval</strong>：経済的価値のある実世界タスク評価を導入。</li>
<li><strong>ChatGPT Pulse</strong>：Proユーザー向けに日次更新を提供する新機能。</li>
</ul>
<p><strong>5. トレーニング技術：損失関数、LoRA統合、データ保存</strong></p>
<ul>
<li><strong>Tversky Loss</strong>：分類タスクでの性能向上を狙う損失関数。</li>
<li><strong>Super-Bias</strong>：複数LoRAの非破壊的統合を可能にする手法。</li>
<li><strong>MXFP4保存</strong>：巨大モデルの効率的保存形式。</li>
</ul>
    </main>

    <footer>
        <p>
            <a href="https://github.com/YIPG/ainews">GitHub</a>
            <a href="https://news.smol.ai/">news.smol.ai</a>
        </p>
    </footer>
</body>
</html>