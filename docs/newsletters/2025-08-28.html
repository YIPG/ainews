<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>リアルタイムこそ全て？ | AIニュース</title>
    <meta name="description" content="リアルタイムこそ全て？ - AIニュース 2025-08-28。最新のAI技術動向を日本語でお届け。">
    <meta name="keywords" content="AI,人工知能,ニュースレター,2025-08-28,機械学習,深層学習,日本語">
    <meta name="author" content="AIニュース">
    <link rel="canonical" href="https://yipg.github.io/ainews/docs/newsletters/2025-08-28.html">
    
    <!-- Open Graph meta tags -->
    <meta property="og:title" content="リアルタイムこそ全て？ | AIニュース">
    <meta property="og:description" content="リアルタイムこそ全て？ - AIニュース 2025-08-28。最新のAI技術動向を日本語でお届け。">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://yipg.github.io/ainews/docs/newsletters/2025-08-28.html">
    <meta property="og:image" content="https://yipg.github.io/ainews/newsletters/og/2025-08-28.png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:image:type" content="image/png">
    <meta property="og:site_name" content="AIニュース">
    <meta property="og:locale" content="ja_JP">
    <meta property="article:published_time" content="2025-08-28T09:00:00+00:00">
    <meta property="article:author" content="AIニュース">
    <meta property="article:section" content="AI技術ニュース">
    
    <!-- Twitter Card meta tags -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="リアルタイムこそ全て？ | AIニュース">
    <meta name="twitter:description" content="リアルタイムこそ全て？ - AIニュース 2025-08-28。最新のAI技術動向を日本語でお届け。">
    <meta name="twitter:image" content="https://yipg.github.io/ainews/newsletters/og/2025-08-28.png">
    
    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>✏️</text></svg>">
    <link rel="alternate icon" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAACXBIWXMAAA7EAAAOxAGVKw4bAAAA">
    
    <!-- RSS Feed -->
    <link rel="alternate" type="application/rss+xml" title="AIニュース RSS Feed" href="../feed.xml">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: Verdana, Geneva, sans-serif;
            font-size: 1em;
            line-height: 1.7;
            letter-spacing: 0.02em;
            max-width: 720px;
            margin: 0 auto;
            padding: 20px;
            background-color: #fff;
            color: #111;
            word-wrap: break-word;
        }
        
        nav {
            margin-bottom: 25px;
            padding-bottom: 15px;
            border-bottom: 1px solid #ddd;
            display: flex;
            align-items: center;
            justify-content: space-between;
            flex-wrap: nowrap;
        }
        
        .site-title {
            font-size: 1.1em;
            font-weight: bold;
            color: #111;
            text-decoration: none;
            flex-shrink: 0;
        }
        
        .site-title:hover {
            text-decoration: underline;
        }
        
        .nav-links {
            font-size: 0.85em;
            white-space: nowrap;
        }
        
        .nav-links a {
            color: #111;
            text-decoration: none;
            margin-left: 12px;
        }
        
        .nav-links a:hover {
            text-decoration: underline;
        }
        
        
        h1, h2, h3, h4, h5, h6 {
            margin: 35px 0 20px 0;
            line-height: 1.3;
            color: #111;
            letter-spacing: 0.01em;
        }
        
        h1 { font-size: 1.5em; }
        h2 { font-size: 1.3em; }
        h3 { font-size: 1.1em; }
        
        p {
            margin: 20px 0;
        }
        
        a {
            color: #0969da;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin: 20px 0;
            padding-left: 30px;
        }
        
        li {
            margin: 8px 0;
        }
        
        blockquote {
            border-left: 3px solid #ccc;
            margin: 25px 0;
            padding: 0 25px;
            color: #555;
            font-style: italic;
        }
        
        code {
            background-color: #f6f8fa;
            padding: 2px 4px;
            border-radius: 3px;
            font-family: 'Courier New', Courier, monospace;
            font-size: 0.9em;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            padding: 20px;
            overflow-x: auto;
            margin: 25px 0;
        }
        
        pre code {
            background: none;
            padding: 0;
        }
        
        img {
            max-width: 100%;
            height: auto;
            margin: 25px 0;
            border-radius: 3px;
        }
        
        hr {
            border: none;
            border-top: 1px solid #ddd;
            margin: 35px 0;
        }
        
        footer {
            margin-top: 40px;
            padding-top: 15px;
            border-top: 1px solid #ddd;
            text-align: center;
            color: #555;
            font-size: 0.85em;
        }
        
        footer a {
            color: #555;
            text-decoration: none;
            margin: 0 8px;
        }
        
        footer a:hover {
            text-decoration: underline;
        }
        
        @media (max-width: 600px) {
            body {
                padding: 15px;
                font-size: 0.95em;
            }
            
            nav {
                flex-direction: column;
                align-items: flex-start;
                gap: 10px;
            }
            
            .nav-links {
                font-size: 0.8em;
            }
            
            .nav-links a {
                margin-left: 0;
                margin-right: 12px;
            }
            
            .article-title {
                font-size: 1.4em;
            }
        }
        
        @media (max-width: 480px) {
            body {
                font-size: 0.9em;
                padding: 12px;
            }
            
            .site-title {
                font-size: 1em;
            }
            
            .nav-links {
                font-size: 0.75em;
            }
            
            .article-title {
                font-size: 1.3em;
            }
        }
        
        @media (prefers-color-scheme: dark) {
            body {
                background-color: #111;
                color: #eee;
            }
            
            nav {
                border-bottom-color: #444;
            }
            
            .site-title, .nav-links a, .article-title, h1, h2, h3, h4, h5, h6 {
                color: #eee;
            }
            
            .article-date {
                color: #ccc;
            }
            
            blockquote {
                border-left-color: #555;
                color: #ccc;
            }
            
            code {
                background-color: #2d3748;
                color: #e2e8f0;
            }
            
            pre {
                background-color: #2d3748;
            }
            
            hr, footer {
                border-color: #444;
            }
            
            footer, footer a {
                color: #ccc;
            }
        }
    </style>
</head>
<body>
    <nav>
        <a href="../index.html" class="site-title">✏️ AIニュース</a>
        <div class="nav-links">
            <a href="../index.html">ホーム</a>
            <a href="./archive.html">アーカイブ</a>
            <a href="../feed.xml">RSS</a>
            <a href="https://github.com/YIPG/ainews">GitHub</a>
        </div>
    </nav>

    <main>
        <p><strong>リアルタイムこそ全て？</strong></p>
<p>Realtime APIはこれまでプレビュー提供されていましたが、このたびGA（一般提供）となりました。<a href="https://openai.com/index/introducing-gpt-realtime/#image-input">画像入力</a>、<a href="https://openai.com/index/introducing-gpt-realtime/#remote-mcp-server-support">リモートMCPサーバー対応</a>、<a href="https://openai.com/index/introducing-gpt-realtime/#additional-capabilities">SIP/PBX対応とプロンプトキャッシュ</a>、さらに強化された<a href="https://openai.com/index/introducing-gpt-realtime/#function-calling">ファンクションコーリング</a>などが追加されています。これに合わせて新しいリアルタイムモデルも登場しました。残念ながらgpt5-realtimeではありませんが、API中心の改善（ファンクションコーリングや指示追従性の向上）が主で、モデル自体もわずかに賢くなっています。</p>
<p>新たに2種類の音声が追加され、音声操作は数値化できないほどの向上があるとのことです。<a href="https://x.com/swyx/status/1961124194789499233">試してみる価値あり</a>です。</p>
<hr />
<h1 id="ai-twitter">AI Twitterまとめ</h1>
<p><strong>OpenAIのgpt-realtimeとRealtime API GA（音声エージェント、電話、ツール）</strong></p>
<ul>
<li><strong>gpt‑realtimeモデル + Realtime API GA</strong> : OpenAIはこれまでで最も高度な音声対音声モデルをリリースし、Realtime APIをGA化しました。主な改善点は、指示追従性の向上、ツール呼び出し、韻律や非言語的キューの改善、多言語切り替え、新しい音声（<strong>Cedar</strong>、<strong>Marin</strong>）、画像入力、リモートMCPツール対応、SIP電話、WebRTC APIの拡張（サーバーWebSocket制御、ビデオ対応）、および約20%の価格引き下げです。価格は、音声入力トークン100万あたり約32ドル（キャッシュ時0.40ドル/100万）、音声出力トークン100万あたり64ドルと共有されています。GPT‑4o‑realtimeとの比較ベンチマークではBigBench、ComplexFuncBench、音声指示追従で大幅な向上が示されています。デモにはNotion MCP例やWebRTC/SIPスターターコードがあります。スレッド: <a href="https://twitter.com/OpenAI/status/1961110295486808394">@OpenAI</a>、<a href="https://twitter.com/OpenAIDevs/status/1961124915719053589">@OpenAIDevs</a>、<a href="https://twitter.com/juberti/status/1961116594211364942">API詳細 @juberti</a>、<a href="https://twitter.com/omarsar0/status/1961117107417928047">価格情報 @omarsar0</a>、<a href="https://twitter.com/reach_vb/status/1961140618295394579">ベンチマーク所感 @reach_vb</a>、<a href="https://twitter.com/pbbakkum/status/1961120041799487654">MCPデモ @pbbakkum</a>。</li>
<li><strong>開発者向けメモ</strong> : 新しいオールインワンWebRTC APIは一時トークン手順を不要にし、同一接続でのビデオ対応を可能にしました。SIPエンドポイントは、コールルーティング、転送、切断APIを提供し、本番の通話フローを構築できます。Cookbookには音声プロンプト設計（速度、トーン、ハンドオフ）に関するガイドがあります。<a href="https://twitter.com/juberti/status/1961118374345241016">WebRTC APIアップデート</a>、<a href="https://twitter.com/juberti/status/1961118371090501972">SIP詳細</a>を参照ください。</li>
</ul>
<p><strong>コーディングモデルと開発ツール: xAIのGrok Code Fast 1、OpenAI Codex、エディタ/CLI</strong></p>
<ul>
<li><strong>xAIのGrok Code Fast 1</strong> : 「速度優先」の経済的推論モデルで、エージェント型コーディング向けに設計され、1週間無料で提供されます。GitHub Copilot、Cursor、Cline、Kilo Code、Roo Code、opencode、Windsurfなど主要IDE/ツールに統合されています。チームはベンチマークを超えた実用性を重視し、人間＋自動評価で迅速な改善を行っています。コミュニティテストは好評で、Clineは「3つの無料コーディング方法」（Grokによるクラウド、LM Studioによるローカル、Qwen Codeによる日次制限付き）を追加しました。発表と背景: <a href="https://twitter.com/xai/status/1961129789944627207">@xai</a>、<a href="https://twitter.com/skcd42/status/1961132126298157060">@skcd42</a>、<a href="https://twitter.com/MohitReddy13/status/1961138324426690608">@MohitReddy13</a>、<a href="https://twitter.com/cline/status/1961201105729401060">@clineローンチスレッド</a>。</li>
<li><strong>OpenAI Codexの新スタック統合</strong> : OpenAIのCodexが大幅アップデートされ、IDE拡張（Cursor/VSCode/Windsurf）、改善されたローカルCLI、ローカル＋クラウドの統合タスク管理、GitHubコードレビューが追加されました。ローカル/リモートワークフローを含む開発スタック全体での統合が進んでいます。スレッド: <a href="https://twitter.com/kevinweil/status/1960854500278985189">@kevinweil</a>、<a href="https://twitter.com/gdb/status/1960900413785563593">@gdb</a>、<a href="https://twitter.com/sama/status/1961096744533647501">@sama</a>。</li>
<li><strong>エコシステム改善</strong> : GoogleのGemini CLIがZedにネイティブ統合され（マルチフォルダIDEモード、差分統計、安定性向上、コミュニティ主導PR）、複数エディタ間のワークフローが容易になりました（<a href="https://twitter.com/_philschmid/status/1961090847174262937">@_philschmid</a>）。OpenAIのRealtime GAも音声主体のコーディングアシスタント（MCP over voice）を可能にします。</li>
</ul>
<p><strong>新モデルとベンチマーク: Microsoft MAI、Cohere Translate、Tencent TV2A、GLM‑4.5</strong></p>
<ul>
<li><strong>Microsoft MAI‑1‑preview（テキスト）とMAI‑Voice‑1</strong> : Microsoftが初の自社開発モデルを発表。MAI‑1‑previewはLMArenaテキストリーダーボードで初登場13位、MAI‑Voice‑1は高品質音声生成を目指しています。Microsoftは迅速な反復と製品展開を示唆。詳細: <a href="https://twitter.com/mustafasuleyman/status/1961111770422186452">@mustafasuleyman</a>、<a href="https://twitter.com/lmarena_ai/status/1961112908026593557">@lmarena_ai</a>、<a href="https://twitter.com/yusuf_i_mehdi/status/1961112928230461615">@yusuf_i_mehdi</a>。</li>
<li><strong>Cohere Command A Translate</strong> : 特定タスク向け翻訳モデルで、RWS/Language Weaverによる第三者評価で高評価。ドメイン特化型翻訳は、複雑な多分野タスクで汎用フロンティアモデル（GPT‑5など）を上回るとの反応。詳細は<a href="https://twitter.com/cohere/status/1961081787674763525">Cohereブログ</a>、<a href="https://twitter.com/nickfrosst/status/1961093091554713686">@nickfrosst</a>。</li>
<li><strong>Tencent HunyuanVideo‑Foley（TV2A）</strong> : 約10万時間のデータで学習したエンドツーエンドのテキスト/ビデオ→音声フレームワーク。MMDiTバックボーン、REPA損失、Audio VAEを採用し、音質、視覚的意味、時間的整合性でSOTAを達成。コード、レポート、HFウェイトが公開されています（<a href="https://twitter.com/TencentHunyuan/status/1960920482779423211">発表</a>）。</li>
<li><strong>Zhipu AI GLM‑4.5</strong> : BerkeleyのFunction‑Calling Leaderboard V4で首位となり、実用的なAPI呼び出しタスクでのツール利用能力を強化（<a href="https://twitter.com/Zai_org/status/1961149535754858586">結果</a>）。</li>
</ul>
<p><strong>エージェントシステム、評価、パターン</strong></p>
<ul>
<li><strong>並列エージェントのスケーリング軸</strong> : Andrew Ng氏は、並列エージェントのオーケストレーションを、データ、学習計算、推論時計算に続く第4のスケーリング手段として強調。トークン価格低下やレイテンシ制約の中で、研究エージェント、バックグラウンドワーカー＋UIモニター、エージェント混合集約などの研究やガイドが増えると予想（<a href="https://twitter.com/AndrewYNg/status/1961118026398617648">スレッド</a>）。</li>
<li><strong>Memory‑R1（記憶持ちエージェントのRL）</strong> : GRPO変種が、Llama‑3.1‑8BやQwen‑2.5‑7Bでの記憶ベンチマークにおいてF1/BLEU/LaaJを大幅向上。少量データ（152 QAペア）で成果を上げ、より強力なメモリマネージャーと組み合わせると効果が増幅。詳細: <a href="https://twitter.com/omarsar0/status/1961073807537693072">@omarsar0</a>。</li>
<li><strong>Agentic RAGと評価可能性</strong> : Elysia（オープンソースのAgentic RAG）は、意思決定ツリー構造、動的データ表示、オンデマンドチャンク化、フィードバック少数ショットを活用し、決定性とデバッグ性を向上（<a href="https://twitter.com/victorialslocum/status/1961095661719359624">概要</a>）。LlamaIndexはマルチエージェント「コーディングエージェント」を出荷し、ドキュメントワークフローを自動生成（編集/テスト/設定、コード優先、LlamaIndexワークフローでオーケストレーション）（<a href="https://twitter.com/jerryjliu0/status/1961123785597505603">デモ</a>）。AI SDK v5はLangSmithトレーシングを追加し、トークン使用量、ツールトレース、TTFTを可視化（<a href="https://twitter.com/Hacubu/status/1961103113122984202">@Hacubu</a>）。Rekaは検索拡張評価用にResearch‑Evalを公開（374問、多様かつ高品質、フロンティアモデルの精度は26.7%–59.1%）、既存のSimpleQA/BrowseCompを超える評価を目指す（<a href="https://twitter.com/RekaAILabs/status/1961192688029765936">@RekaAILabs</a>）。</li>
<li><strong>DSPy実践</strong> : データ中心パイプラインとLLMの組み込み位置に関する議論。自動化前に仕様/評価で最適化（fireside with @lateinteraction）（<a href="https://twitter.com/sh_reya/status/1961110090314125524">セッション</a>）。</li>
</ul>
<p><strong>画像/動画生成: Nano Bananaの勢い、ByteDance USO、Runwayの実運用</strong></p>
<ul>
<li><strong>Nano Banana（Gemini 2.5 Flash Image）</strong> : 個別スタイルやパネルプロンプト、モバイルワークフローでの利用が活発。ハッカソンも発表され、Googleは「banana」開発の舞台裏を紹介。Demis氏によるアイソメトリックマップ→ゲームアイデア、glifエージェントやSunoとの連携などの事例あり。サンプル: <a href="https://twitter.com/demishassabis/status/1961077016830083103">@demishassabis</a>、<a href="https://twitter.com/OfficialLoganK/status/1961127857192673540">@OfficialLoganK</a>、<a href="https://twitter.com/tulseedoshi/status/1961068980640108889">@tulseedoshi</a>。</li>
<li><strong>ByteDance USO（Apache‑2.0）スタイル転送/編集</strong> : テキスト＋画像駆動の編集をオープンソース化。HFデモあり、実務者から高評価。「nano banana」時代の有力なオープン代替手段（<a href="https://twitter.com/multimodalart/status/1961147988258295893">概要</a>）。</li>
<li><strong>Runway Gen‑4の実運用</strong> : Fabulaとの映画制作パートナーシップで、プロのワークフローを補完する事例を紹介（<a href="https://twitter.com/runwayml/status/1961088220571066620">Runway公式</a>）。またWan 2.2 S2Vの試用では、音声前処理やファインチューニングが音楽的整合性に重要であることが確認されました（<a href="https://twitter.com/ostrisai/status/1960907113821298877">@ostrisai</a>）。別件として、MoonshotのKimi Slidesはエージェント型デッキ作成を導入（アイデア→デッキ、将来的には自動画像検索/レイアウト/仕上げ）（<a href="https://twitter.com/Kimi_Moonshot/status/1961011693745811542">@Kimi_Moonshot</a>）。</li>
</ul>
<p><strong>インフラと戦略</strong></p>
<ul>
<li><strong>コンピュート拡張</strong> : OpenAIとOracleが4.5GWのデータセンター建設（Stargate）を計画中との報道。1.2GWのAbileneに続き、SoftBank、Microsoft、NVIDIAがパートナーに。年間契約額は300億ドル規模との噂。サイト選定は進行中（<a href="https://twitter.com/DeepLearningAI/status/1960900145421177053">@DeepLearningAI</a>）。</li>
<li><strong>プラットフォームシェアを国家戦略に</strong> : 米国の優位性維持には、米国製ハード/ソフト上での利用（トークン、モデル、開発者）最大化が必要との政策論。開発者エコシステムを回すことを重視し、輸出規制が逆に代替スタック（Huawei+CloudMatrix+DeepSeek/Qwen）を育てるリスクを指摘（<a href="https://twitter.com/sriramk/status/1961072926561550366">@sriramk</a>）。関連観察として、事前学習は同じインターネットでも、強化学習や後処理の選択（および製品データ）がモデルの「種分化」を生むとの指摘（<a href="https://twitter.com/tszzl/status/1960953564681134472">@tszzl</a>、<a href="https://twitter.com/Yuchenj_UW/status/1961121746670817404">@Yuchenj_UW</a>）。</li>
</ul>
<p><strong>エンゲージメント上位ツイート</strong></p>
<ul>
<li>xAIがGrok Code Fast 1を主要IDE向けに7日間無料提供 <a href="https://twitter.com/xai/status/1961129789944627207">@xai</a></li>
<li>OpenAIがRealtime APIとgpt‑realtimeの開発者向けライブ配信を告知 <a href="https://twitter.com/OpenAI/status/1961081377174212979">@OpenAI</a></li>
<li>OpenAIがgpt‑realtimeとRealtime API GAを発表 <a href="https://twitter.com/OpenAI/status/1961110295486808394">@OpenAI</a></li>
<li>Karpathy氏が教科書や環境をLLM学習用に変換する構想を投稿 <a href="https://twitter.com/karpathy/status/1961128638725923119">@karpathy</a></li>
<li>「Nano Banana」コミュニティの盛り上がりとハッカソン発表 <a href="https://twitter.com/OfficialLoganK/status/1961127857192673540">@OfficialLoganK</a>、Demis氏のアイソメマップ投稿 <a href="https://twitter.com/demishassabis/status/1961077016830083103">@demishassabis</a></li>
<li>OpenAI Codexの新機能が開発者に好評 <a href="https://twitter.com/sama/status/1961096744533647501">@sama</a></li>
</ul>
    </main>

    <footer>
        <p>
            <a href="https://github.com/YIPG/ainews">GitHub</a>
            <a href="https://news.smol.ai/">news.smol.ai</a>
        </p>
    </footer>
</body>
</html>