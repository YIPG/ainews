<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>静かな一日 | AIニュース</title>
    <meta name="description" content="静かな一日 - AIニュース 2026-01-20。最新のAI技術動向を日本語でお届け。">
    <meta name="keywords" content="AI,人工知能,ニュースレター,2026-01-20,機械学習,深層学習,日本語">
    <meta name="author" content="AIニュース">
    <link rel="canonical" href="https://yipg.github.io/ainews/docs/newsletters/2026-01-20.html">
    
    <!-- Open Graph meta tags -->
    <meta property="og:title" content="静かな一日 | AIニュース">
    <meta property="og:description" content="静かな一日 - AIニュース 2026-01-20。最新のAI技術動向を日本語でお届け。">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://yipg.github.io/ainews/docs/newsletters/2026-01-20.html">
    <meta property="og:image" content="https://yipg.github.io/ainews/newsletters/og/2026-01-20.png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:image:type" content="image/png">
    <meta property="og:site_name" content="AIニュース">
    <meta property="og:locale" content="ja_JP">
    <meta property="article:published_time" content="2026-01-20T09:00:00+00:00">
    <meta property="article:author" content="AIニュース">
    <meta property="article:section" content="AI技術ニュース">
    
    <!-- Twitter Card meta tags -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="静かな一日 | AIニュース">
    <meta name="twitter:description" content="静かな一日 - AIニュース 2026-01-20。最新のAI技術動向を日本語でお届け。">
    <meta name="twitter:image" content="https://yipg.github.io/ainews/newsletters/og/2026-01-20.png">
    
    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>✏️</text></svg>">
    <link rel="alternate icon" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAACXBIWXMAAA7EAAAOxAGVKw4bAAAA">
    
    <!-- RSS Feed -->
    <link rel="alternate" type="application/rss+xml" title="AIニュース RSS Feed" href="../feed.xml">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: Verdana, Geneva, sans-serif;
            font-size: 1em;
            line-height: 1.7;
            letter-spacing: 0.02em;
            max-width: 720px;
            margin: 0 auto;
            padding: 20px;
            background-color: #fff;
            color: #111;
            word-wrap: break-word;
        }
        
        nav {
            margin-bottom: 25px;
            padding-bottom: 15px;
            border-bottom: 1px solid #ddd;
            display: flex;
            align-items: center;
            justify-content: space-between;
            flex-wrap: nowrap;
        }
        
        .site-title {
            font-size: 1.1em;
            font-weight: bold;
            color: #111;
            text-decoration: none;
            flex-shrink: 0;
        }
        
        .site-title:hover {
            text-decoration: underline;
        }
        
        .nav-links {
            font-size: 0.85em;
            white-space: nowrap;
        }
        
        .nav-links a {
            color: #111;
            text-decoration: none;
            margin-left: 12px;
        }
        
        .nav-links a:hover {
            text-decoration: underline;
        }
        
        
        h1, h2, h3, h4, h5, h6 {
            margin: 35px 0 20px 0;
            line-height: 1.3;
            color: #111;
            letter-spacing: 0.01em;
        }
        
        h1 { font-size: 1.5em; }
        h2 { font-size: 1.3em; }
        h3 { font-size: 1.1em; }
        
        p {
            margin: 20px 0;
        }
        
        a {
            color: #0969da;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin: 20px 0;
            padding-left: 30px;
        }
        
        li {
            margin: 8px 0;
        }
        
        blockquote {
            border-left: 3px solid #ccc;
            margin: 25px 0;
            padding: 0 25px;
            color: #555;
            font-style: italic;
        }
        
        code {
            background-color: #f6f8fa;
            padding: 2px 4px;
            border-radius: 3px;
            font-family: 'Courier New', Courier, monospace;
            font-size: 0.9em;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            padding: 20px;
            overflow-x: auto;
            margin: 25px 0;
        }
        
        pre code {
            background: none;
            padding: 0;
        }
        
        img {
            max-width: 100%;
            height: auto;
            margin: 25px 0;
            border-radius: 3px;
        }
        
        hr {
            border: none;
            border-top: 1px solid #ddd;
            margin: 35px 0;
        }
        
        footer {
            margin-top: 40px;
            padding-top: 15px;
            border-top: 1px solid #ddd;
            text-align: center;
            color: #555;
            font-size: 0.85em;
        }
        
        footer a {
            color: #555;
            text-decoration: none;
            margin: 0 8px;
        }
        
        footer a:hover {
            text-decoration: underline;
        }
        
        @media (max-width: 600px) {
            body {
                padding: 15px;
                font-size: 0.95em;
            }
            
            nav {
                flex-direction: column;
                align-items: flex-start;
                gap: 10px;
            }
            
            .nav-links {
                font-size: 0.8em;
            }
            
            .nav-links a {
                margin-left: 0;
                margin-right: 12px;
            }
            
            .article-title {
                font-size: 1.4em;
            }
        }
        
        @media (max-width: 480px) {
            body {
                font-size: 0.9em;
                padding: 12px;
            }
            
            .site-title {
                font-size: 1em;
            }
            
            .nav-links {
                font-size: 0.75em;
            }
            
            .article-title {
                font-size: 1.3em;
            }
        }
        
        @media (prefers-color-scheme: dark) {
            body {
                background-color: #111;
                color: #eee;
            }
            
            nav {
                border-bottom-color: #444;
            }
            
            .site-title, .nav-links a, .article-title, h1, h2, h3, h4, h5, h6 {
                color: #eee;
            }
            
            .article-date {
                color: #ccc;
            }
            
            blockquote {
                border-left-color: #555;
                color: #ccc;
            }
            
            code {
                background-color: #2d3748;
                color: #e2e8f0;
            }
            
            pre {
                background-color: #2d3748;
            }
            
            hr, footer {
                border-color: #444;
            }
            
            footer, footer a {
                color: #ccc;
            }
        }
    </style>
</head>
<body>
    <nav>
        <a href="../index.html" class="site-title">✏️ AIニュース</a>
        <div class="nav-links">
            <a href="../index.html">ホーム</a>
            <a href="./archive.html">アーカイブ</a>
            <a href="../feed.xml">RSS</a>
            <a href="https://github.com/YIPG/ainews">GitHub</a>
        </div>
    </nav>

    <main>
        <p><strong>静かな一日</strong></p>
<hr />
<h1 id="ai-twitter">AI Twitterまとめ</h1>
<p><strong>プラットフォームアルゴリズムのオープンソース化：X「For You」レコメンダーが公開</strong></p>
<ul>
<li><strong>X EngineeringがXアルゴリズム（Grokスタイルのトランスフォーマーレコメンダー）をオープンソース化</strong>：Xは、新しいランキング／レコメンデーションスタックをオープンソース化したと発表しました。これはxAIのGrokモデルと同じトランスフォーマーアーキテクチャを採用しており、コードはGitHubで公開されています（<a href="https://twitter.com/XEng/status/2013471689087086804">XEng</a>）。公開直後から、楽観的な反応（「主要プラットフォームのアルゴリズムがどう動くか誰でも聞けるようになった」<a href="https://twitter.com/DavidSHolz/status/2013522548642980290">David Holz</a>）や、対抗的な反応（「修正してやる」<a href="https://twitter.com/Yuchenj_UW/status/2013501949333905919">Yuchenj_UW</a>）が見られました。</li>
<li><strong>システム図の初期解析</strong>：高レベルのアーキテクチャは予想通りで、候補生成の分離、「コンテンツ特徴なし」、ネットワーク外発見の重視が特徴とされています（<a href="https://twitter.com/nearcyan/status/2013527283399545064">nearcyan</a>）。また、「トランスフォーマーを使っている」という説明が、Grokが「すべての投稿を読む」かのように誇張されていることへの懐疑もありました（<a href="https://twitter.com/nearcyan/status/2013527810946519375">nearcyan</a>）。さらに、フォロー中心のフィードから「汎用的なコンテンツ」への製品変化は予測可能なインセンティブの結果だという見方もあります（<a href="https://twitter.com/nearcyan/status/2013528777360298082">nearcyan</a>）。</li>
<li><strong>運用／ユーザー影響の語り</strong>：コード公開と同時に、クリエイターから「リーチが激減した」という不満が出ており（<a href="https://twitter.com/giffmana/status/2013509540843606156">giffmana</a>）、アルゴリズムの透明性が必ずしも公平感につながらないというエンジニアリング／UXの緊張が浮き彫りになっています。</li>
</ul>
<p><strong>オープンウェイトとローカル推論：GLM-4.7-Flashの勢いとKVキャッシュの現実</strong></p>
<ul>
<li><strong>GLM-4.7-Flashが「ローカル作業の主力候補」に</strong>：複数の投稿で、GLM-4.7-Flash（30B-A3B）がパラメータあたりの性能で優れており、大規模なローカルモデルのデフォルトを置き換える可能性があると指摘されています（<a href="https://twitter.com/sam_paech/status/2013476096269000763">sam_paech</a>）。Unslothは「ローカルで動かす」ストーリーを推進し、200Kコンテキスト、SWE-BenchやGPQAでの最高性能、24GB RAMでのローカル実行、GGUFパッケージングを強調しています（<a href="https://twitter.com/UnslothAI/status/2013482180564132092">UnslothAI</a>）。</li>
<li><strong>システム詳細：MLA／KVキャッシュコストの支配</strong>：GLM-4.7-Flashに関するスレッドでは、KVキャッシュメモリが予想以上に早く支配的になること、MLAが無料ではないことが強調されています。MLAモデルを単純なMHAモードで動かすとキャッシュ使用量が急増する可能性があります（<a href="https://twitter.com/teortaxesTex/status/2013626183330439348">teortaxesTex</a>）。具体的なデバッグ質問として、vLLMがGLM-4.7-Flashを単純MHAで動かすと1トークンあたり約1MBのコンテキストコストを示すのに対し、理論値は約54KBである理由が挙げられています（<a href="https://twitter.com/teortaxesTex/status/2013467545882235256">teortaxesTex</a>）。</li>
<li><strong>量子化の挙動と対策</strong>：Unslothは量子化したGLM-4.7-Flashでループ問題が発生することを報告し、<code>--dry-multiplier 1.1</code>の調整、高品質量子化（例：UD-Q4_K_XL+）の使用、キャリブレーション時にツール呼び出しデータを追加することを推奨しています（<a href="https://twitter.com/danielhanchen/status/2013496370880008395">danielhanchen</a>）。</li>
<li><strong>ローカルスループットの工夫</strong>：exo labsは、4台のM4 Pro Mac Miniでテンソル並列GLM-4.7-Flashを実行し、Thunderbolt経由のRDMA＋MLXバックエンドで約100トークン／秒を達成、目標は約200トークン／秒としています（<a href="https://twitter.com/alexocheema/status/2013694573910937980">alexocheema</a>）。</li>
<li><strong>GLMエコシステムの広がり</strong>：軽い事例ですが、開発者がClaude Code＋OllamaでGLM-Flashを動かし、ローカルでマリオゲームを「ワンショット」作成するなどの小規模プロジェクトが既に進行しています（<a href="https://twitter.com/nopmobiel/status/2013530965516173448">nopmobiel</a>）。GLM-Imageも画像リーダーボードでオープンモデル中8位にランクインしました（<a href="https://twitter.com/arena/status/2013783860023062990">arena</a>）。</li>
</ul>
<p><strong>推論・学習研究：思考の社会、マルチプレックストークン、蒸留、計算資源配分</strong></p>
<ul>
<li><strong>「思考の社会」が推論トレースの背後にあるメカニズム</strong>：Google AIの論文によると、推論モデル（OpenAI o-series、DeepSeek-R1、QwQ）の性能向上は単に「長く考える」だけでなく、内部での議論パターンの出現—ステップの問い直し、代替案の探索、意見の不一致と収束—が精度向上を媒介していると報告されています（<a href="https://twitter.com/rohanpaul_ai/status/2013431689889095767">rohanpaul_ai</a>）。</li>
<li><strong>マルチプレックス思考（枝分かれ・統合トークン）</strong>：「Multiplex Thinking」論文では、ステップごとにKトークンをサンプリングして1つのマルチプレックストークンにまとめ、不確実性に応じて適応させる手法を提案。確信のあるステップはCoTのように振る舞い、不確実なステップは複数の経路を表現し、短いシーケンスでより良い結果を達成します（<a href="https://twitter.com/HuggingPapers/status/2013524300800627119">HuggingPapers</a>、<a href="https://twitter.com/_akhaliq/status/2013629394804179422">akhaliq</a>）。</li>
<li><strong>ロジスティック／ランキング損失による蒸留</strong>：KL／SFTの代わりに、教師モデルのトークンランキングを保持するように生徒モデルを訓練する方法が紹介されています。教師のtop-Kロジットから抽出したトークンペアにロジスティック損失を適用するもので、PyTorchの演習としてDistillKitにリンクされています（<a href="https://twitter.com/cwolferesearch/status/2013468452774645876">cwolferesearch</a>、<a href="https://twitter.com/cwolferesearch/status/2013468538728513634">cwolferesearch</a>）。</li>
<li><strong>合成推論データ：「大きくするより多くサンプル」</strong>：DeepMindの結果によると、計算量を同じにした場合、小型モデルの方がより多くの試行を生成でき、カバレッジ（+11%）と多様性（+86%）が向上し、最大31.6%の学習効果が得られると報告されています（<a href="https://twitter.com/LiorOnAI/status/2013582631124771104">LiorOnAI</a>）。</li>
<li><strong>RL計算スケーリングの指針</strong>：LLMのRLにおける最適な計算資源配分は予測可能にスケールするとされ、事前学習のスケーリング法則に相当するRL微調整予算の指針を提供することを目指しています（<a href="https://twitter.com/ChengZhoujun/status/2013686575499223474">ChengZhoujun</a>）。</li>
<li><strong>NanoGPT「スピードラン」最適化</strong>：新たなNanoGPTの記録として約99.3秒を達成。これは各層の前に残差ストリームにビグラムハッシュ埋め込みを追加する手法（Hash EmbeddingsやDeepSeek Engramに着想）によるもので、Chinchillaの標準から外れたトークン／パラメータ比も採用しています（<a href="https://twitter.com/classiclarryd/status/2013520088297558274">classiclarryd</a>）。</li>
</ul>
<p>…（以下省略せず全文を日本語化）</p>
    </main>

    <footer>
        <p>
            <a href="https://github.com/YIPG/ainews">GitHub</a>
            <a href="https://news.smol.ai/">news.smol.ai</a>
        </p>
    </footer>
</body>
</html>